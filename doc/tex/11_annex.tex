
\newpage
\begin{appendices}

\section{Compiled code binaries}\label{annex:compilation}

% small intro
To perform the experiment on function renaming, the dataset used was a set of well-known open source programs:
% list of software used
\begin{itemize}
	\item Apache http server
	\item Filezilla ftp client
	\item Nginx http server
	\item OpenSSL library
	\item GlibC library
\end{itemize}


% symbols compilation summary and references
They were compiled from source using debugging options that make the final binary include the function names (also called symbols). Basically, each package or software had different options to include in the compilation command, but most of the times it required to include the -d for debugging option followed by some other indications. 


% example of symbols
Once the code is compiled with debugging information, the different functions or subroutines can be related to a function name that is listed inside the binary. Examples of function names are the following:

\begin{itemize}
\item aes\_encrypt\_cbc, which is highly informative of the purpose of the function, encrypting with AES algorithm using Cipher Block Chaining.
\item apr\_socket\_sendfile, which is again highly informative telling that it sends a file through a socket
\item \_zn9\_\_gnu\_cxx12\_\_pool\_allocice10deallocateepcy, others are not so informative or easy to understand, but at least it shows that it is handling memory pool allocations.
\end{itemize}

This will be the base on which a ruleset will transform each of the function names ( a total of more than 30000) into a small set of classes (8 for v1, 170 for v2 and 24 for v3 versions of the dataset)






\section{Feature extraction details}\label{annex:graph_from_code}


This annex will present the details of the implementation of the feature extraction from the dataset of assembly function code listings, used in the task of assembly function code classification.

\textbf{Graph of an assembly function code}

% compiled code binaries, machine code to assembly code
In this thesis, the tasks that classifies binary code functions takes advantage of programs that are prepared for reading and parsing binary files into human readable formats, using a programing language called assembler or assembly. However, a binary file is a file that contains bytes organized following a convention, or file format like PE or COFF, completely dependent of the operating system, but not assembler directives. The bytes contained in those file formats represent machine language code. This is not a problem as, per wikipedia definition, an assembly language (or assembler language), often abbreviated asm, is any low-level programming language in which there is a very strong correspondence between the program's statements and the architecture's machine code instructions. 


% Disassembler program, IDA free and how it works
For analysing a binary file, programs that convert the bytes of the binary file, that represent machine code, into assembler instructions are called disassemblers. For this thesis the selected disassembler program is called IDA free, which is a free version of the corresponding professional program IDA pro. This program reads the binary file bytes, according to the corresponding file formats, like PE for Microsoft Windows or COFF2 in Unix operating systems, and is able to interpret the machine code and translate it into assembler code instructions. There is a direct correspondence between machine code and assembler directives.

% IDA and python plugins
The selected disassembler program, IDA free, allows for executing scripts written in the programming language python. This scripts are run from inside its user interface to do tasks, like inspection and modification of the database of the binary code loaded.

% Plugin
The python script is ran as a script, also known as "plugin", inside the disassembler program (IDA free). It takes advantage of series of exposed interfaces or methods that read the database that contains the information of the disassembled binary file and its instructions. The procedure followed by the python script is to process all the lines of code of each function contained in the binary file. For each function or subroutine that the disassembler has detected, the python script will write 2 separate text files that contain the list of elements found as nodes and the list of relationships between them as edges, conveniently following a file format that the python package NetworkX can read and import into a NetworkX graph representation. 
The elements considered are all the types of elements that can appear in assembly code and that the disassembler detects: instructions, registers, memory addresses, immediate values, displacements and called functions. The edges represent relationships between them. For example, the instruction "mov eax, 0x0457AB" is related to the register "eax", the memory address "0x0457AB", as well as the previous and next instruction found in the code listing when following its execution flow. When the instruction is calling another function, for example "call another\_function\_address", an edge relating this instruction and the function another\_function\_address must exist. 



\begin{figure}[H]
\minipage{0.5\textwidth}%
  \centering
    \includegraphics[width=0.9\linewidth]{img/code_graph02.png}
\endminipage
\minipage{0.5\textwidth}%
  \centering
    \includegraphics[width=0.9\linewidth]{img/code_graph01.png}
\endminipage
\caption{Assembler code transformed into a graph representation}\label{fig:code_graph01}
\end{figure}




% verification
Several assembly code functions are selected for testing the python plugin that generates the graph of the function code. The procedure is simple, the assembly code is printed as a code listing (each instruction is shown in assembly language in a separate line) like the disassembly program shows it inside its user interface. Then the contents of the file containing the description of the nodes, usually called function\_name\_nodes.txt where the function\_name part is replaced by the actual function name being analysed, and the file containing the set of edges joining nodes, usually called function\_name\_edges.txt where the function\_name part is replaced by the actual function name being analysed, are compared to the code listing to verify that every line of code, every register, memory address and the like is present in the nodes file, and every relationship between instructions, registers, memory addresses, called functions and the like is also present in the edges list file.


\begin{figure}[H]
\minipage{0.5\textwidth}%
  \centering
    \includegraphics[width=0.85\linewidth]{img/code_graph03.png}
\endminipage
\minipage{0.5\textwidth}%
  \centering
    \includegraphics[width=0.95\linewidth]{img/code_graph04.png}
\endminipage
\caption{Edges and nodes list text files used to convert assembler code listings into graphs}\label{fig:code_graph02}
\end{figure}






\section{Labeling of the dataset}\label{annex:labels}


In this annex, a description of the process of labeling of the dataset is given.

The task of renaming functions in assembler code will be performed on a dataset of binaries that have been compiled with debugging information, that is with the so called symbols, which are the names of the functions or subroutines contained in the program. So, in the dataset every function keeps its original name.


The goal of the task is to predict a function name, in a more general way, by giving a name that describes or is a synonym of that main task performed by the function being renamed.  The current labels (the original names of the functions) are too specific. Thus, we need to assign as a label a name that is much more generalistic, in the sense that it indicates what is the main purpose of the function. The following steps have been followed.

First, a series of topics have been chosen:
\begin{itemize}
\item cryptographic
\item networking
\item graphical user interface
\item disk
\item data structures
\item memory
\item users
\item computation
\end{itemize}

Given the type of program binaries used as a dataset (network servers, clients and cryptographic applications), those topics cover the main functionalities of them.

Second, to be able to give a richer sense to the function names, a series of types of actions have been chosen:
\begin{itemize}
\item configure 
\item verify
\item save
\item delete
\item update
\item create 
\item get 
\item answer
\item read
\item write
\item send
\item receive
\item show
\item hide
\item start
\item stop
\item sync
\item parse
\item match
\item encrypt
\item data
\item file
\item compute
\item work
\end{itemize}

They have been chose based on the visual observation the real names in the dataset and by common sense also.

Third, 2 labeling strategies are created, one that consists of applying only the topic and a more comprehensive that assigns a topic and a task to a function. For example, the first labeling strategy may rename the function aes\_encrypt as cryptography, while the second strategy may rename it as cryptography\_encrypt. During the training of the models, those 2 labeling strategies will be compared. It is desirable that the second strategy is implemented over the first one, but the chance of success in this second strategy is lower as there are much more classes than in the second one. 

Finally, the labels have been assigned following very simple rules based on the real name of each function in the dataset and the number of appearances of each topic and task within it. The script uses the topics and tasks and their synonyms. It counts how many times each topic and each task appears in the real name of the function. The topic and the task that have the maximum number of appearances are assigned to the function. Two dataset are build, one with the first labelling strategy (assigning only the topic) and one with the second strategy (topic and task). The first dataset has 10 classes (9 + unknown). The second dataset has 170 classes. 

The final set of labels for each dataset version is shown below:

\begin{figure}[H]
\minipage{0.2\textwidth}%
  %\centering
    For the dataset v1:\\\\
   {\footnotesize
\begin{itemize}
	\item gui
	\item network
	\item disk
	\item cryptography
	\item datastruct
	\item memory
	\item process
	\item users
	\item computation
\end{itemize}
}
\endminipage
\minipage{0.45\textwidth}%
  
  For the dataset v2:\\

 \minipage{0.5\textwidth}%
  {\footnotesize
  \begin{itemize} 
    \item gui-hide
    \item gui-show
    \item gui-config
    \item gui-work
    \item gui-update
    \item gui
    \item network-send
    \item network-receive
    \item network-config
    \item network-save
    \item network-data
    \item network-file
    \item network-verify
    \item network-answer
    \item network-get
    \item network
    \end{itemize}
   }
   \endminipage
   \minipage{0.5\textwidth}%
   {\footnotesize
   \begin{itemize} 
    \item disk-work
    \item disk-read
    \item disk-write
    \item disk-delete
    \item disk-verify
    \item disk-parse
    \item disk-match
    \item disk

    \item cryptography-work
    \item cryptography-compute
    \item cryptography-send
    \item cryptography-encrypt
    \item cryptography-verify
    \item cryptography-config
    \item cryptography
    \item ...
%    \item datastruct-work
%    \item datastruct-config
%    \item datastruct%

    %\item memory-config
    %\item memory-work
    %\item memory-read
    %\item memory-write
    %\item memory-update
    %\item memory-delete
    %\item memory-create
    %\item memory-verify
    %\item memory



    %\item process-start
    %\item process-stop
    %\item process-create
    %\item process-update
    %\item process-delete
    %\item process-sync
    %\item process

    %\item users
    %\item users-create
    %\item users-update
    %\item users-delete
    %\item users-verify
    %\item users-config
    %\item users-save

    %\item computation
    %\item computation-work

	\end{itemize}
	}
   \endminipage
\endminipage
\minipage{0.35\textwidth}%
  
For the dataset v3:\\
\minipage{0.5\textwidth}%
{\footnotesize
\begin{itemize}
    \item gui-config
    \item gui

    \item network-send
    \item network-parse
    \item network-config
    \item network

    \item disk-file
    \item disk-read
    \item disk-write
    \item disk


    \item cryptography-encrypt
    \item cryptography-config
    \item cryptography
\end{itemize}
}
\endminipage
\minipage{0.5\textwidth}%
  
{\footnotesize
\begin{itemize}
    \item datastruct

    \item memory-config
    \item memory-read
    \item memory-write
    \item memory


    \item process-update
    \item process-sync    
    \item process-config  
    \item process

    \item users
    \item computation
\end{itemize}
}
\endminipage
\endminipage
\caption{Dataset labelling versions}\label{fig:labelling_versions}
\end{figure}










%During the training, some of the classes have been ignored due to the low frequency of appearance.







\section{Feature engineering in assembly code classification}\label{annex:feature_engineering}

Some of the machine learning models for classifying code functions in assembly (compiled binaries), make use of features that have been designed outside of the algorithm. It's the case of the code features, those related to aspects of an assembly function code like number of instructions or number of called functions, and the topological features of the graph of a function, those derived from the function's graph based on the relations between instructions, registers, memory addresses and other instructions. 
For the rest of the models of this task, the ones based on graph neural networks, there is no feature engineering, as they use the graph as an input to learning and prediction.

% HOW CODE FEATURES ARE EXTRACTED
The code features are aimed at summarizing or extracting relevant aspects of the underlying code. To this goal, counts of number of instructions, registers, memory addresses, function calls and the like are extracted from each assembly function code listing. The full assembly code listing is also extracted as a feature for models that use Bag of Words strategies. These features are simply obtained by reading the text files that list the nodes and the edges of the graph of the function, as the allow for recovering the basic elements on which the graph is constructed, the nodes, which are representations of instructions, registers, memory addresses and the like.
The list of features from code is the following:
\begin{itemize}
	\item  number of registers
	\item number of distinct registers
	\item number of instructions
	\item number of displacements
	\item number of immediates
	\item number of memory addresses
	\item number of functions called
	\item the list of words used in the code listing
	\item the list of words but replacing any register by the word register (and the same for memory addresses)
	\item a list of registers used
	\item a list of functions used
\end{itemize}

% TESTS CONDUCTED ON THE EXTRACTED CODE FEATURES
The code features extraction implementation is tested on several assembly function code listings, by comparing the counts of instructions, registers, memory addresses and the like versus those values extracted by the code that reads the text files that list nodes and edges of the graph of the assembly function.



% HOW TOPOLOGICAL FEATURES ARE EXTRACTED
The features that are derived from the topological aspects of graphs, like assortativity and clustering coefficient, are obtained with the implementation included inside the NetworkX Python library.

No testing of these topological features is performed, as the Python library NetworkX is used by a large community and has a great reputation. 
The list of the topological features extracted is the following:
\begin{itemize}
	\item number of nodes
	\item diameter of the graph
	\item radius
	\item average degree
	\item density
	\item node connectivity
	\item average clustering
	\item average shortest path length
	\item degree assortativity coefficient
	\item degree perason correlation coefficient
\end{itemize}


A distribution analysis is performed on all the features to see if they carry a considerable amount of discriminative power towards the different classes of the dataset. The analysis for dataset v1 is the following:

\begin{figure}[H]
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_nregs.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_number_of_distinct_registers.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_number_of_instructions.png}
\endminipage


\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_number_of_displacements.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_number_of_immediates.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_number_of_addresses.png}
\endminipage

\caption{Boxplots of the distribution of the data for several features on v1 dataset}\label{fig:distribution_analysis1}
\end{figure}




\begin{figure}[H]

\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_number_of_functions.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_size.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_diameter.png}
\endminipage

\vfill 

\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_radius.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_average_degree.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_density.png}
\endminipage

\caption{Boxplots of the distribution of the data for several features on v1 dataset}\label{fig:distribution_analysis2}
\end{figure}




\begin{figure}[H]

\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_connectivity.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_average_clustering.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_average_shortests_path_length.png}
\endminipage

\vfill


\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_degree_assortativity.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_degree_pearson_correlation_coefficient.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_number_of_functions.png}
\endminipage

\caption{Boxplots of the distribution of the data for several features on v1 dataset}\label{fig:distribution_analysis3}
\end{figure}




\begin{figure}[H]



\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v1_unbalanced_size.png}
\endminipage


\caption{Boxplots of the distribution of the data for several features on v1 dataset}\label{fig:distribution_analysis4}
\end{figure}



The analysis for dataset v3 is the following:

\begin{figure}[H]
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_nregs.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_number_of_distinct_registers.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_number_of_instructions.png}
\endminipage


\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_number_of_displacements.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_number_of_immediates.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_number_of_addresses.png}
\endminipage

\caption{Boxplots of the distribution of the data for several features on v3 dataset}\label{fig:distribution_analysis5}
\end{figure}




\begin{figure}[H]

\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_number_of_functions.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_size.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_diameter.png}
\endminipage

\vfill 

\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_radius.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_average_degree.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_density.png}
\endminipage

\caption{Boxplots of the distribution of the data for several features on v3 dataset}\label{fig:distribution_analysis6}
\end{figure}




\begin{figure}[H]

\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_connectivity.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_average_clustering.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_average_shortests_path_length.png}
\endminipage

\vfill


\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_degree_assortativity.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_degree_pearson_correlation_coefficient.png}
\endminipage
\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_number_of_functions.png}
\endminipage

\caption{Boxplots of the distribution of the data for several features on v3 dataset}\label{fig:distribution_analysis7}
\end{figure}




\begin{figure}[H]



\minipage{0.32\textwidth}%
\centering
\includegraphics[width=0.9\linewidth]{img/boxplots/v3_unbalanced_size.png}
\endminipage


\caption{Boxplots of the distribution of the data for several features on v3 dataset}\label{fig:distribution_analysis8}
\end{figure}




\newpage
\section{Training Results}\label{annex:models}

\subsection{Experiment 1}

\begin{table}[H]
\centering
\begin{tabular}{|llllccc|}
\hline
 Model &                                                                          Paramteres  &  Runs\/Epochs  &  Splits &    Loss &        Accuracy &        F1-macro  \\
\hline
 META1 &      d19d16h10e19n16n15 & 100-20 & 100-2000-10556- &  2.3561 &   0.280 ± 0.061 &   0.251 ± 0.060  \\
 META1 &     d19d16h10e19n16n15 & 100-250 & 100-2000-10556- &  3.8995 &   0.139 ± 0.018 &   0.128 ± 0.020  \\
 META1 &         d19d16h10e19n16n15 & 100-20 & 20-500-1500- &  3.0269 &   0.142 ± 0.027 &   0.127 ± 0.029  \\
 META1 &        d19d16h10e19n16n15 & 100-250 & 20-500-1500- &  4.9482 &   0.093 ± 0.013 &   0.087 ± 0.017  \\
 META1 &      d19d16h10e19n16n15 & 100-20 & 200-3000-10556- &  2.0677 &  \textbf{ 0.342 ± 0.078} &   \textbf{0.312 ± 0.076 } \\
 META1 &     d19d16h10e19n16n15 & 100-250 & 200-3000-10556- &  3.3414 &   0.219 ± 0.027 &   0.208 ± 0.028  \\
 META1 &    d19d16h10e19n16n15 & 100-600 & 200-3000-10556- &  3.7691 &   0.142 ± 0.037 &   0.124 ± 0.039  \\
 META1 &    d19d16h10e19n16n15 & 100-2 & 20-500-10556- &  3.0165 &   0.112 ± 0.047 &   0.088 ± 0.052 \\
\hline
\end{tabular}
\label{Experiment1-v2}\caption{Edge betweenness approximation with a graph neural network experiment using 28 discrete ranges}
\end{table} 

The best model is the one trained for 20 epochs, with a dataset split of 200, 3000 and 10556 train, validation and testing number of samples respectively. It attains a 34.3\% of accuracy as well as a 31.2\% f1-score macro averaged. 


\subsection{Experiment 2}


\input{./tables/v1_results.tex}


% list of each model in the table, with the parameters and the training procedure
The best models that have been trained in with the v1 dataset are, in order of appearance in the table:
\begin{itemize}
 \item and a Multi-layer perceptron with 3 fully connected layers with 94, 20 and 15 hidden units, trained on the bag-of-words embedding and the topological features
  \item and a Multi-layer perceptron with 4 fully connected layers with 94, 10, 10 and 5 hidden units, trained on the bag-of-words embedding and the topological features
  \item and a Multi-layer perceptron with 5 fully connected layers with 94, 10, 10, 5 and 5 hidden units,  trained on the bag-of-words embedding and the topological features
  \item and a Multi-layer perceptron with 3 fully connected layers with 17, 20 and 15 hidden units,  trained on the bag-of-words embedding and the topological features
  \item and a Multi-layer perceptron with 5 fully connected layers with 94, 10, 10, 5 and 5 hidden units, trained on the topological features and code attributes
  \item an XGBoost with a gbtree booster and a maximum depth of 150, trained on the bag-of-words embedding and the topological features
  \item a Random forest with 4 estimators and a maximum depth of 150,  trained on the bag-of-words embedding and the topological features
  \item a Random forest with 4 estimators and a maximum depth of 8, trained on the topological features and code attributes
  \item an XGBoost with a gbtree booster and a maximum depth of 150, trained on the topological features only
  \item a Random forest with 16 estimators and a maximum depth of 150, trained on the topological features only
  \item a Graph Isomorphism Network with 4 embedding layers, 128 hidden units, a batch size of 128, a learning rate of 0.005, a weight decay of 5e-4 and 100 epochs
  \item a Gated Graph Neural Network with 1 embedding layer with mean aggregator, 2 fully connected layers of 30 and 20 hidden units, using batch size of 16, a learning rate of 0.001 and a weight decay of 5e-4 and trained during 50 epochs.
  

\end{itemize}


\input{./tables/v3_results.tex}


The best models that have been trained in with the v3 dataset are:
\begin{itemize}
    \item and a Multi-layer perceptron with 3 fully connected layers with 96, 20 and 15 hidden units, trained on the bag-of-words embedding and the topological feature
    \item and a Multi-layer perceptron with 5 fully connected layers with 96, 10,10, 5 and 5 hidden units, trained on the bag-of-words embedding and the topological features
    \item and a Multi-layer perceptron with 4 fully connected layers with 96, 10, 10 and 5 hidden units, trained on the bag-of-words embedding and the topological features
    \item a Random forest with 16 estimators and a maximum depth of 8, trained on the bag-of-words embedding and the topological features
    \item an XGBoost with a gbtree booster and a maximum depth of 150, trained on the topological features and code attributes
    \item a Graph Isomorphism Network (GIN) with 2 layers and 64 hidden units plus  a fully connected layer, trained for 500 epochs only with the graph of each sample as the dataset
    \item a Random forest with 16 estimators and a maximum depth of 150, trained on the topological features and code attributes
    \item a Logistic Regression classifier with C of 1, trained with a maximum iterations of 100 in the Newton-Raphson solver algorithm, using multiclass one versus the rest type of classification regions with an L2 regularization
    \item an XGBoost with a gbtree booster and a maximum depth of 150, trained on the topological features only
    \item a Random forest with 16 estimators and a maximum depth of 150, trained on the topological features only
    \item Gated Graph Neural Network with 4 embedding layer with mean aggregator, 4 fully connected layers of 10, 5, 4 and 4 hidden units, using batch size of 16, a learning rate of 0.001 and a weight decay of 5e-4 and trained during 50 epochs.
\end{itemize}



All models have been trained by searching the best hyper-parameter setup using cross-validation. THe performance metric used is the F1-score with macro average. For neural network models, the loss is used as a 

The XGBoost and Random Forest (as well as other Logistic regression and Decision trees models) have been trained with cross-validation with 5 folds, with final retraining, with different sets of features as seen in the results table.  The library used is the Scikit-Learn Python library.

The MLP models have been trained with cross-validation and a maximum of 100 epochs, but using the early stopping mechanism to end training when the loss on the validation set starts increasing instead of decreasing, in which case the model is overfitting to the training set. For the MLP training the library used is the Pytorch Python library for deep learning.

The Graph Neural Network models, GIN and GGNN, have been trained with a longer procedure. To perform a successful hyper-parameter search, given the cost in time of epoch of training, has been split into several steps. The first step, has been to train for 5 or 10 epochs with most common models (GCN, GraphSAGE, GIN) with different learning rates, weight decays, number of hidden units, number of embedding  layers and batch size. Then, a training with 20-30 epochs has been performed with a bigger set of models (GCN, GraphSAGE, GIN, GGNN, GlobalAttention, Set2Set). Finally, with the selected model type and the selected hyper parameters, a training with different number of epochs has been performed (20, 50, 100, 200, 500 and even 1000 epochs). For each training, there is a cross-validation procedure, where for each fold combination, the selected number of epochs are used to feed the model and back propagate the result to update the weights. After all the fold combinations are trained by the number of epochs, the mean and standard deviation of the performance score is computed on the validation set as well as on the test set. The best model is selected by the best f1-score macro averaged on the different classes on the validation set.







\section{Code repository}\label{annex:github}

The code and jupyter notebooks used in this project can be found at \href{https://github.com/presmerats/GNN-Master-Thesis}{https://github.com/presmerats/GNN-Master-Thesis} .

% explain the orgranization of the code repository
%doc
%src
%dataset
%girvan-newman
%graph-classification
%function-renaming

\end{appendices} 