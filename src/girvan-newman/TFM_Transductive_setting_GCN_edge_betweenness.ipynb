{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from pprint import pprint\n",
    "import torch\n",
    "from torch_geometric.utils import scatter_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LinkMessagePassing(torch.nn.Module):\n",
    "    r\"\"\"Base class for creating message passing layers\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}_i^{\\prime} = \\gamma_{\\mathbf{\\Theta}} \\left( \\mathbf{x}_i,\n",
    "        \\square_{j \\in \\mathcal{N}(i)} \\, \\phi_{\\mathbf{\\Theta}}\n",
    "        \\left(\\mathbf{x}_i, \\mathbf{x}_j,\\mathbf{e}_{i,j}\\right) \\right),\n",
    "\n",
    "    where :math:`\\square` denotes a differentiable, permutation invariant\n",
    "    function, *e.g.*, sum, mean or max, and :math:`\\gamma_{\\mathbf{\\Theta}}`\n",
    "    and :math:`\\phi_{\\mathbf{\\Theta}}` denote differentiable functions such as\n",
    "    MLPs.\n",
    "    See `here <https://rusty1s.github.io/pytorch_geometric/build/html/notes/\n",
    "    create_gnn.html>`__ for the accompanying tutorial.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, aggr='add'):\n",
    "        super(LinkMessagePassing, self).__init__()\n",
    "        \n",
    "        # this calls will get all params of the self.message() func\n",
    "        # defined in the instance that inherits from this class\n",
    "        #  ecample def message(self, x_j, norm) -> x_j and norm\n",
    "        self.message_args = inspect.getargspec(self.message)[0][1:]\n",
    "        # with GCN this is [x_j, norm]\n",
    "        self.update_args = inspect.getargspec(self.update)[0][2:]\n",
    "        # with GCN this is []\n",
    "\n",
    "    #def propagate(self, aggr, edge_index, edge_neighbors, **kwargs):\n",
    "    #def propagate(self, aggr, edge_index, **kwargs):\n",
    "    def propagate(self, aggr, edge_neighbors, **kwargs):\n",
    "        r\"\"\"The initial call to start propagating messages.\n",
    "        Takes in an aggregation scheme (:obj:`\"add\"`, :obj:`\"mean\"` or\n",
    "        :obj:`\"max\"`), the edge indices, and all additional data which is\n",
    "        needed to construct messages and to update node embeddings.\"\"\"\n",
    "\n",
    "        assert aggr in ['add', 'mean', 'max']\n",
    "        #kwargs['edge_index'] = edge_index\n",
    "        kwargs['edge_neighbors'] = edge_neighbors\n",
    "        #print(\"self update_args: \", self.update_args)\n",
    "        \n",
    "        #print(\"self message_args: \",self.message_args)\n",
    "        #print(\"kwargs: \",kwargs)\n",
    "        size = None\n",
    "        message_args = []\n",
    "        for arg in self.message_args:\n",
    "            if arg[-2:] == '_i':\n",
    "                tmp = kwargs[arg[:-2]]\n",
    "                size = tmp.size(0)\n",
    "                message_args.append(tmp[edge_index[0]])\n",
    "            elif arg[-2:] == '_j':\n",
    "                tmp = kwargs[arg[:-2]]\n",
    "                size = tmp.size(0)\n",
    "                message_args.append(tmp[edge_index[1]]) #appends x tensors of the selected nodes in edge list\n",
    "            elif arg[-2:] == '_l':\n",
    "                # this branch is for link/edge feature based messages\n",
    "                \"\"\"\n",
    "                   create a edge_neighborhood list\n",
    "                   this lists says which edge index corresponds to neighbors of the current edge\n",
    "                   the messages passed will correspond to those of the edge_neighbors\n",
    "                  \n",
    "                   some idea would be: use the same, just change messages from links and change\n",
    "                   x features to correspond to edges, maybe add as xedge\n",
    "                   \n",
    "                   so message would be xedges[neighbor_edge_list]\n",
    "                   \n",
    "                   norm would be the same           \n",
    "                   \n",
    "                   way propagate is called changes from LinkGCNConv\n",
    "                   message and update parameteres change also\n",
    "                   \n",
    "                   maybe: the aggregate could take into account that there's 2 ends of an edge,\n",
    "                   like aggregating from each side and doing a mean \n",
    "\n",
    "                \"\"\"\n",
    "                tmp = kwargs[arg[:-2]] # this is the values of the edge betweennesses for each edge\n",
    "                size = tmp.size(0)\n",
    "                message_args.append(tmp[edge_neighbors[0]]) #appends x tensors of the selected nodes in edge list\n",
    "            else:\n",
    "                message_args.append(kwargs[arg]) # appends full norm tensor\n",
    "        #print(\"message_args: \")\n",
    "        #pprint(message_args)\n",
    "        update_args = [kwargs[arg] for arg in self.update_args]\n",
    "        \n",
    "        #print(\"update_args: \", update_args)\n",
    "        out = self.message(*message_args)\n",
    "\n",
    "        #print(\"\\n normalized messages (edge attribute) \")\n",
    "        #pprint(out)\n",
    "        #print(\"\\n edge_neighbor index used \")\n",
    "        #pprint(edge_neighbors[0])\n",
    "\n",
    "        \n",
    "        out = scatter_(aggr, out, edge_neighbors[0], dim_size=size)\n",
    "        #print(\"\\n scatter output \")\n",
    "        #pprint(out)\n",
    "\n",
    "        out = self.update(out, *update_args)\n",
    "\n",
    "        #print(\"\\n\")\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):  # pragma: no cover\n",
    "        r\"\"\"Constructs messages in analogy to :math:`\\phi_{\\mathbf{\\Theta}}`\n",
    "        for each edge in :math:`(i,j) \\in \\mathcal{E}`.\n",
    "        Can take any argument which was initially passed to :meth:`propagate`.\n",
    "        In addition, features can be lifted to the source node :math:`i` and\n",
    "        target node :math:`j` by appending :obj:`_i` or :obj:`_j` to the\n",
    "        variable name, *.e.g.* :obj:`x_i` and :obj:`x_j`.\"\"\"\n",
    "\n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out):  # pragma: no cover\n",
    "        r\"\"\"Updates node embeddings in analogy to\n",
    "        :math:`\\gamma_{\\mathbf{\\Theta}}` for each node\n",
    "        :math:`i \\in \\mathcal{V}`.\n",
    "        Takes in the output of aggregation as first argument and any argument\n",
    "        which was initially passed to :meth:`propagate`.\"\"\"\n",
    "\n",
    "        return aggr_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter_add\n",
    "#from torch_geometric.nn.conv import MessagePassing\n",
    "#from torch_geometric.nn.conv import LinkMessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "#from ..inits import glorot, zeros\n",
    "\n",
    "\n",
    "class LinkGCNConv(LinkMessagePassing):\n",
    "    r\"\"\"The graph convolutional operator from the `\"Semi-supervised\n",
    "    Classfication with Graph Convolutional Networks\"\n",
    "    <https://arxiv.org/abs/1609.02907>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{X}^{\\prime} = \\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n",
    "        \\mathbf{\\hat{D}}^{-1/2} \\mathbf{X} \\mathbf{\\Theta},\n",
    "\n",
    "    where :math:`\\mathbf{\\hat{A}} = \\mathbf{A} + \\mathbf{I}` denotes the\n",
    "    adjacency matrix with inserted self-loops and\n",
    "    :math:`\\hat{D}_{ii} = \\sum_{j=0} \\hat{A}_{ij}` its diagonal degree matrix.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        improved (bool, optional): If set to :obj:`True`, the layer computes\n",
    "            :math:`\\mathbf{\\hat{A}}` as :math:`\\mathbf{A} + 2\\mathbf{I}`.\n",
    "            (default: :obj:`False`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, improved=False, bias=True):\n",
    "        super(LinkGCNConv, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.improved = improved\n",
    "\n",
    "        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.weight)\n",
    "        zeros(self.bias)\n",
    "\n",
    "    def forward(self, x, edge_neighbors, edge_weight=None):\n",
    "        \"\"\"\n",
    "            needs to be changed to have:\n",
    "            - edge_neighborhoods\n",
    "            - xedge as features for edges\n",
    "            - aggregate function \n",
    "\n",
    "        \"\"\"\n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones(\n",
    "                (edge_neighbors.size(1), ), dtype=x.dtype, device=x.device)\n",
    "        edge_weight = edge_weight.view(-1)\n",
    "        assert edge_weight.size(0) == edge_neighbors.size(1)\n",
    "\n",
    "        edge_neighbors = add_self_loops(edge_neighbors, num_nodes=x.size(0))\n",
    "        loop_weight = torch.full(\n",
    "            (x.size(0), ),\n",
    "            1 if not self.improved else 2,\n",
    "            dtype=x.dtype,\n",
    "            device=x.device)\n",
    "        edge_weight = torch.cat([edge_weight, loop_weight], dim=0)\n",
    "\n",
    "        row, col = edge_neighbors\n",
    "        deg = scatter_add(edge_weight, row, dim=0, dim_size=x.size(0))\n",
    "        deg_inv = deg.pow(-0.5)\n",
    "        deg_inv[deg_inv == float('inf')] = 0\n",
    "\n",
    "        norm = deg_inv[row] * edge_weight * deg_inv[col]\n",
    "\n",
    "        x = torch.matmul(x, self.weight)\n",
    "        return self.propagate('add', edge_neighbors, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_l, norm):\n",
    "        return norm.view(-1, 1) * x_l\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        if self.bias is not None:\n",
    "            aggr_out = aggr_out + self.bias\n",
    "        return aggr_out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#from torch_geometric.nn import GCNConv\n",
    "#from torch_geometric.nn import LinkGCNConv\n",
    "import torch.nn as nn\n",
    "from pprint import pprint\n",
    "\n",
    "import networkx as nx\n",
    "import time\n",
    "from torch_geometric.data import DataLoader\n",
    "import importlib\n",
    "from torch_geometric.data import Data\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MyOwnDataset2():\n",
    "    def __init__(self,  root, name, transform=None, pre_transform=None):\n",
    "        f = open(name, 'rb')\n",
    "        self.data = pickle.load(f) \n",
    "        #print(self.data)\n",
    "        #print(self.data.edge_index)\n",
    "        #print(self.data.num_features)\n",
    "        self.num_features = self.data.num_features\n",
    "        self.num_classes = 1\n",
    "        self.filename = name\n",
    "        \n",
    "        # prepare edge_neighbors\n",
    "        edges_dict = {}\n",
    "        i=0\n",
    "        for edge in self.data.edge_index[0]:\n",
    "            edges_dict[i]= (self.data.edge_index[0][i],\n",
    "                            self.data.edge_index[1][i])\n",
    "            i+=1\n",
    "            \n",
    "        #print(\"\\n edges_dict:\")\n",
    "        #pprint(edges_dict)\n",
    "        #print(\"\\n\")\n",
    "        \"\"\"\n",
    "            {\n",
    "            0 : (1,3),\n",
    "            1 : (1,4),\n",
    "            2 : (2,0)\n",
    "            ...\n",
    "            }\n",
    "            \n",
    "            edge_neighbors= [[],[]]\n",
    "            for edge in edges_dict.keys():\n",
    "                for node in edges_dict[edge]:\n",
    "                    for edge2 in edges_dict.keys():\n",
    "                        if edge2 != edge and \\\n",
    "                           ( edges_dict[edge2][0] == node or \\\n",
    "                             edges_dict[edge2][1] == node ):\n",
    "                             edge_neighbors[0].append(edge)\n",
    "                             edge_neighbors[1].append(edge2)\n",
    "                             \n",
    "        \"\"\"\n",
    "        edge_neighbors= [[],[]]\n",
    "        for edge in edges_dict.keys():\n",
    "            for node in edges_dict[edge]:\n",
    "                for edge2 in edges_dict.keys():\n",
    "                    if edge2 != edge and ( edges_dict[edge2][0] == node or edges_dict[edge2][1] == node ):\n",
    "                        edge_neighbors[0].append(edge)\n",
    "                        edge_neighbors[1].append(edge2)\n",
    "        \n",
    "        self.data.edge_neighbors = torch.LongTensor(edge_neighbors)\n",
    "        \n",
    "        #print()\n",
    "        #print(\"edge_neighbors\")\n",
    "        #pprint(self.data.edge_neighbors)\n",
    "        #print()\n",
    "        #print(type(self.data.edge_neighbors))\n",
    "        #print()\n",
    "        \n",
    "        f.close()\n",
    "\n",
    "class NetLGCN1(torch.nn.Module):\n",
    "    def __init__(self, d1=16):\n",
    "        super(NetLGCN1, self).__init__()\n",
    "        self.conv1 = LinkGCNConv(1, d1)\n",
    "        self.conv2 = LinkGCNConv(d1, 1)\n",
    "        self.d1 = d1\n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_neighbors = data.x, data.edge_neighbors\n",
    "\n",
    "        x = self.conv1(x, edge_neighbors)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_neighbors)\n",
    "\n",
    "        # output as multiclass target\n",
    "        #return F.log_softmax(x, dim=1)\n",
    "        \n",
    "        # output as regression target\n",
    "        return x\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Net1-gcn(%d,%d)-gcn(%d,%d)\" % (dataset.num_features,self.d1,self.d1,\n",
    "                                               dataset.num_classes)\n",
    "\n",
    "class NetLGCN2(torch.nn.Module):\n",
    "    def __init__(self, d1=16,d2=16):\n",
    "        super(NetLGCN2, self).__init__()\n",
    "        self.conv1 = LinkGCNConv(dataset.num_features, d1)\n",
    "        self.fc1 = nn.Linear(d1, d2)\n",
    "        self.fc2 = nn.Linear(d2, dataset.num_features)\n",
    "        self.d1 = d1\n",
    "        self.d2 = d2\n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_neighbors = data.x, data.edge_neighbors\n",
    "\n",
    "        x = self.conv1(x, edge_neighbors)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # output as multiclass target\n",
    "        #return F.log_softmax(x, dim=1)\n",
    "        \n",
    "        # output as regression target\n",
    "        return x\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Net1-gcn(%d,%d)-gcn(%d,%d)\" % (dataset.num_features,self.d1,self.d1,\n",
    "                                               dataset.num_classes)\n",
    "    \n",
    "    \n",
    "class Net2(torch.nn.Module):\n",
    "    def __init__(self, d1=300,d2=100):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, d1 )\n",
    "        #self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "        self.fc1 = nn.Linear(d1, d2)\n",
    "        self.fc2 = nn.Linear(d2, dataset.num_features)\n",
    "        self.d1 = d1\n",
    "        self.d2 = d2\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # 2 fc layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # output as regression target\n",
    "        return x\n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Net2-gcn(%d,%d)-fc(%d,%d)-fc(%d,%d)\" % (dataset.num_features,self.d1,self.d1,\n",
    "                                                        self.d2,self.d2,\n",
    "                                                        dataset.num_features)\n",
    "\n",
    "    \n",
    "    \n",
    "class Net3(torch.nn.Module):\n",
    "    def __init__(self, d1=300,d2=100):\n",
    "        super(Net3, self).__init__()\n",
    "        self.conv1 = SAGEConv(dataset.num_features, d1 )\n",
    "        #self.conv2 = SAGEConv(16, dataset.num_classes)\n",
    "        self.fc1 = nn.Linear(d1, d2)\n",
    "        self.fc2 = nn.Linear(d2, dataset.num_features)\n",
    "        self.d1 = d1\n",
    "        self.d2 = d2\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # 2 fc layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # output as regression target\n",
    "        return x\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Net3-SAGEgcn(%d,%d)-fc(%d,%d)-fc(%d,%d)\" % (dataset.num_features,self.d1,self.d1,\n",
    "                                                        self.d2,self.d2,\n",
    "                                                        dataset.num_features)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def loadDataset(collection, name=None):\n",
    "    try:\n",
    "        # import datasets\n",
    "        themodule = importlib.import_module(\"torch_geometric.datasets\")\n",
    "        # get the function corresponding to collection\n",
    "        method_to_call = getattr(themodule, collection)\n",
    "        if name:\n",
    "            dataset = method_to_call(root='./data/'+str(collection), name=name)\n",
    "            dataset.filename = name\n",
    "            return dataset\n",
    "        else:\n",
    "            return method_to_call(root='./data/'+str(collection)) \n",
    "    except:\n",
    "        # custom module\n",
    "        method_to_call = globals()[collection]\n",
    "       \n",
    "        if name:\n",
    "            \n",
    "            dataset = method_to_call(root='./data/'+str(collection), name=name)\n",
    "            dataset.filename = name\n",
    "            return dataset\n",
    "        else:\n",
    "            return method_to_call(root='./data/'+str(collection)) \n",
    "        \n",
    "\n",
    "\n",
    "def transformMask(mask):\n",
    "    train_mask = []\n",
    "    i = 0\n",
    "    for pick in mask:\n",
    "        if pick[0]==1:\n",
    "            train_mask.append(i)\n",
    "        i+=1\n",
    "    return train_mask\n",
    "\n",
    "\n",
    "def shuffleTrainTestMasks(data, trainpct = 0.7):\n",
    "    ysize = list(data.y.size())[0]\n",
    "    data.train_mask = torch.zeros(ysize,1, dtype=torch.long)\n",
    "    data.train_mask[int(ysize*trainpct):] = 1\n",
    "    data.train_mask = data.train_mask[torch.randperm(ysize)]\n",
    "    data.test_mask = torch.ones(ysize,1, dtype=torch.long) - data.train_mask\n",
    "    \n",
    "    data.train_mask = transformMask(data.train_mask)\n",
    "    data.test_mask = transformMask(data.test_mask)\n",
    "  \n",
    "\n",
    "def shuffleTrainTestValMasks(data, trainpct = 0.7, valpct = 0.2):\n",
    "\n",
    "    ysize = list(data.y.size())[0]\n",
    "    #print(\"total \", ysize)\n",
    "    #print(\" train \",int(ysize*trainpct)-int(ysize*trainpct*valpct))\n",
    "    #print(\" val \",int(ysize*trainpct*valpct))\n",
    "    #print(\" test \",int(ysize*(1- trainpct) ))\n",
    "    data.train_mask = torch.zeros(ysize,1, dtype=torch.long)\n",
    "    data.train_mask[:int(ysize*trainpct)] = 1\n",
    "    data.train_mask = data.train_mask[torch.randperm(ysize)]\n",
    "    #print(\" train sum \",data.train_mask.sum())\n",
    "    data.test_mask = torch.ones(ysize,1, dtype=torch.long) - data.train_mask\n",
    "    #print(\" test sum \",data.test_mask.sum())\n",
    "    \n",
    "    # transform to list of indexes\n",
    "    data.train_mask = transformMask(data.train_mask)\n",
    "    data.test_mask = transformMask(data.test_mask)\n",
    "    \n",
    "    data.val_mask = data.train_mask[:int(ysize*trainpct*valpct)]\n",
    "    data.train_mask = data.train_mask[int(ysize*trainpct*valpct):]\n",
    "\n",
    "    \n",
    "    #print(data.train_mask)\n",
    "    #print(data.val_mask)\n",
    "    #print(data.test_mask)\n",
    "    \n",
    "    \n",
    "\n",
    "def trainTestEval(dataset, epochs=1, batch_size=32):\n",
    "    global Net\n",
    "    loader = DataLoader(dataset,  shuffle=False)\n",
    "    i = 0\n",
    "    #print(loader)\n",
    "    #print(dir(loader))\n",
    "    \n",
    "    G = dataset.data\n",
    "    print(G)\n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    # 1.  prepare model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #print(\"using \",device)\n",
    "    model = Net.to(device)  \n",
    "    data = G.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    model.train()\n",
    "\n",
    "    # 2.  create a train_mask, and a test_mask (val_mask for further experiments)\n",
    "    #shuffleTrainTestMasks(data)\n",
    "    #shuffleTrainTestValMasks(data)\n",
    "    shuffleTrainTestMasks(data)\n",
    "\n",
    "    # 3. train some epochs\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.mse_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 25 == 0 :\n",
    "            print(\"epoch-loss: \",epoch, loss)\n",
    "\n",
    "    # 4. Model evaluation\n",
    "    model.eval()\n",
    "    #  classification in a multiclass setting\n",
    "    #_, pred = model(data).max(dim=1)\n",
    "    #correct = pred[data.test_mask].eq(data.y[data.test_mask]).sum().item()\n",
    "    #acc = correct / data.test_mask.sum().item()\n",
    "    #print('Accuracy: {:.4f}'.format(acc))\n",
    "\n",
    "\n",
    "    # regression \n",
    "    pred = model(data)\n",
    "    #print(\"target: \",data.y[data.test_mask])\n",
    "    #print(\"prediction: \",pred[data.test_mask])\n",
    "    #print(pred[data.test_mask].type())\n",
    "    #print(data.y[data.test_mask].type())\n",
    "    \n",
    "    # prepare the normalized mean root squared error\n",
    "    t = data.y[data.test_mask]\n",
    "    y = pred[data.test_mask]\n",
    "    nrmse = torch.sum((t - y) ** 2)/len(data.test_mask)\n",
    "    nrmse = nrmse.sqrt()\n",
    "    print(\"RMSE: \",nrmse)\n",
    "\n",
    "    #m = torch.mean(t)\n",
    "    #print(\"mean\",m)\n",
    "    #tmax = torch.max(t)\n",
    "    #tmin = torch.min(t)\n",
    "    #sd = tmax-tmin\n",
    "    #print(\"sd\",sd)\n",
    "    #nrmse = (nrmse - m)/sd\n",
    "    #print(\"NRMSE:\",nrmse)\n",
    "\n",
    "\n",
    "    endtime = time.time()\n",
    "    print(\"Total train-test time: \"+str(endtime-start))\n",
    "    \n",
    "    with open(\"results.txt\",\"a\") as f:\n",
    "        #print(dir(dataset))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(str(model)+\" \" \n",
    "                +str(dataset.filename)+\" \"  \n",
    "                +\"nrmse: \"+str(nrmse.item())+\" \" \n",
    "                +\"total time: \"+str(endtime-start) \n",
    "                +\" negative vals?: \"+str(False) \n",
    "                +\"\\n\"\n",
    "               )\n",
    "    \n",
    "    del model\n",
    "\n",
    "    #i+=1\n",
    "    #if i==1:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 7], x=[7, 1], y=[7])\n",
      "tensor([[0, 0, 1, 1, 1, 2, 3],\n",
      "        [1, 2, 2, 3, 4, 4, 4]])\n",
      "Data(edge_index=[2, 7], edge_neighbors=[2, 28], x=[7, 1], y=[7])\n",
      "epoch-loss:  0 tensor(0.9520, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "RMSE:  tensor(0.9339, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Total train-test time: 1.9290800094604492\n"
     ]
    }
   ],
   "source": [
    "#dataset = loadDataset(collection='MyOwnDataset2', name='precomputed/er_10_0_10_nb.pickle')\n",
    "dataset = MyOwnDataset2(\n",
    "    root='', \n",
    "    name='precomputed/er_5_0_45_eb.pickle')\n",
    "#print(dir(dataset.data))\n",
    "#print()\n",
    "global Net\n",
    "Net=Net1(d1=5)\n",
    "trainTestEval(dataset,  epochs=1)\n",
    "del Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 7], edge_neighbors=[2, 28], x=[7, 1], y=[7])\n",
      "epoch-loss:  0 tensor(0.3592, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  25 tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  50 tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  75 tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  100 tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  125 tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  150 tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  175 tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "RMSE:  tensor(0.1227, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Total train-test time: 0.541536808013916\n"
     ]
    }
   ],
   "source": [
    "#dataset = loadDataset(collection='MyOwnDataset2', name='precomputed/er_10_0_10_nb.pickle')\n",
    "dataset = MyOwnDataset2(\n",
    "    root='', \n",
    "    name='precomputed/er_5_0_45_eb.pickle')\n",
    "#print(dir(dataset.data))\n",
    "#print()\n",
    "global Net\n",
    "Net=Net1(d1=55)\n",
    "trainTestEval(dataset,  epochs=200)\n",
    "del Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 7], edge_neighbors=[2, 28], x=[7, 1], y=[7])\n",
      "epoch-loss:  0 tensor(0.0720, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  25 tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  50 tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  75 tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  100 tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  125 tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  150 tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  175 tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "RMSE:  tensor(0.0835, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Total train-test time: 0.5560200214385986\n"
     ]
    }
   ],
   "source": [
    "dataset = MyOwnDataset2(\n",
    "    root='', \n",
    "    name='precomputed/er_5_0_45_eb.pickle')\n",
    "global Net\n",
    "Net=Net1(d1=55)\n",
    "trainTestEval(dataset,  epochs=200)\n",
    "del Net\n",
    "\n",
    "# RMSE is between 15% adn 8% in a transductive setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 16], edge_neighbors=[2, 88], x=[16, 1], y=[16])\n",
      "epoch-loss:  0 tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  25 tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  50 tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  75 tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  100 tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  125 tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  150 tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  175 tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  200 tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  225 tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  250 tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  275 tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  300 tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  325 tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  350 tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  375 tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "RMSE:  tensor(0.2818, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Total train-test time: 1.0754420757293701\n"
     ]
    }
   ],
   "source": [
    "dataset = MyOwnDataset2(\n",
    "    root='', \n",
    "    name='precomputed/TUDataset_PROTEINS_996_eb.pickle')\n",
    "global Net\n",
    "Net=NetLGCN2(d1=250,d2=50)\n",
    "trainTestEval(dataset,  epochs=400)\n",
    "del Net"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-pytorch",
   "language": "python",
   "name": "gnn-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
