{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN in a transductive setting for Node betweenness\n",
    "This notebook shows how a GCN/GraphSAGE model is trained to compute Node betweenness centrality on different graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from torch.nn import *\n",
    "from TFM_edge_betweenness_model import META1\n",
    "from TFM_node_betweenness_training import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Selected graphs for HP search\n",
    "\n",
    "Graphs with higher number of node betweenness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "def get_planetoid_dataset(root,name, normalize_features=False, transform=None):\n",
    "    #path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', name)\n",
    "    dataset = Planetoid(root, name)\n",
    "\n",
    "    if transform is not None and normalize_features:\n",
    "        dataset.transform = T.Compose([T.NormalizeFeatures(), transform])\n",
    "    elif normalize_features:\n",
    "        dataset.transform = T.NormalizeFeatures()\n",
    "    elif transform is not None:\n",
    "        dataset.transform = transform\n",
    "\n",
    "    return dataset\n",
    "\n",
    "#dataset1 = TUDataset(root='temp/'+thename, name='REDDIT-BINARY')\n",
    "dataset = get_planetoid_dataset(root='temp/planetoid',name='Cora', normalize_features=True)\n",
    "#inspectGraphDataset(dataset, thename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Benchmark train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch_geometric.nn import SGConv, APPNP, ChebConv, GATConv\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def index_to_mask(index, size):\n",
    "    mask = torch.zeros(size, dtype=torch.uint8, device=index.device)\n",
    "    mask[index] = 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "def random_planetoid_splits(data, num_classes):\n",
    "    # Set new random planetoid splits:\n",
    "    # * 20 * num_classes labels for training\n",
    "    # * 500 labels for validation\n",
    "    # * 1000 labels for testing\n",
    "\n",
    "    indices = []\n",
    "    for i in range(num_classes):\n",
    "        index = (data.y == i).nonzero().view(-1)\n",
    "        index = index[torch.randperm(index.size(0))]\n",
    "        indices.append(index)\n",
    "\n",
    "    train_index = torch.cat([i[:20] for i in indices], dim=0)\n",
    "\n",
    "    rest_index = torch.cat([i[20:] for i in indices], dim=0)\n",
    "    rest_index = rest_index[torch.randperm(rest_index.size(0))]\n",
    "\n",
    "    data.train_mask = index_to_mask(train_index, size=data.num_nodes)\n",
    "    data.val_mask = index_to_mask(rest_index[:500], size=data.num_nodes)\n",
    "    data.test_mask = index_to_mask(rest_index[500:1500], size=data.num_nodes)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def run(dataset,\n",
    "        model,\n",
    "        runs,\n",
    "        epochs,\n",
    "        lr,\n",
    "        weight_decay,\n",
    "        early_stopping,\n",
    "        permute_masks=None,\n",
    "        logger=None):\n",
    "\n",
    "    val_losses, accs, durations = [], [], []\n",
    "    for _ in range(runs):\n",
    "        data = dataset[0]\n",
    "        if permute_masks is not None:\n",
    "            data = permute_masks(data, dataset.num_classes)\n",
    "        data = data.to(device)\n",
    "\n",
    "        model.to(device).reset_parameters()\n",
    "        optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        t_start = time.perf_counter()\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        test_acc = 0\n",
    "        val_loss_history = []\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train(model, optimizer, data)\n",
    "            eval_info = evaluate(model, data)\n",
    "            eval_info['epoch'] = epoch\n",
    "\n",
    "            if logger is not None:\n",
    "                logger(eval_info)\n",
    "\n",
    "            if eval_info['val_loss'] < best_val_loss:\n",
    "                best_val_loss = eval_info['val_loss']\n",
    "                test_acc = eval_info['test_acc']\n",
    "\n",
    "            val_loss_history.append(eval_info['val_loss'])\n",
    "            if early_stopping > 0 and epoch > epochs // 2:\n",
    "                tmp = tensor(val_loss_history[-(early_stopping + 1):-1])\n",
    "                if eval_info['val_loss'] > tmp.mean().item():\n",
    "                    break\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        t_end = time.perf_counter()\n",
    "\n",
    "        val_losses.append(best_val_loss)\n",
    "        accs.append(test_acc)\n",
    "        durations.append(t_end - t_start)\n",
    "\n",
    "    loss, acc, duration = tensor(val_losses), tensor(accs), tensor(durations)\n",
    "\n",
    "    print('Val Loss: {:.4f}, Test Accuracy: {:.3f} ± {:.3f}, Duration: {:.3f}'.\n",
    "          format(loss.mean().item(),\n",
    "                 acc.mean().item(),\n",
    "                 acc.std().item(),\n",
    "                 duration.mean().item()))\n",
    "    with open('preliminary_semisuperv.csv','a') as f:\n",
    "        if 'conv1' in dir(model):\n",
    "            f.write('{}, {}, {:.4f}, {:.3f} ± {:.3f}, {:.3f}\\n'.\n",
    "              format(\n",
    "                     model.conv1.__class__.__name__, \n",
    "                     str(runs)+'_epochs='+str(epochs),\n",
    "                     loss.mean().item(),\n",
    "                     acc.mean().item(),\n",
    "                     acc.std().item(),\n",
    "                     duration.mean().item()))\n",
    "        else:\n",
    "            f.write('{}, {}, {:.4f}, {:.3f} ± {:.3f}, {:.3f}\\n'.\n",
    "              format(\n",
    "                     model.__class__.__name__, \n",
    "                     str(runs)+'_epochs='+str(epochs),\n",
    "                     loss.mean().item(),\n",
    "                     acc.mean().item(),\n",
    "                     acc.std().item(),\n",
    "                     duration.mean().item()))\n",
    "            \n",
    "\n",
    "def train(model, optimizer, data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def evaluate(model, data):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(data)\n",
    "\n",
    "    outs = {}\n",
    "    for key in ['train', 'val', 'test']:\n",
    "        mask = data['{}_mask'.format(key)]\n",
    "        loss = F.nll_loss(logits[mask], data.y[mask]).item()\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "\n",
    "        outs['{}_loss'.format(key)] = loss\n",
    "        outs['{}_acc'.format(key)] = acc\n",
    "\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.8864, Test Accuracy: 0.789 ± 0.018, Duration: 1.091\n"
     ]
    }
   ],
   "source": [
    "import argparse \n",
    "\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('--random_splits', type=bool, default=False)\n",
    "#parser.add_argument('--runs', type=int, default=100)\n",
    "#parser.add_argument('--epochs', type=int, default=200)\n",
    "#parser.add_argument('--lr', type=float, default=0.01)\n",
    "#parser.add_argument('--weight_decay', type=float, default=0.0005)\n",
    "#parser.add_argument('--early_stopping', type=int, default=10)\n",
    "#parser.add_argument('--hidden', type=int, default=16)\n",
    "#parser.add_argument('--dropout', type=float, default=0.5)\n",
    "#parser.add_argument('--normalize_features', type=bool, default=True)\n",
    "#args = parser.parse_args()    \n",
    "    \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)  \n",
    "\n",
    "permute_masks = random_planetoid_splits \n",
    "run(dataset, Net(dataset), 100, 200, 0.01, 0.0005,\n",
    "    10, permute_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.7587, Test Accuracy: 0.790 ± 0.018, Duration: 0.585\n"
     ]
    }
   ],
   "source": [
    "#SGConv\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = SGConv(\n",
    "            dataset.num_features, dataset.num_classes, K=3, cached=True)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "\n",
    "permute_masks = random_planetoid_splits \n",
    "run(dataset, Net(dataset), 100, 200, 0.01, 0.0005,\n",
    "    10, permute_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.8133, Test Accuracy: 0.769 ± 0.027, Duration: 5.049\n"
     ]
    }
   ],
   "source": [
    "#Chebconv\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = ChebConv(dataset.num_features, 16, 3)\n",
    "        self.conv2 = ChebConv(16, dataset.num_classes, 3)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "\n",
    "permute_masks = random_planetoid_splits \n",
    "run(dataset, Net(dataset), 100, 200, 0.01, 0.0005,\n",
    "    10, permute_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.8894, Test Accuracy: 0.808 ± 0.017, Duration: 0.984\n"
     ]
    }
   ],
   "source": [
    "#APPNPN\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin1 = Linear(dataset.num_features, 16)\n",
    "        self.lin2 = Linear(16, dataset.num_classes)\n",
    "        self.prop1 = APPNP(3, 0.1)\n",
    "        self.conv1 = APPNP(3, 0.1) # for reporting only\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        x = self.prop1(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "permute_masks = random_planetoid_splits \n",
    "run(dataset, Net(dataset), 100, 200, 0.01, 0.0005,\n",
    "    10, permute_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.8111, Test Accuracy: 0.803 ± 0.016, Duration: 1.967\n"
     ]
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GATConv(\n",
    "            dataset.num_features,\n",
    "            16,\n",
    "            heads=8,\n",
    "            dropout=0.5)\n",
    "        self.conv2 = GATConv(\n",
    "            16 * 8,\n",
    "            dataset.num_classes,\n",
    "            heads=8,\n",
    "            concat=False,\n",
    "            dropout=0.5)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    \n",
    "permute_masks = random_planetoid_splits \n",
    "run(dataset, Net(dataset), 100, 200, 0.01, 0.0005,\n",
    "    10, permute_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.read_csv('preliminary_semisuperv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>params</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGConv</td>\n",
       "      <td>100_epochs=200</td>\n",
       "      <td>1.7587</td>\n",
       "      <td>0.790 ± 0.018</td>\n",
       "      <td>0.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChebConv</td>\n",
       "      <td>100_epochs=200</td>\n",
       "      <td>0.8133</td>\n",
       "      <td>0.769 ± 0.027</td>\n",
       "      <td>5.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APPNP</td>\n",
       "      <td>100_epochs=200</td>\n",
       "      <td>0.8894</td>\n",
       "      <td>0.808 ± 0.017</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GATConv</td>\n",
       "      <td>100_epochs=200</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.803 ± 0.016</td>\n",
       "      <td>1.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCNConv</td>\n",
       "      <td>100_epochs=200</td>\n",
       "      <td>0.8864</td>\n",
       "      <td>0.789 ± 0.018</td>\n",
       "      <td>1.091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model           params   Val Loss   Test Accuracy   Duration\n",
       "0    SGConv   100_epochs=200     1.7587   0.790 ± 0.018      0.585\n",
       "1  ChebConv   100_epochs=200     0.8133   0.769 ± 0.027      5.049\n",
       "2     APPNP   100_epochs=200     0.8894   0.808 ± 0.017      0.984\n",
       "3   GATConv   100_epochs=200     0.8111   0.803 ± 0.016      1.967\n",
       "4   GCNConv   100_epochs=200     0.8864   0.789 ± 0.018      1.091"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{llrlr}\\n\\\\toprule\\n    Model &           params &   Val Loss &   Test Accuracy &   Duration \\\\\\\\\\n\\\\midrule\\n   SGConv &   100\\\\_epochs=200 &     1.7587 &   0.790 ± 0.018 &      0.585 \\\\\\\\\\n ChebConv &   100\\\\_epochs=200 &     0.8133 &   0.769 ± 0.027 &      5.049 \\\\\\\\\\n    APPNP &   100\\\\_epochs=200 &     0.8894 &   0.808 ± 0.017 &      0.984 \\\\\\\\\\n  GATConv &   100\\\\_epochs=200 &     0.8111 &   0.803 ± 0.016 &      1.967 \\\\\\\\\\n  GCNConv &   100\\\\_epochs=200 &     0.8864 &   0.789 ± 0.018 &      1.091 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.to_latex(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-89e6c98d9288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-pytorch",
   "language": "python",
   "name": "gnn-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
