{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPNN for edge betweenness\n",
    "\n",
    "The notebook will train a model to compute edge betweenness of edges of a graph, in an inductive setting allowing for generalization to unseen graphs.\n",
    "This model will be used to predict edge betweenness inside the Girvan-Newman algorithm by networkx library.\n",
    "Steps:\n",
    "1. get a dataset to detect community in\n",
    "2. train an edge classifier (not node) for edge betweenness\n",
    "3. save this model to disk\n",
    "4. load this model and predict edge betweenness on unseen graphs\n",
    "5. use networkx Girvan-Newman algorithm with a replacement for best edge selection routine, a replacmenet that loads the model and predict edge betweenness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Dataset\n",
    "\n",
    "## 1.1 datasets available:\n",
    "multiple graphs in wihch we can compute edge betweenness\n",
    "Choice: MUTAG, ENZYMES, PROTEINS...\n",
    "\n",
    "## 1.2 target:\n",
    "we need the edge betweenness of each edge,  which we can compute with networkx for example\n",
    "\n",
    "## 1.3 dataset creation\n",
    "1. get the graphs from MUTAG\n",
    "2. transform to networkx\n",
    "3. compute the edge betweenness\n",
    "4. save to networkx graph format\n",
    "5. transform to PyTorch_Geometric dataset\n",
    "6. pass this dataset to model training task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Model \n",
    "\n",
    "## 2.1 Choice of the graph neural network\n",
    "Choose or create a GNN that \n",
    "1. considers and __predicts__ edge features!\n",
    "2. works in an inductive setting (predicts on unseen graphs)\n",
    "\n",
    "Ideas:\n",
    "- Link prediction algorithm\n",
    "- Link prediction algorithm modified?\n",
    "- MPNN\n",
    "- GraphSAGE modified?\n",
    "- Graph Network (DeepMind)\n",
    "\n",
    "models allowing edge features:\n",
    "- GNN\n",
    "- MPNN\n",
    "- DCNN\n",
    "- PATCHY-SAN\n",
    "- DGCNN [Deep Graph Convolutional Neural Network](https://www.groundai.com/project/link-prediction-based-on-graph-neural-networks/)\n",
    "- EGNNA\n",
    "\n",
    "other ideas:\n",
    "- model modif -> predict values edges\n",
    "    - betweenness associated to shortedst path -> features nodes not needed for example\n",
    "    - take a look at link prediction algorithms..\n",
    "- maybe node features are also useful..\n",
    "    - set a feature vector with a real value for each edge of a node\n",
    "    - predict that feature vector **STRANGE Multiple regression..**\n",
    "- change the model:\n",
    "    - edges with their associated edge neighbors -> edge adjacency matrix\n",
    "    - COMBINE function combines ehv + ehn n in EN(v) EN(v)=\"Edge Neighborhood of edge v\"\n",
    "- additional node in each edge\n",
    "- transform nodes to edges **IMPOSSIBLE?**\n",
    "- min betweens in both vertex=edge betweenness **WRONG**\n",
    " \n",
    "\n",
    "## 2.2 Implementation\n",
    "Available implementation or build. PyTorchGeometric seems a good tool to implement models..\n",
    "\n",
    "\n",
    "## 2.3 Hyperparameter search\n",
    "Which hyperparams to search for optimal performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Modify Girvan-Newman\n",
    "\n",
    "Modify the Girvan-Newman algorithm by calling a new function that:\n",
    "    1. loads the GNN model from disk\n",
    "    2. predicts the edge betweenness of all edges of a graph\n",
    "    3. ranks the edges according to that edge betweenness\n",
    "The rest is already taken car by networkx.\n",
    "\n",
    "Time the improvement: time original and new Girvan-Newman execution and see difference in times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def loadDataset(collection, name=None):\n",
    "    # import datasets\n",
    "    themodule = importlib.import_module(\"torch_geometric.datasets\")\n",
    "    # get the function corresponding to collection\n",
    "    method_to_call = getattr(themodule, collection)\n",
    "    if name:\n",
    "        return method_to_call(root='./data/'+str(collection), name=name)\n",
    "    else:\n",
    "        return method_to_call(root='./data/'+str(collection)) \n",
    "\n",
    "    \n",
    "def writeAdjacencyMatrixToDisk(G, filename='temp_adjacency_matrix.txt'):\n",
    "    \"\"\"\n",
    "        Transform to networkx dataset\n",
    "\n",
    "        possible formats: GML, Adjacency matrix, ..\n",
    "        start by Adjcency list \n",
    "             --> (ignoring edge/node features)\n",
    "             --> line format: source target target2 target3 ... \n",
    "        later we can improve this...\n",
    "    \"\"\"\n",
    "    f = open(filename,'w')\n",
    "    _ni=-1\n",
    "    newline = False\n",
    "    theline = []\n",
    "    careturn = \"\"\n",
    "    for ei in range(G.edge_index.size()[1]):\n",
    "        if int(G.edge_index[0,ei].item()) != _ni:\n",
    "            newline=True\n",
    "            _ni=int(G.edge_index[0,ei].item())\n",
    "            \n",
    "        else:\n",
    "            newline=False\n",
    "            \n",
    "            \n",
    "        ni = str(G.edge_index[0,ei].item())\n",
    "        vi = str(G.edge_index[1,ei].item())\n",
    "        if newline:\n",
    "            f.write(''.join(theline))\n",
    "            #print(''.join(theline))\n",
    "            #print(\" --> \"+str(_ni))\n",
    "            theline =[]\n",
    "            theline.append(careturn+ni+\" \")\n",
    "            theline.append(vi+\" \")\n",
    "            careturn = \"\\n\"\n",
    "        else:\n",
    "            theline.append(vi+\" \")\n",
    "        # print(\"({},{})\".format(ni,vi))\n",
    "    \n",
    "    \n",
    "def nx_createNxGraphInMem(G):\n",
    "    \"\"\"\n",
    "        Transform to networkx dataset\n",
    "\n",
    "        possible formats: GML, Adjacency matrix, ..\n",
    "        start by Adjcency list \n",
    "             --> (ignoring edge/node features)\n",
    "             --> line format: source target target2 target3 ... \n",
    "        later we can improve this...\n",
    "    \"\"\"\n",
    "    g = nx.MultiGraph()\n",
    "   \n",
    "    for ei in range(G.edge_index.size()[1]):    \n",
    "        ni = str(G.edge_index[0,ei].item())\n",
    "        vi = str(G.edge_index[1,ei].item())\n",
    "        g.add_edge(ni,vi)\n",
    "    return g\n",
    "    \n",
    "def nx_verifyEdges(G, g):\n",
    "    for ei in range(G.edge_index.size()[1]):\n",
    "        ni = str(G.edge_index[0,ei].item())\n",
    "        vi = str(G.edge_index[1,ei].item())\n",
    "        if (ni,vi,0) not in list(g.edges):\n",
    "            if (vi,ni,1) not in list(g.edges):\n",
    "                print(\"Error {} not in networkx graph\".format((ni,vi)))\n",
    "            \n",
    "        \n",
    "\n",
    "def nx_compute_edge_betweenness(G):\n",
    "    \n",
    "    print(list(G.edges)[:10])\n",
    "    G_components = nx.connected_component_subgraphs(G)\n",
    "    G_mc = list(G_components)[0]  \n",
    "    eb_dict_res = {}\n",
    "    eb_dict = nx.edge_betweenness_centrality(G_mc)\n",
    "    \n",
    "    # if there are more connected components...\n",
    "    if len(list(G_components))>1:\n",
    "        print(\"connected components: \",len(list(G_components)))\n",
    "    \n",
    "    eb_dict_res.update(eb_dict)\n",
    "    \n",
    "        \n",
    "    return eb_dict_res\n",
    "\n",
    "\n",
    "def update_edge_betweenness(G, eb_dict):\n",
    "    \"\"\"\n",
    "        G.edge_attr must contain the edge betweenness values \n",
    "        for each edge\n",
    "        \n",
    "        G.y must contain it also.. (it is a copy of the edge betweenness..)\n",
    "        this could help the training phase\n",
    "        \n",
    "        Size restrictions:\n",
    "        - Given the size of the graphs, is it better to just transform the \n",
    "        object instead to write a new one?\n",
    "        - also just use G.y? but for GNN algorithms..not sure\n",
    "        \n",
    "        new_edg_attr will be size [num edges, 1]\n",
    "        and must be sorted in accordance to G.edge_index\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    new_edg_attr = []\n",
    "    for i in range(len(G.edge_index[0])):\n",
    "        ni = G.edge_index[0][i]\n",
    "        vi = G.edge_index[1][i]\n",
    "        \n",
    "        if ni and vi:\n",
    "            ni=str(ni.item())\n",
    "            vi=str(vi.item())\n",
    "            #print((ni,vi))\n",
    "            try:\n",
    "                new_edg_attr.append([eb_dict[(ni,vi)]])\n",
    "            except:\n",
    "                try:\n",
    "                    new_edg_attr.append([eb_dict[(vi,ni)]])\n",
    "                except:\n",
    "                    #print(\"ERROR {} and {} not found!\".format((ni,vi),(vi,ni)))\n",
    "                    new_edg_attr.append([0])\n",
    "        else:\n",
    "            new_edg_attr.append([0])\n",
    "\n",
    "    new_edg_attr = torch.FloatTensor(new_edg_attr)\n",
    "    \n",
    "    #newG = Data(\n",
    "    #    x=G.x, \n",
    "    #    edge_index=G.edge_index, \n",
    "    #    edge_attr=new_edg_attr,\n",
    "    #    y=new_edg_attr)\n",
    "    \n",
    "    #G.edge_attr = new_edg_attr\n",
    "    G.y = new_edg_attr\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENZYMES(600)\n",
      "\n",
      " data:  Data(edge_index=[2, 74564], x=[19580, 3], y=[600])\n",
      "Batch(batch=[1069], edge_index=[2, 4264], x=[1069, 3], y=[32])\n",
      "[('0', '1'), ('0', '2'), ('0', '3'), ('1', '2'), ('1', '3'), ('1', '24'), ('1', '27'), ('2', '3'), ('2', '27'), ('2', '28')]\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "tensor([9.8498])\n",
      "tensor([[   0,    0,    0,  ..., 1068, 1068, 1068],\n",
      "        [   1,    2,    3,  ..., 1051, 1052, 1067]])\n",
      "Batch(batch=[1069], edge_index=[2, 4264], x=[1069, 3], y=[4264, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch_geometric.data import DataLoader\n",
    "import networkx as nx\n",
    "\n",
    "# load the dataset examples---------------------------------------\n",
    "#PPI\n",
    "#dataset = loadDataset('PPI')\n",
    "#QM7b\n",
    "#dataset = loadDataset('QM7b')\n",
    "#MUTAG\n",
    "#dataset = loadDataset(collection='Entities',name='MUTAG')\n",
    "#ENZYMES FROM TUDataset\n",
    "dataset = loadDataset(collection='TUDataset',name='ENZYMES')\n",
    "\n",
    "print(dataset)\n",
    "print(\"\\n data: \",dataset.data) # many graphs!\n",
    "#print(\"\\n num_features: \",dataset.num_features)\n",
    "#print(\"\\n num_classes: \",dataset.num_classes)\n",
    "\n",
    "# read graphs------------------------------------------------------\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "i = 0\n",
    "prefix = 'temp_aj_m'\n",
    "for G in loader:\n",
    "    print(G)\n",
    "    \n",
    "    # Transform to networkx graph-----------------------------------\n",
    "    # write to adjacency matrix on disk\n",
    "    writeAdjacencyMatrixToDisk(G, filename=prefix+str(i)+'.txt')\n",
    "    \n",
    "    # load into a networkx graph object\n",
    "    g2 = nx.read_adjlist(prefix+str(i)+'.txt')\n",
    "    #g2 = nx_createNxGraphInMem(G)\n",
    "    \n",
    "    # compute edge betweenness--------------------------------------\n",
    "    eb_dict = nx_compute_edge_betweenness(g2)\n",
    "    \n",
    "    # write edge betweenness back to PyTorch Geometric graph--------\n",
    "    # 6 edge_betweenneess are missing\n",
    "    G = update_edge_betweenness(G,eb_dict)\n",
    "    \n",
    "    #print(dir(G))\n",
    "    print(G.y)\n",
    "    print(sum(G.y)) # so G.y is not all zeroes\n",
    "    print(G.edge_index)\n",
    "    print(G)\n",
    "    \n",
    "    i+=1\n",
    "    if i==1:\n",
    "        break\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encapsulate these functionalities into a Python module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "- Link prediction algorithm\n",
    "- Link prediction algorithm modified?\n",
    "- MPNN\n",
    "- GraphSAGE modified?\n",
    "- Graph Network (DeepMind)\n",
    "\n",
    "models allowing edge features:\n",
    "- GNN\n",
    "- MPNN\n",
    "- DCNN\n",
    "- PATCHY-SAN\n",
    "- DGCNN [Deep Graph Convolutional Neural Network](https://www.groundai.com/project/link-prediction-based-on-graph-neural-networks/)\n",
    "- EGNNA\n",
    "\n",
    "other ideas:\n",
    "- additional node in each edge -> **NO SENSE**\n",
    "- transform nodes to edges **IMPOSSIBLE?**\n",
    "- min betweens in both vertex=edge betweenness **WRONG**\n",
    "- model modif -> predict values edges\n",
    "    - betweenness associated to shortedst path -> features nodes not needed for example\n",
    "    - take a look at link prediction algorithms..\n",
    "- maybe node features are also useful..\n",
    "    - set a feature vector with a real value for each edge of a node\n",
    "    - predict that feature vector **STRANGE Multiple regression..**\n",
    "- change the model Link Conv Network:\n",
    "    - edges with their associated edge neighbors -> edge adjacency matrix\n",
    "    - COMBINE function combines ehv + ehn n in EN(v) EN(v)=\"Edge Neighborhood of edge v\"\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link convolutional network idea:\n",
    "\n",
    "#### Edge adjacency matrix: \n",
    "it's more a python dictionary, where for each edge there are other edges listed. It's symmetric\n",
    "`\n",
    "show by code with nx and PyTorchGeom\n",
    "`\n",
    "#### Edge neighborhood:\n",
    "extracted from the Edge adjacency matrix\n",
    "\n",
    "#### Embedding generation algorithm:\n",
    "\n",
    "Adaptation from the GraphSAGE algorithm:\n",
    "\n",
    "Initialization: \n",
    "x(u,v) contains the features of the edge.\n",
    "If no features are considered? Well at least the weight of the link must be present. So in cases there is no weight associated, se x(u,v) to 1 in all edges\n",
    "$$ e^{0}_{(u,v)} = x_{(u,v)} \\forall (u,v) \\in G $$ \n",
    "for k = 1..K do\n",
    "for (u,v) in G:\n",
    "    $$ e^{k}_{EN((u,v))} = AGGREGATE_k({e^{k-1}_{(w,r)}, \\forall (w,r) \\in EN((u,v))}) $$ \n",
    "    $$ e^{k}_{(u,v)} = \\sigma(W^kÂ·CONCAT(e^{k-1}_{(u,v)},e^{k}_{EN((u,v))} )$$\n",
    "end\n",
    "$$ e^{k}_{(u,v)} = e^{k}_{(u,v)}/||e^{k}_{(u,v)}||_2, \\forall (u,v) \\in G $$ \n",
    "end\n",
    "$$ z_{(u,v)} = e^{K}_{(u,v)} \\forall (u,v) \\in G $$\n",
    "\n",
    "\n",
    "**Thoughts**\n",
    "Probably this won't work well as edge betweennes depends on \"long range\" interactions...\n",
    "Anyways node betweenneess works well,(maybe retest it with GraphSage and test on unseen graphs\n",
    " \n",
    "**Next Steps**\n",
    "\n",
    "Quick retest of betweenneess centrality with GCN and GraphSage (retake code from igraph test for example)\n",
    "\n",
    "Read about PyTorch GCN model.\n",
    "gcn(x, edge_index), x is features matrix, edge_index is 2 lists of nodes\n",
    "- how to transform that to edge feaatures and edge_adjacency\n",
    "- probably add an edge to int translation list -> then everything can now be used with original PyTorch Geometric code\n",
    "- x will contain edge features (only the weights?)\n",
    "- edge_index will be the Edge adjacency matrix but using edge id's\n",
    "- **IMPORTANT** understand how from x (node feature matrix) the output is generated! (example return F.log_softmax(x, dim=1)\n",
    "\n",
    "### Link prediction approaches\n",
    "Read about link prediction approaches and copy their approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Girvan-Newman modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-55f286ca2230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentrality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'football.gml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_edge_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mcomp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgirvan_newman\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmost_valuable_edge\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmost_central_edge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nx' is not defined"
     ]
    }
   ],
   "source": [
    "# modifying edge_betweenness\n",
    "from networkx import edge_betweenness_centrality as betweenness\n",
    "\n",
    "\n",
    "def predict_all_betweennesses(G):\n",
    "    centrality = {}\n",
    "    \n",
    "    # transform networkx graph to PyTorch Geometric Dataset\n",
    "    \n",
    "    \n",
    "    # load model from disk\n",
    "    \n",
    "    \n",
    "    # predict all betweennesses of edges of G\n",
    "    \n",
    "    # save into centrality dict \n",
    "    # { (n1,n2): 0.0938, (n3,n4): 0.1230, ..}\n",
    "    \n",
    "    return centrality\n",
    "    \n",
    "\n",
    "def most_central_edge(G):\n",
    "    centrality = predict_all_betweennesses(G)\n",
    "    return max(centrality.values())\n",
    "\n",
    "# read graph into networkx\n",
    "G = nx.read_gml('graph.gml')\n",
    "\n",
    "# add weight 1 to all edges\n",
    "nx.set_edge_attributes(G, {(u,v): 1 for u, v in G.edges()},'weight')\n",
    "\n",
    "# compute the communities by girvan_newman algorithm\n",
    "comp = girvan_newman(G, most_valuable_edge=most_central_edge)\n",
    "\n",
    "# print the results\n",
    "tuple(sorted(c) for c in next(comp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-pytorch",
   "language": "python",
   "name": "gnn-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
