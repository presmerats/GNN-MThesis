{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how a GCN/GraphSAGE model is trained to compute Node betweenness centrality on different graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net1(torch.nn.Module):\n",
    "    def __init__(self, d1=16):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, d1)\n",
    "        self.conv2 = GCNConv(d1, dataset.num_classes)\n",
    "        self.d1 = d1\n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # output as multiclass target\n",
    "        #return F.log_softmax(x, dim=1)\n",
    "        \n",
    "        # output as regression target\n",
    "        return x\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Net1-gcn(%d,%d)-gcn(%d,%d)\" % (dataset.num_features,self.d1,self.d1,\n",
    "                                               dataset.num_classes)\n",
    "    \n",
    "    \n",
    "class Net2(torch.nn.Module):\n",
    "    def __init__(self, d1=300,d2=100):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, d1 )\n",
    "        #self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "        self.fc1 = nn.Linear(d1, d2)\n",
    "        self.fc2 = nn.Linear(d2, dataset.num_features)\n",
    "        self.d1 = d1\n",
    "        self.d2 = d2\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # 2 fc layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # output as regression target\n",
    "        return x\n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Net2-gcn(%d,%d)-fc(%d,%d)-fc(%d,%d)\" % (dataset.num_features,self.d1,self.d1,\n",
    "                                                        self.d2,self.d2,\n",
    "                                                        dataset.num_features)\n",
    "\n",
    "    \n",
    "    \n",
    "class Net3(torch.nn.Module):\n",
    "    def __init__(self, d1=300,d2=100):\n",
    "        super(Net3, self).__init__()\n",
    "        self.conv1 = SAGEConv(dataset.num_features, d1 )\n",
    "        #self.conv2 = SAGEConv(16, dataset.num_classes)\n",
    "        self.fc1 = nn.Linear(d1, d2)\n",
    "        self.fc2 = nn.Linear(d2, dataset.num_features)\n",
    "        self.d1 = d1\n",
    "        self.d2 = d2\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # 2 fc layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # output as regression target\n",
    "        return x\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Net3-SAGEgcn(%d,%d)-fc(%d,%d)-fc(%d,%d)\" % (dataset.num_features,self.d1,self.d1,\n",
    "                                                        self.d2,self.d2,\n",
    "                                                        dataset.num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import time\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "import importlib\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "import pickle\n",
    "\n",
    "def loadDataset(collection, name=None):\n",
    "    try:\n",
    "        # import datasets\n",
    "        themodule = importlib.import_module(\"torch_geometric.datasets\")\n",
    "        # get the function corresponding to collection\n",
    "        method_to_call = getattr(themodule, collection)\n",
    "        if name:\n",
    "            dataset = method_to_call(root='./data/'+str(collection), name=name)\n",
    "            dataset.filename = name\n",
    "            return dataset\n",
    "        else:\n",
    "            return method_to_call(root='./data/'+str(collection)) \n",
    "    except:\n",
    "        # custom module\n",
    "        method_to_call = globals()[collection]\n",
    "       \n",
    "        if name:\n",
    "            \n",
    "            dataset = method_to_call(root='./data/'+str(collection), name=name)\n",
    "            dataset.filename = name\n",
    "            return dataset\n",
    "        else:\n",
    "            return method_to_call(root='./data/'+str(collection)) \n",
    "        \n",
    "\n",
    "\n",
    "def transformMask(mask):\n",
    "    train_mask = []\n",
    "    i = 0\n",
    "    for pick in mask:\n",
    "        if pick[0]==1:\n",
    "            train_mask.append(i)\n",
    "        i+=1\n",
    "    return train_mask\n",
    "\n",
    "\n",
    "def shuffleTrainTestMasks(data, trainpct = 0.7):\n",
    "    ysize = list(data.y.size())[0]\n",
    "    data.train_mask = torch.zeros(ysize,1, dtype=torch.long)\n",
    "    data.train_mask[int(ysize*trainpct):] = 1\n",
    "    data.train_mask = data.train_mask[torch.randperm(ysize)]\n",
    "    data.test_mask = torch.ones(ysize,1, dtype=torch.long) - data.train_mask\n",
    "    \n",
    "    data.train_mask = transformMask(data.train_mask)\n",
    "    data.test_mask = transformMask(data.test_mask)\n",
    "  \n",
    "\n",
    "def shuffleTrainTestValMasks(data, trainpct = 0.7, valpct = 0.2):\n",
    "\n",
    "    ysize = list(data.y.size())[0]\n",
    "    #print(\"total \", ysize)\n",
    "    #print(\" train \",int(ysize*trainpct)-int(ysize*trainpct*valpct))\n",
    "    #print(\" val \",int(ysize*trainpct*valpct))\n",
    "    #print(\" test \",int(ysize*(1- trainpct) ))\n",
    "    data.train_mask = torch.zeros(ysize,1, dtype=torch.long)\n",
    "    data.train_mask[:int(ysize*trainpct)] = 1\n",
    "    data.train_mask = data.train_mask[torch.randperm(ysize)]\n",
    "    #print(\" train sum \",data.train_mask.sum())\n",
    "    data.test_mask = torch.ones(ysize,1, dtype=torch.long) - data.train_mask\n",
    "    #print(\" test sum \",data.test_mask.sum())\n",
    "    \n",
    "    # transform to list of indexes\n",
    "    data.train_mask = transformMask(data.train_mask)\n",
    "    data.test_mask = transformMask(data.test_mask)\n",
    "    \n",
    "    data.val_mask = data.train_mask[:int(ysize*trainpct*valpct)]\n",
    "    data.train_mask = data.train_mask[int(ysize*trainpct*valpct):]\n",
    "\n",
    "    \n",
    "    #print(data.train_mask)\n",
    "    #print(data.val_mask)\n",
    "    #print(data.test_mask)\n",
    "    \n",
    "    \n",
    "\n",
    "def trainTestEval(dataset, epochs=1, batch_size=32):\n",
    "    global Net\n",
    "    loader = DataLoader(dataset,  shuffle=False)\n",
    "    i = 0\n",
    "    print(loader)\n",
    "    print(dir(loader))\n",
    "    \n",
    "    G = dataset.data\n",
    "    print(G)\n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    # 1.  prepare model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #print(\"using \",device)\n",
    "    model = Net.to(device)  \n",
    "    data = G.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    model.train()\n",
    "\n",
    "    # 2.  create a train_mask, and a test_mask (val_mask for further experiments)\n",
    "    #shuffleTrainTestMasks(data)\n",
    "    #shuffleTrainTestValMasks(data)\n",
    "    shuffleTrainTestMasks(data)\n",
    "\n",
    "    # 3. train some epochs\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.mse_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 25 == 0 :\n",
    "            print(\"epoch-loss: \",epoch, loss)\n",
    "\n",
    "    # 4. Model evaluation\n",
    "    model.eval()\n",
    "    #  classification in a multiclass setting\n",
    "    #_, pred = model(data).max(dim=1)\n",
    "    #correct = pred[data.test_mask].eq(data.y[data.test_mask]).sum().item()\n",
    "    #acc = correct / data.test_mask.sum().item()\n",
    "    #print('Accuracy: {:.4f}'.format(acc))\n",
    "\n",
    "\n",
    "    # regression \n",
    "    pred = model(data)\n",
    "    #print(\"target: \",data.y[data.test_mask])\n",
    "    #print(\"prediction: \",pred[data.test_mask])\n",
    "    #print(pred[data.test_mask].type())\n",
    "    #print(data.y[data.test_mask].type())\n",
    "    \n",
    "    # prepare the normalized mean root squared error\n",
    "    t = data.y[data.test_mask]\n",
    "    y = pred[data.test_mask]\n",
    "    nrmse = torch.sum((t - y) ** 2)/len(data.test_mask)\n",
    "    nrmse = nrmse.sqrt()\n",
    "    print(\"RMSE: \",nrmse)\n",
    "\n",
    "    #m = torch.mean(t)\n",
    "    #print(\"mean\",m)\n",
    "    #tmax = torch.max(t)\n",
    "    #tmin = torch.min(t)\n",
    "    #sd = tmax-tmin\n",
    "    #print(\"sd\",sd)\n",
    "    #nrmse = (nrmse - m)/sd\n",
    "    #print(\"NRMSE:\",nrmse)\n",
    "\n",
    "\n",
    "    endtime = time.time()\n",
    "    print(\"Total train-test time: \"+str(endtime-start))\n",
    "    \n",
    "    with open(\"results.txt\",\"a\") as f:\n",
    "        print(dir(dataset))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(str(model)+\" \" \n",
    "                +str(dataset.filename)+\" \"  \n",
    "                +\"nrmse: \"+str(nrmse.item())+\" \" \n",
    "                +\"total time: \"+str(endtime-start) \n",
    "                +\" negative vals?: \"+str(False) \n",
    "                +\"\\n\"\n",
    "               )\n",
    "    \n",
    "    del model\n",
    "\n",
    "    #i+=1\n",
    "    #if i==1:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOwnDataset2():\n",
    "    def __init__(self,  root, name, transform=None, pre_transform=None):\n",
    "        f = open(name, 'rb')\n",
    "        self.data = pickle.load(f) \n",
    "        #print(self.data.num_features)\n",
    "        self.num_features = self.data.num_features\n",
    "        self.num_classes = 1\n",
    "        f.close()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Net for node Betweenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backend', '_backward_hooks', '_buffers', '_forward_hooks', '_forward_pre_hooks', '_get_name', '_load_from_state_dict', '_load_state_dict_pre_hooks', '_modules', '_named_members', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_slow_forward', '_state_dict_hooks', '_tracing_name', '_version', 'add_module', 'apply', 'buffers', 'children', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'half', 'load_state_dict', 'message', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'propagate', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', 'reset_parameters', 'share_memory', 'state_dict', 'to', 'train', 'training', 'type', 'update', 'zero_grad']\n",
      "['__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backend', '_backward_hooks', '_buffers', '_forward_hooks', '_forward_pre_hooks', '_get_name', '_load_from_state_dict', '_load_state_dict_pre_hooks', '_modules', '_named_members', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_slow_forward', '_state_dict_hooks', '_tracing_name', '_version', 'add_module', 'apply', 'buffers', 'children', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'half', 'load_state_dict', 'message', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'propagate', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', 'reset_parameters', 'share_memory', 'state_dict', 'to', 'train', 'training', 'type', 'update', 'zero_grad']\n",
      "<torch_geometric.data.dataloader.DataLoader object at 0x7fdd3ca714e0>\n",
      "['_DataLoader__initialized', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'batch_sampler', 'batch_size', 'collate_fn', 'dataset', 'drop_last', 'num_workers', 'pin_memory', 'sampler', 'timeout', 'worker_init_fn']\n",
      "Data(edge_index=[2, 12], x=[4, 1], y=[4])\n",
      "self update_args:  []\n",
      "self message_args:  ['x_j', 'norm']\n",
      "kwargs:  {'x': tensor([[ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977]], device='cuda:0',\n",
      "       grad_fn=<MmBackward>), 'norm': tensor([0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500,\n",
      "        0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
      "       device='cuda:0'), 'edge_index': tensor([[0, 1, 0, 2, 0, 3, 1, 2, 1, 3, 2, 3, 0, 1, 2, 3],\n",
      "        [1, 0, 2, 0, 3, 0, 2, 1, 3, 1, 3, 2, 0, 1, 2, 3]], device='cuda:0')}\n",
      "message_args:  [tensor([[ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977],\n",
      "        [ 0.2749,  0.3246, -0.1759, -0.2546,  0.3474, -0.2139, -0.1478, -0.3342,\n",
      "          0.3141, -0.0657, -0.3581,  0.2842, -0.4953, -0.3919,  0.2997, -0.0806,\n",
      "         -0.2364, -0.3242,  0.1261,  0.3977]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward>), tensor([0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500,\n",
      "        0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
      "       device='cuda:0')]\n",
      "update_args:  []\n",
      "self update_args:  []\n",
      "self message_args:  ['x_j', 'norm']\n",
      "kwargs:  {'x': tensor([[-0.3491],\n",
      "        [-0.4806],\n",
      "        [-0.3119],\n",
      "        [ 0.1669]], device='cuda:0', grad_fn=<MmBackward>), 'norm': tensor([0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500,\n",
      "        0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
      "       device='cuda:0'), 'edge_index': tensor([[0, 1, 0, 2, 0, 3, 1, 2, 1, 3, 2, 3, 0, 1, 2, 3],\n",
      "        [1, 0, 2, 0, 3, 0, 2, 1, 3, 1, 3, 2, 0, 1, 2, 3]], device='cuda:0')}\n",
      "message_args:  [tensor([[-0.4806],\n",
      "        [-0.3491],\n",
      "        [-0.3119],\n",
      "        [-0.3491],\n",
      "        [ 0.1669],\n",
      "        [-0.3491],\n",
      "        [-0.3119],\n",
      "        [-0.4806],\n",
      "        [ 0.1669],\n",
      "        [-0.4806],\n",
      "        [ 0.1669],\n",
      "        [-0.3119],\n",
      "        [-0.3491],\n",
      "        [-0.4806],\n",
      "        [-0.3119],\n",
      "        [ 0.1669]], device='cuda:0', grad_fn=<IndexBackward>), tensor([0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500,\n",
      "        0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
      "       device='cuda:0')]\n",
      "update_args:  []\n",
      "epoch-loss:  0 tensor(0.0594, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "self update_args:  []\n",
      "self message_args:  ['x_j', 'norm']\n",
      "kwargs:  {'x': tensor([[ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877]], device='cuda:0',\n",
      "       grad_fn=<MmBackward>), 'norm': tensor([0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500,\n",
      "        0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
      "       device='cuda:0'), 'edge_index': tensor([[0, 1, 0, 2, 0, 3, 1, 2, 1, 3, 2, 3, 0, 1, 2, 3],\n",
      "        [1, 0, 2, 0, 3, 0, 2, 1, 3, 1, 3, 2, 0, 1, 2, 3]], device='cuda:0')}\n",
      "message_args:  [tensor([[ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877],\n",
      "        [ 0.2849,  0.3146, -0.1660, -0.2446,  0.3374, -0.2039, -0.1378, -0.3243,\n",
      "          0.3241, -0.0558, -0.3481,  0.2742, -0.4853, -0.3819,  0.2897, -0.0707,\n",
      "         -0.2264, -0.3142,  0.1162,  0.3877]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward>), tensor([0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500,\n",
      "        0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
      "       device='cuda:0')]\n",
      "update_args:  []\n",
      "self update_args:  []\n",
      "self message_args:  ['x_j', 'norm']\n",
      "kwargs:  {'x': tensor([[-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565]], device='cuda:0', grad_fn=<MmBackward>), 'norm': tensor([0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500,\n",
      "        0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
      "       device='cuda:0'), 'edge_index': tensor([[0, 1, 0, 2, 0, 3, 1, 2, 1, 3, 2, 3, 0, 1, 2, 3],\n",
      "        [1, 0, 2, 0, 3, 0, 2, 1, 3, 1, 3, 2, 0, 1, 2, 3]], device='cuda:0')}\n",
      "message_args:  [tensor([[-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565],\n",
      "        [-0.1565]], device='cuda:0', grad_fn=<IndexBackward>), tensor([0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500,\n",
      "        0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
      "       device='cuda:0')]\n",
      "update_args:  []\n",
      "RMSE:  tensor(0.2072, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Total train-test time: 2.0856058597564697\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data', 'filename', 'num_classes', 'num_features']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = loadDataset(collection='MyOwnDataset2', name='precomputed/TUDataset_ENZYMES_11_nd.pickle')\n",
    "global Net\n",
    "Net=Net1(d1=20)\n",
    "trainTestEval(dataset,  epochs=1)\n",
    "del Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backend', '_backward_hooks', '_buffers', '_forward_hooks', '_forward_pre_hooks', '_get_name', '_load_from_state_dict', '_load_state_dict_pre_hooks', '_modules', '_named_members', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_slow_forward', '_state_dict_hooks', '_tracing_name', '_version', 'add_module', 'apply', 'buffers', 'children', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'half', 'load_state_dict', 'message', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'propagate', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', 'reset_parameters', 'share_memory', 'state_dict', 'to', 'train', 'training', 'type', 'update', 'zero_grad']\n",
      "['__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backend', '_backward_hooks', '_buffers', '_forward_hooks', '_forward_pre_hooks', '_get_name', '_load_from_state_dict', '_load_state_dict_pre_hooks', '_modules', '_named_members', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_slow_forward', '_state_dict_hooks', '_tracing_name', '_version', 'add_module', 'apply', 'buffers', 'children', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'half', 'load_state_dict', 'message', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'propagate', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', 'reset_parameters', 'share_memory', 'state_dict', 'to', 'train', 'training', 'type', 'update', 'zero_grad']\n",
      "<torch_geometric.data.dataloader.DataLoader object at 0x7fb628a21320>\n",
      "['_DataLoader__initialized', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'batch_sampler', 'batch_size', 'collate_fn', 'dataset', 'drop_last', 'num_workers', 'pin_memory', 'sampler', 'timeout', 'worker_init_fn']\n",
      "Data(edge_index=[2, 449110], x=[1000, 1], y=[1000])\n",
      "['x_j', 'norm']\n",
      "{'x': tensor([[ 0.5169, -0.1171,  0.4754,  ...,  0.4300, -0.4251, -0.4765],\n",
      "        [ 0.5169, -0.1171,  0.4754,  ...,  0.4300, -0.4251, -0.4765],\n",
      "        [ 0.5169, -0.1171,  0.4754,  ...,  0.4300, -0.4251, -0.4765],\n",
      "        ...,\n",
      "        [ 0.5169, -0.1171,  0.4754,  ...,  0.4300, -0.4251, -0.4765],\n",
      "        [ 0.5169, -0.1171,  0.4754,  ...,  0.4300, -0.4251, -0.4765],\n",
      "        [ 0.5169, -0.1171,  0.4754,  ...,  0.4300, -0.4251, -0.4765]],\n",
      "       device='cuda:0', grad_fn=<MmBackward>), 'norm': tensor([0.0022, 0.0022, 0.0021,  ..., 0.0021, 0.0022, 0.0023], device='cuda:0'), 'edge_index': tensor([[  0,   1,   0,  ..., 997, 998, 999],\n",
      "        [  1,   0,   2,  ..., 997, 998, 999]], device='cuda:0')}\n",
      "[tensor([[ 0.5169, -0.1171,  0.4754,  ...,  0.4300, -0.4251, -0.4765],\n",
      "        [ 0.5169, -0.1171,  0.4754,  ...,  0.4300, -0.4251, -0.4765],\n",
      "        [ 0.5169, -0.1171,  0.4754,  ...,  0.4300, -0.4251, -0.4765],\n",
      "        ...,\n",
      "        [ 0.5169, -0.1171,  0.4754,  ...,  0.4300, -0.4251, -0.4765],\n",
      "        [ 0.5169, -0.1171,  0.4754,  ...,  0.4300, -0.4251, -0.4765],\n",
      "        [ 0.5169, -0.1171,  0.4754,  ...,  0.4300, -0.4251, -0.4765]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward>), tensor([0.0022, 0.0022, 0.0021,  ..., 0.0021, 0.0022, 0.0023], device='cuda:0')]\n",
      "['x_j', 'norm']\n",
      "{'x': tensor([[-8.8112e-01],\n",
      "        [-1.9771e-01],\n",
      "        [-4.3041e-01],\n",
      "        [-6.4298e-01],\n",
      "        [-7.2801e-01],\n",
      "        [ 5.1451e-01],\n",
      "        [-2.4492e-01],\n",
      "        [ 6.5718e-01],\n",
      "        [ 2.0614e-03],\n",
      "        [-5.9367e-01],\n",
      "        [-3.0918e-01],\n",
      "        [-4.0661e-01],\n",
      "        [ 1.7329e-01],\n",
      "        [ 1.8126e-01],\n",
      "        [ 4.1313e-01],\n",
      "        [-2.8073e-01],\n",
      "        [-3.3279e-01],\n",
      "        [-3.5994e-01],\n",
      "        [ 6.2135e-01],\n",
      "        [-1.4228e-01],\n",
      "        [-9.8006e-01],\n",
      "        [ 4.2092e-01],\n",
      "        [ 6.8391e-01],\n",
      "        [ 1.7680e-01],\n",
      "        [-7.0396e-03],\n",
      "        [-6.5591e-01],\n",
      "        [-5.9839e-01],\n",
      "        [-1.4729e-01],\n",
      "        [-2.0870e-01],\n",
      "        [ 8.7378e-03],\n",
      "        [-2.1166e-01],\n",
      "        [ 3.5545e-02],\n",
      "        [-2.7870e-01],\n",
      "        [-9.0725e-01],\n",
      "        [-1.0837e+00],\n",
      "        [ 3.2169e-02],\n",
      "        [ 9.8240e-02],\n",
      "        [-2.5537e-01],\n",
      "        [ 2.4293e-01],\n",
      "        [ 6.0327e-01],\n",
      "        [-3.0659e-01],\n",
      "        [-3.4324e-01],\n",
      "        [-1.9430e-01],\n",
      "        [-6.1920e-01],\n",
      "        [-1.2948e-01],\n",
      "        [ 1.5828e-01],\n",
      "        [-1.1395e-01],\n",
      "        [-9.4338e-02],\n",
      "        [ 3.0675e-01],\n",
      "        [-3.3380e-01],\n",
      "        [-1.6816e-02],\n",
      "        [ 3.2694e-01],\n",
      "        [ 4.0882e-01],\n",
      "        [-7.8096e-01],\n",
      "        [-3.1190e-01],\n",
      "        [ 4.1484e-01],\n",
      "        [-1.6338e-01],\n",
      "        [ 1.9640e-01],\n",
      "        [-1.0391e-01],\n",
      "        [ 4.1974e-01],\n",
      "        [-2.9541e-02],\n",
      "        [-8.0920e-01],\n",
      "        [ 3.3012e-01],\n",
      "        [-3.7886e-01],\n",
      "        [-6.0626e-01],\n",
      "        [ 1.5058e-01],\n",
      "        [-6.2054e-01],\n",
      "        [-3.7531e-01],\n",
      "        [ 5.0398e-01],\n",
      "        [-5.6455e-01],\n",
      "        [ 5.7860e-01],\n",
      "        [-7.6744e-01],\n",
      "        [ 2.0242e-01],\n",
      "        [-9.6496e-02],\n",
      "        [-3.2117e-01],\n",
      "        [ 1.8971e-01],\n",
      "        [-1.1035e+00],\n",
      "        [-8.3214e-01],\n",
      "        [ 4.7329e-04],\n",
      "        [ 7.5142e-02],\n",
      "        [ 2.4083e-01],\n",
      "        [-1.0780e-01],\n",
      "        [-1.6302e-01],\n",
      "        [ 9.8505e-03],\n",
      "        [-1.2579e-02],\n",
      "        [ 5.8447e-01],\n",
      "        [-4.3906e-01],\n",
      "        [-4.8838e-01],\n",
      "        [ 1.0291e-01],\n",
      "        [-2.1478e-01],\n",
      "        [-8.0626e-01],\n",
      "        [-1.9065e-01],\n",
      "        [-3.6113e-01],\n",
      "        [-4.8922e-01],\n",
      "        [-1.5487e-01],\n",
      "        [-2.0197e-02],\n",
      "        [-8.1935e-02],\n",
      "        [-3.4699e-01],\n",
      "        [ 7.8881e-02],\n",
      "        [-4.2138e-01],\n",
      "        [-8.7065e-01],\n",
      "        [-3.4692e-01],\n",
      "        [-2.6566e-01],\n",
      "        [ 1.1268e-01],\n",
      "        [-5.4224e-01],\n",
      "        [-2.0627e-01],\n",
      "        [ 6.3594e-01],\n",
      "        [-6.2239e-01],\n",
      "        [ 2.7285e-01],\n",
      "        [-8.1937e-01],\n",
      "        [ 5.3328e-02],\n",
      "        [ 1.6278e-01],\n",
      "        [ 6.2112e-01],\n",
      "        [ 4.7334e-01],\n",
      "        [-8.2215e-01],\n",
      "        [-2.2422e-02],\n",
      "        [-4.2935e-01],\n",
      "        [-4.8730e-01],\n",
      "        [-1.0867e-02],\n",
      "        [-3.6226e-01],\n",
      "        [ 5.5290e-01],\n",
      "        [-2.5822e-01],\n",
      "        [ 7.6512e-01],\n",
      "        [ 1.5015e-01],\n",
      "        [-5.1537e-01],\n",
      "        [-1.3797e-01],\n",
      "        [-1.7265e-01],\n",
      "        [-2.6243e-01],\n",
      "        [-2.2744e-01],\n",
      "        [-1.5685e-01],\n",
      "        [-1.8877e-01],\n",
      "        [ 3.5529e-01],\n",
      "        [-1.6743e-01],\n",
      "        [-3.6699e-01],\n",
      "        [ 4.3605e-02],\n",
      "        [ 3.6863e-01],\n",
      "        [-3.4551e-01],\n",
      "        [-1.0802e-02],\n",
      "        [ 5.2865e-02],\n",
      "        [-1.8849e-01],\n",
      "        [ 3.1944e-01],\n",
      "        [ 0.0000e+00],\n",
      "        [ 2.7941e-02],\n",
      "        [-8.6076e-01],\n",
      "        [ 4.6882e-01],\n",
      "        [-1.4692e-01],\n",
      "        [-7.7881e-01],\n",
      "        [-9.1052e-01],\n",
      "        [ 1.5901e-01],\n",
      "        [ 1.7908e-01],\n",
      "        [-8.2839e-01],\n",
      "        [ 4.6948e-01],\n",
      "        [-3.2843e-01],\n",
      "        [-2.8188e-01],\n",
      "        [-2.0700e-01],\n",
      "        [-5.1216e-01],\n",
      "        [ 2.7222e-01],\n",
      "        [ 6.8413e-01],\n",
      "        [-3.3895e-01],\n",
      "        [-3.2846e-01],\n",
      "        [ 6.6185e-02],\n",
      "        [ 2.4094e-01],\n",
      "        [-4.9239e-01],\n",
      "        [-3.0115e-01],\n",
      "        [-9.0382e-01],\n",
      "        [-7.6224e-03],\n",
      "        [-3.0791e-01],\n",
      "        [-9.1038e-01],\n",
      "        [-1.0484e-01],\n",
      "        [ 7.5736e-02],\n",
      "        [-9.1164e-01],\n",
      "        [-1.4171e-01],\n",
      "        [ 1.1493e-01],\n",
      "        [-1.7223e-01],\n",
      "        [-9.5680e-01],\n",
      "        [-4.1410e-01],\n",
      "        [-1.6041e-01],\n",
      "        [ 3.2927e-02],\n",
      "        [-4.6032e-01],\n",
      "        [ 3.6021e-01],\n",
      "        [-1.9486e-01],\n",
      "        [ 1.6360e-01],\n",
      "        [-6.0698e-01],\n",
      "        [-6.1720e-01],\n",
      "        [-1.7053e-02],\n",
      "        [-1.8472e-01],\n",
      "        [-5.4997e-01],\n",
      "        [-1.1954e-01],\n",
      "        [-8.3331e-01],\n",
      "        [-1.0842e+00],\n",
      "        [-9.1189e-01],\n",
      "        [-8.1114e-02],\n",
      "        [-3.1695e-01],\n",
      "        [-7.3378e-01],\n",
      "        [-2.0929e-01],\n",
      "        [-6.6703e-01],\n",
      "        [-3.0335e-01],\n",
      "        [-9.7162e-01],\n",
      "        [ 5.3061e-03],\n",
      "        [-6.3135e-01],\n",
      "        [-6.3227e-01],\n",
      "        [ 2.9746e-01],\n",
      "        [-3.9315e-01],\n",
      "        [-4.8188e-01],\n",
      "        [-7.4918e-01],\n",
      "        [ 5.5910e-01],\n",
      "        [-6.5202e-01],\n",
      "        [-8.1326e-01],\n",
      "        [ 3.2945e-01],\n",
      "        [ 5.3770e-02],\n",
      "        [ 4.6271e-01],\n",
      "        [ 6.6927e-02],\n",
      "        [ 1.3209e-02],\n",
      "        [-4.8081e-01],\n",
      "        [-2.1440e-01],\n",
      "        [-1.9017e-01],\n",
      "        [-6.3202e-02],\n",
      "        [-4.6730e-01],\n",
      "        [ 1.6690e-02],\n",
      "        [-1.7720e-01],\n",
      "        [-5.8204e-03],\n",
      "        [-4.3182e-01],\n",
      "        [-1.1031e-02],\n",
      "        [ 2.0324e-01],\n",
      "        [-3.5461e-01],\n",
      "        [-7.7395e-01],\n",
      "        [-6.2738e-02],\n",
      "        [-3.4042e-01],\n",
      "        [-4.6105e-01],\n",
      "        [ 1.5911e-01],\n",
      "        [ 1.7183e-01],\n",
      "        [ 1.4761e-01],\n",
      "        [ 4.9716e-01],\n",
      "        [-6.8645e-01],\n",
      "        [-6.0618e-01],\n",
      "        [ 5.3135e-01],\n",
      "        [-1.3407e-01],\n",
      "        [-2.8071e-02],\n",
      "        [-1.6687e-01],\n",
      "        [-2.2488e-01],\n",
      "        [-3.8338e-01],\n",
      "        [ 3.2209e-02],\n",
      "        [ 1.5270e-01],\n",
      "        [-2.3864e-01],\n",
      "        [-8.1170e-01],\n",
      "        [-3.1595e-01],\n",
      "        [-3.4495e-01],\n",
      "        [ 3.9137e-01],\n",
      "        [-2.1371e-02],\n",
      "        [ 3.7812e-01],\n",
      "        [ 1.5378e-01],\n",
      "        [-1.3414e-01],\n",
      "        [ 2.7650e-01],\n",
      "        [ 1.6326e-02],\n",
      "        [ 3.5334e-01],\n",
      "        [-4.9749e-01],\n",
      "        [-4.7241e-01],\n",
      "        [-2.8991e-01],\n",
      "        [-6.1511e-01],\n",
      "        [ 1.3015e-01],\n",
      "        [-3.4299e-01],\n",
      "        [-5.2142e-01],\n",
      "        [-4.4115e-01],\n",
      "        [ 7.8776e-01],\n",
      "        [-1.5112e-02],\n",
      "        [-3.6110e-01],\n",
      "        [-4.0440e-01],\n",
      "        [-1.4670e-01],\n",
      "        [-3.0499e-01],\n",
      "        [-1.2738e-01],\n",
      "        [-1.8471e-01],\n",
      "        [ 1.3320e-01],\n",
      "        [ 4.4551e-01],\n",
      "        [-2.3252e-02],\n",
      "        [ 5.0025e-01],\n",
      "        [ 1.1694e-01],\n",
      "        [ 2.1968e-01],\n",
      "        [ 5.5899e-02],\n",
      "        [-5.1192e-02],\n",
      "        [-1.0806e-01],\n",
      "        [-4.1896e-01],\n",
      "        [ 1.6703e-01],\n",
      "        [-8.1113e-01],\n",
      "        [ 3.1984e-02],\n",
      "        [-6.7714e-01],\n",
      "        [ 5.4516e-01],\n",
      "        [ 6.0344e-01],\n",
      "        [-2.9758e-01],\n",
      "        [-7.9583e-01],\n",
      "        [ 2.4228e-01],\n",
      "        [-3.4143e-01],\n",
      "        [-1.4863e-01],\n",
      "        [-3.0018e-01],\n",
      "        [-1.7708e-02],\n",
      "        [-3.1408e-01],\n",
      "        [-4.1681e-02],\n",
      "        [-4.4499e-01],\n",
      "        [-3.0168e-01],\n",
      "        [-1.9211e-01],\n",
      "        [-1.6581e-01],\n",
      "        [-5.7921e-01],\n",
      "        [-7.8814e-01],\n",
      "        [-8.1058e-01],\n",
      "        [ 1.9091e-01],\n",
      "        [ 5.2769e-01],\n",
      "        [-4.8897e-01],\n",
      "        [ 2.1001e-01],\n",
      "        [ 1.6108e-02],\n",
      "        [ 4.2148e-02],\n",
      "        [-3.5754e-01],\n",
      "        [-3.7446e-01],\n",
      "        [-5.2989e-01],\n",
      "        [-9.3603e-01],\n",
      "        [ 1.2907e-02],\n",
      "        [-1.3999e-01],\n",
      "        [-7.7651e-01],\n",
      "        [-4.9711e-01],\n",
      "        [-1.1845e-01],\n",
      "        [-9.2478e-01],\n",
      "        [ 3.8610e-02],\n",
      "        [ 1.7032e-01],\n",
      "        [ 4.3488e-01],\n",
      "        [ 4.3556e-01],\n",
      "        [ 1.5421e-01],\n",
      "        [-1.9343e-01],\n",
      "        [-2.3237e-02],\n",
      "        [ 1.0805e-01],\n",
      "        [-8.9009e-01],\n",
      "        [ 1.6367e-01],\n",
      "        [ 2.0054e-01],\n",
      "        [-2.8865e-01],\n",
      "        [-4.7491e-01],\n",
      "        [-4.6527e-01],\n",
      "        [ 7.1393e-01],\n",
      "        [ 6.8764e-01],\n",
      "        [-7.8897e-01],\n",
      "        [ 5.2789e-01],\n",
      "        [ 7.8664e-01],\n",
      "        [ 5.2716e-01],\n",
      "        [-5.9209e-01],\n",
      "        [-6.5506e-01],\n",
      "        [-3.9318e-01],\n",
      "        [-5.5637e-01],\n",
      "        [-3.9760e-01],\n",
      "        [ 3.0162e-01],\n",
      "        [ 1.5288e-02],\n",
      "        [-4.4891e-01],\n",
      "        [ 1.2718e-01],\n",
      "        [-2.6245e-01],\n",
      "        [ 1.9537e-01],\n",
      "        [ 1.6575e-01],\n",
      "        [ 1.6772e-01],\n",
      "        [-7.8252e-01],\n",
      "        [ 1.6535e-01],\n",
      "        [ 2.9182e-01],\n",
      "        [ 3.5143e-01],\n",
      "        [ 5.9124e-02],\n",
      "        [-5.9124e-01],\n",
      "        [-6.1529e-01],\n",
      "        [-2.0823e-01],\n",
      "        [ 1.2102e-01],\n",
      "        [-8.6957e-01],\n",
      "        [-5.2283e-01],\n",
      "        [-1.8536e-01],\n",
      "        [-6.5261e-01],\n",
      "        [-3.9425e-02],\n",
      "        [ 3.1567e-01],\n",
      "        [-1.9907e-01],\n",
      "        [-3.4902e-01],\n",
      "        [-5.7195e-01],\n",
      "        [ 4.8053e-01],\n",
      "        [-6.5038e-01],\n",
      "        [ 3.7465e-03],\n",
      "        [ 3.3812e-01],\n",
      "        [-1.1213e-01],\n",
      "        [-3.5266e-01],\n",
      "        [-4.7158e-01],\n",
      "        [-2.6946e-01],\n",
      "        [-4.2710e-01],\n",
      "        [ 1.4423e-02],\n",
      "        [ 4.5709e-02],\n",
      "        [-7.7827e-01],\n",
      "        [ 9.7191e-02],\n",
      "        [ 3.7117e-01],\n",
      "        [-2.3520e-01],\n",
      "        [-2.9015e-01],\n",
      "        [ 3.6827e-01],\n",
      "        [ 5.2930e-03],\n",
      "        [-1.8743e-02],\n",
      "        [-2.8918e-01],\n",
      "        [-3.0364e-01],\n",
      "        [ 8.4655e-02],\n",
      "        [ 4.2131e-01],\n",
      "        [ 3.1336e-01],\n",
      "        [ 3.7109e-03],\n",
      "        [-5.2725e-02],\n",
      "        [ 2.2702e-02],\n",
      "        [-8.3528e-01],\n",
      "        [-4.8379e-02],\n",
      "        [-5.3511e-02],\n",
      "        [-5.1159e-01],\n",
      "        [ 2.6550e-01],\n",
      "        [-6.2005e-02],\n",
      "        [ 5.2780e-01],\n",
      "        [ 3.9149e-02],\n",
      "        [-8.2030e-01],\n",
      "        [ 3.6630e-01],\n",
      "        [ 7.4526e-01],\n",
      "        [ 3.3569e-01],\n",
      "        [-4.3626e-01],\n",
      "        [-2.2566e-01],\n",
      "        [ 3.7677e-02],\n",
      "        [-4.6689e-01],\n",
      "        [-2.2578e-01],\n",
      "        [ 5.5844e-01],\n",
      "        [-5.4527e-01],\n",
      "        [-4.4676e-01],\n",
      "        [-7.8485e-01],\n",
      "        [ 4.0356e-02],\n",
      "        [ 1.6748e-01],\n",
      "        [ 1.3272e-01],\n",
      "        [ 1.4572e-01],\n",
      "        [-9.2544e-01],\n",
      "        [-1.1064e-02],\n",
      "        [-4.4902e-01],\n",
      "        [ 3.7794e-01],\n",
      "        [-4.6251e-01],\n",
      "        [-4.6589e-01],\n",
      "        [ 1.6698e-01],\n",
      "        [-4.1267e-01],\n",
      "        [-3.0214e-01],\n",
      "        [-5.6189e-01],\n",
      "        [ 1.8198e-01],\n",
      "        [-7.8230e-01],\n",
      "        [-9.4690e-01],\n",
      "        [ 2.8151e-02],\n",
      "        [-3.1755e-01],\n",
      "        [-8.3547e-02],\n",
      "        [ 5.3530e-01],\n",
      "        [ 6.4330e-01],\n",
      "        [ 5.7079e-01],\n",
      "        [-8.2555e-01],\n",
      "        [-1.5997e-01],\n",
      "        [ 4.5062e-01],\n",
      "        [-1.0639e-02],\n",
      "        [-1.9649e-02],\n",
      "        [-7.9528e-03],\n",
      "        [ 4.0856e-04],\n",
      "        [ 6.7110e-02],\n",
      "        [-2.0173e-01],\n",
      "        [ 7.9207e-01],\n",
      "        [-8.4300e-01],\n",
      "        [-1.4600e-01],\n",
      "        [-3.5423e-01],\n",
      "        [ 5.8009e-01],\n",
      "        [-3.0159e-02],\n",
      "        [-3.6735e-01],\n",
      "        [-4.3114e-01],\n",
      "        [-7.2418e-02],\n",
      "        [-4.8956e-01],\n",
      "        [-5.6964e-01],\n",
      "        [-4.5822e-01],\n",
      "        [-4.0424e-01],\n",
      "        [-4.5685e-01],\n",
      "        [-1.3238e-01],\n",
      "        [-4.7499e-01],\n",
      "        [ 6.5769e-02],\n",
      "        [ 1.0324e-01],\n",
      "        [-3.0270e-01],\n",
      "        [ 2.2497e-01],\n",
      "        [ 6.2785e-01],\n",
      "        [-3.7331e-01],\n",
      "        [ 8.9459e-02],\n",
      "        [-6.0980e-01],\n",
      "        [-8.3124e-01],\n",
      "        [ 1.1839e-01],\n",
      "        [-1.9549e-01],\n",
      "        [-6.9054e-01],\n",
      "        [ 1.5016e-01],\n",
      "        [-3.0260e-01],\n",
      "        [ 3.1967e-01],\n",
      "        [-1.3253e-01],\n",
      "        [ 1.8883e-01],\n",
      "        [-7.7803e-01],\n",
      "        [-3.1746e-01],\n",
      "        [-4.4456e-01],\n",
      "        [ 2.4455e-02],\n",
      "        [-4.4037e-01],\n",
      "        [ 1.6219e-01],\n",
      "        [-2.5192e-04],\n",
      "        [ 2.8473e-02],\n",
      "        [-4.5627e-01],\n",
      "        [-1.3259e-02],\n",
      "        [ 2.1208e-02],\n",
      "        [-2.4331e-01],\n",
      "        [-2.0389e-01],\n",
      "        [ 4.4097e-02],\n",
      "        [-3.5386e-01],\n",
      "        [-1.3350e-01],\n",
      "        [-3.1867e-01],\n",
      "        [-3.9484e-02],\n",
      "        [-2.7353e-01],\n",
      "        [-1.5912e-01],\n",
      "        [ 2.8534e-01],\n",
      "        [-9.5539e-02],\n",
      "        [-2.0601e-01],\n",
      "        [-1.4758e-01],\n",
      "        [ 5.0008e-01],\n",
      "        [ 2.9782e-01],\n",
      "        [-1.3555e-01],\n",
      "        [ 1.1538e-01],\n",
      "        [ 1.6365e-01],\n",
      "        [-6.1804e-01],\n",
      "        [-1.8247e-03],\n",
      "        [ 1.4255e-01],\n",
      "        [ 1.6808e-02],\n",
      "        [-2.1123e-01],\n",
      "        [ 7.8188e-01],\n",
      "        [-1.3911e-01],\n",
      "        [ 5.6128e-01],\n",
      "        [-8.4249e-02],\n",
      "        [ 1.7296e-01],\n",
      "        [ 1.0826e-01],\n",
      "        [ 1.1502e-01],\n",
      "        [-1.2204e-01],\n",
      "        [ 1.7091e-01],\n",
      "        [ 2.8368e-01],\n",
      "        [-6.5491e-01],\n",
      "        [ 1.3747e-01],\n",
      "        [-3.5175e-01],\n",
      "        [-3.6010e-01],\n",
      "        [-4.0474e-01],\n",
      "        [-5.3767e-01],\n",
      "        [-1.0071e+00],\n",
      "        [ 3.9232e-01],\n",
      "        [ 1.5193e-01],\n",
      "        [ 1.0471e-01],\n",
      "        [ 3.6626e-01],\n",
      "        [-3.3183e-01],\n",
      "        [-6.1891e-01],\n",
      "        [-1.8464e-01],\n",
      "        [-4.5314e-01],\n",
      "        [ 4.9202e-02],\n",
      "        [-4.1176e-01],\n",
      "        [-1.8899e-01],\n",
      "        [ 1.9518e-02],\n",
      "        [-4.4661e-01],\n",
      "        [ 3.4757e-01],\n",
      "        [ 2.1824e-02],\n",
      "        [ 3.1640e-02],\n",
      "        [ 6.4325e-01],\n",
      "        [ 4.7240e-01],\n",
      "        [ 6.4118e-01],\n",
      "        [ 4.5930e-01],\n",
      "        [-3.1738e-01],\n",
      "        [ 2.1412e-02],\n",
      "        [ 1.6034e-01],\n",
      "        [ 1.5679e-01],\n",
      "        [-4.5828e-01],\n",
      "        [-5.7267e-01],\n",
      "        [-4.3875e-01],\n",
      "        [-2.3391e-01],\n",
      "        [-1.1216e-02],\n",
      "        [-2.4276e-01],\n",
      "        [ 1.2708e-01],\n",
      "        [-5.0120e-01],\n",
      "        [-6.1221e-01],\n",
      "        [-5.5951e-01],\n",
      "        [ 7.3105e-02],\n",
      "        [ 4.3155e-02],\n",
      "        [-2.8259e-01],\n",
      "        [-3.4465e-01],\n",
      "        [ 3.3975e-01],\n",
      "        [-9.1637e-01],\n",
      "        [ 9.8967e-02],\n",
      "        [ 4.5163e-01],\n",
      "        [ 2.9048e-02],\n",
      "        [-5.8344e-02],\n",
      "        [-1.4210e-01],\n",
      "        [-4.8887e-01],\n",
      "        [ 1.6570e-02],\n",
      "        [-3.4130e-01],\n",
      "        [ 3.9318e-01],\n",
      "        [-6.3738e-01],\n",
      "        [-9.0695e-01],\n",
      "        [-1.8980e-01],\n",
      "        [-6.2839e-02],\n",
      "        [-3.1717e-01],\n",
      "        [-8.8705e-01],\n",
      "        [-1.3524e-01],\n",
      "        [-2.0416e-01],\n",
      "        [ 1.1781e-01],\n",
      "        [-1.0651e+00],\n",
      "        [ 2.9374e-01],\n",
      "        [-3.3187e-01],\n",
      "        [ 2.0713e-03],\n",
      "        [ 6.8803e-01],\n",
      "        [-3.3073e-01],\n",
      "        [-2.5240e-01],\n",
      "        [ 3.7477e-01],\n",
      "        [ 3.1192e-01],\n",
      "        [-8.1282e-01],\n",
      "        [-3.1530e-01],\n",
      "        [-2.6558e-01],\n",
      "        [ 1.4086e-01],\n",
      "        [ 1.2573e-01],\n",
      "        [ 4.0828e-02],\n",
      "        [ 3.2428e-02],\n",
      "        [-1.0497e+00],\n",
      "        [-9.8317e-01],\n",
      "        [-3.1225e-01],\n",
      "        [ 1.4653e-02],\n",
      "        [ 5.2027e-01],\n",
      "        [-3.7418e-01],\n",
      "        [-1.3814e-01],\n",
      "        [-5.8881e-01],\n",
      "        [-1.2793e-01],\n",
      "        [-1.3124e-01],\n",
      "        [ 1.9931e-01],\n",
      "        [-8.2425e-01],\n",
      "        [-3.9943e-02],\n",
      "        [-9.8178e-01],\n",
      "        [-8.3729e-01],\n",
      "        [-3.7536e-01],\n",
      "        [-5.0874e-01],\n",
      "        [ 6.4206e-01],\n",
      "        [-5.0932e-01],\n",
      "        [ 1.5383e-01],\n",
      "        [ 4.6111e-01],\n",
      "        [ 2.2551e-01],\n",
      "        [-2.9853e-02],\n",
      "        [ 2.1381e-02],\n",
      "        [ 3.4540e-01],\n",
      "        [-4.7067e-01],\n",
      "        [ 2.0225e-01],\n",
      "        [-6.5909e-01],\n",
      "        [-3.5419e-02],\n",
      "        [-3.6367e-01],\n",
      "        [-2.5328e-01],\n",
      "        [-6.9480e-01],\n",
      "        [-3.9353e-02],\n",
      "        [-2.8315e-01],\n",
      "        [ 1.2700e-01],\n",
      "        [ 3.4777e-01],\n",
      "        [ 1.9322e-01],\n",
      "        [ 6.4037e-01],\n",
      "        [-1.6584e-01],\n",
      "        [-1.1145e+00],\n",
      "        [-3.4372e-01],\n",
      "        [-9.5081e-01],\n",
      "        [-2.6293e-01],\n",
      "        [ 3.6106e-01],\n",
      "        [-6.8332e-01],\n",
      "        [ 5.0993e-02],\n",
      "        [-5.3326e-01],\n",
      "        [ 3.8620e-03],\n",
      "        [-2.0554e-01],\n",
      "        [ 1.6879e-01],\n",
      "        [-3.1307e-01],\n",
      "        [-8.2986e-01],\n",
      "        [ 2.6289e-01],\n",
      "        [ 1.0771e-01],\n",
      "        [ 3.2394e-01],\n",
      "        [-1.2957e-01],\n",
      "        [-8.6456e-01],\n",
      "        [ 5.0430e-01],\n",
      "        [-7.7703e-01],\n",
      "        [-7.0982e-01],\n",
      "        [ 1.8364e-01],\n",
      "        [ 5.7664e-01],\n",
      "        [ 3.0796e-01],\n",
      "        [ 5.0841e-01],\n",
      "        [ 8.3942e-02],\n",
      "        [ 1.3523e-02],\n",
      "        [ 1.4998e-01],\n",
      "        [ 3.7993e-01],\n",
      "        [-1.3518e-01],\n",
      "        [ 3.0464e-01],\n",
      "        [-1.8853e-01],\n",
      "        [ 4.7170e-01],\n",
      "        [-6.3300e-01],\n",
      "        [ 2.0161e-02],\n",
      "        [-2.9702e-01],\n",
      "        [ 2.0969e-02],\n",
      "        [ 1.7426e-01],\n",
      "        [ 5.7487e-02],\n",
      "        [ 2.3665e-01],\n",
      "        [-9.9633e-01],\n",
      "        [ 2.8375e-01],\n",
      "        [ 1.3567e-01],\n",
      "        [-4.3284e-01],\n",
      "        [-8.5734e-01],\n",
      "        [-2.7443e-01],\n",
      "        [-6.3027e-01],\n",
      "        [-3.3283e-01],\n",
      "        [-3.4953e-02],\n",
      "        [-9.2965e-01],\n",
      "        [-6.1238e-01],\n",
      "        [ 1.6930e-01],\n",
      "        [ 6.9533e-02],\n",
      "        [-3.4144e-01],\n",
      "        [-1.1462e+00],\n",
      "        [-3.3744e-02],\n",
      "        [-1.0836e-01],\n",
      "        [-6.3030e-01],\n",
      "        [-1.8789e-01],\n",
      "        [ 5.0730e-01],\n",
      "        [ 4.0959e-02],\n",
      "        [-6.4717e-01],\n",
      "        [ 4.2148e-04],\n",
      "        [-7.1427e-01],\n",
      "        [-3.5573e-01],\n",
      "        [-4.0470e-02],\n",
      "        [-4.7825e-01],\n",
      "        [ 3.0331e-01],\n",
      "        [-8.8545e-01],\n",
      "        [-8.0852e-01],\n",
      "        [ 1.6016e-01],\n",
      "        [-3.8785e-01],\n",
      "        [-3.9415e-01],\n",
      "        [-7.8057e-01],\n",
      "        [-1.1212e-01],\n",
      "        [ 6.2281e-02],\n",
      "        [-3.8144e-01],\n",
      "        [-3.2743e-01],\n",
      "        [-7.0440e-02],\n",
      "        [-8.1873e-01],\n",
      "        [ 2.1304e-01],\n",
      "        [-6.1238e-01],\n",
      "        [ 2.0936e-01],\n",
      "        [-3.3943e-01],\n",
      "        [ 3.3721e-01],\n",
      "        [-7.6906e-01],\n",
      "        [-6.5593e-01],\n",
      "        [-1.5536e-01],\n",
      "        [-2.3614e-01],\n",
      "        [ 5.7230e-01],\n",
      "        [ 7.2812e-02],\n",
      "        [ 9.3215e-02],\n",
      "        [ 3.1902e-01],\n",
      "        [-4.4433e-01],\n",
      "        [-2.8584e-01],\n",
      "        [-4.2280e-01],\n",
      "        [-7.1537e-01],\n",
      "        [-5.2218e-01],\n",
      "        [ 6.7698e-01],\n",
      "        [-1.5237e-01],\n",
      "        [-3.9073e-01],\n",
      "        [-1.0684e+00],\n",
      "        [-4.8658e-01],\n",
      "        [ 3.9727e-02],\n",
      "        [ 1.2643e-01],\n",
      "        [ 1.3104e-01],\n",
      "        [-2.4432e-01],\n",
      "        [ 2.8828e-01],\n",
      "        [-3.3640e-01],\n",
      "        [-1.3627e-01],\n",
      "        [ 4.1103e-01],\n",
      "        [-4.9092e-01],\n",
      "        [-7.3487e-03],\n",
      "        [-7.7645e-01],\n",
      "        [ 1.5117e-01],\n",
      "        [ 1.1805e-01],\n",
      "        [-4.3729e-01],\n",
      "        [-4.8445e-01],\n",
      "        [-3.7016e-01],\n",
      "        [ 5.0853e-01],\n",
      "        [-6.3674e-01],\n",
      "        [-1.2628e-01],\n",
      "        [-8.0733e-02],\n",
      "        [ 7.5641e-01],\n",
      "        [ 3.6629e-02],\n",
      "        [-4.8262e-01],\n",
      "        [ 1.6970e-01],\n",
      "        [ 2.8412e-01],\n",
      "        [ 3.6217e-01],\n",
      "        [-9.5324e-02],\n",
      "        [-1.3439e-01],\n",
      "        [-1.8863e-01],\n",
      "        [ 2.0306e-01],\n",
      "        [ 7.8233e-01],\n",
      "        [ 2.7239e-01],\n",
      "        [-3.2612e-01],\n",
      "        [-8.8868e-01],\n",
      "        [-1.3646e-01],\n",
      "        [-1.4899e-01],\n",
      "        [ 2.8769e-01],\n",
      "        [ 3.8111e-01],\n",
      "        [-5.6027e-01],\n",
      "        [-3.5581e-01],\n",
      "        [ 6.7469e-01],\n",
      "        [-2.3329e-01],\n",
      "        [ 4.0518e-01],\n",
      "        [ 1.1053e-01],\n",
      "        [-4.8244e-01],\n",
      "        [ 4.9018e-01],\n",
      "        [-4.2340e-01],\n",
      "        [-3.2566e-01],\n",
      "        [-6.5346e-01],\n",
      "        [ 1.4475e-01],\n",
      "        [-6.1607e-01],\n",
      "        [-9.9460e-01],\n",
      "        [ 2.9852e-01],\n",
      "        [-4.1565e-01],\n",
      "        [ 3.3007e-02],\n",
      "        [-2.2581e-01],\n",
      "        [-6.7457e-01],\n",
      "        [-1.0920e-01],\n",
      "        [-7.6345e-03],\n",
      "        [-5.0025e-01],\n",
      "        [-2.4886e-01],\n",
      "        [-4.2023e-01],\n",
      "        [-3.2647e-01],\n",
      "        [-3.0855e-01],\n",
      "        [-4.8412e-01],\n",
      "        [-8.8178e-01],\n",
      "        [-5.4448e-01],\n",
      "        [-3.6270e-01],\n",
      "        [-3.4597e-02],\n",
      "        [-4.0322e-02],\n",
      "        [-1.8786e-01],\n",
      "        [-7.1491e-01],\n",
      "        [-6.1815e-01],\n",
      "        [-7.5626e-01],\n",
      "        [-4.4054e-01],\n",
      "        [-7.5182e-01],\n",
      "        [-1.0994e-01],\n",
      "        [-9.6889e-01],\n",
      "        [ 1.4755e-01],\n",
      "        [-3.3372e-01],\n",
      "        [ 5.0029e-01],\n",
      "        [ 6.0699e-01],\n",
      "        [-1.1457e-01],\n",
      "        [-3.3284e-01],\n",
      "        [-4.5982e-01],\n",
      "        [-9.2432e-01],\n",
      "        [-8.6021e-01],\n",
      "        [-6.6168e-01],\n",
      "        [-1.0173e-01],\n",
      "        [-4.7581e-01],\n",
      "        [ 4.7075e-01],\n",
      "        [ 4.6394e-01],\n",
      "        [-6.0490e-01],\n",
      "        [ 5.2156e-01],\n",
      "        [-4.0201e-01],\n",
      "        [-3.6293e-01],\n",
      "        [-5.5164e-01],\n",
      "        [ 2.9552e-03],\n",
      "        [-2.8160e-01],\n",
      "        [-1.1778e-01],\n",
      "        [-7.8952e-01],\n",
      "        [ 4.9018e-01],\n",
      "        [ 1.2901e-01],\n",
      "        [-3.5530e-01],\n",
      "        [ 1.6332e-01],\n",
      "        [ 3.3495e-01],\n",
      "        [-2.5993e-03],\n",
      "        [-4.7113e-01],\n",
      "        [-3.4058e-01],\n",
      "        [-3.1439e-01],\n",
      "        [ 2.8713e-01],\n",
      "        [-5.0140e-01],\n",
      "        [-6.5767e-01],\n",
      "        [-8.0738e-01],\n",
      "        [-5.8890e-03],\n",
      "        [ 1.4332e-01],\n",
      "        [-4.0590e-01],\n",
      "        [-1.7057e-01],\n",
      "        [-1.5765e-01],\n",
      "        [ 3.1638e-01],\n",
      "        [ 6.7938e-01],\n",
      "        [ 6.4756e-01],\n",
      "        [-1.4605e-01],\n",
      "        [-2.4430e-01],\n",
      "        [-3.7786e-01],\n",
      "        [ 2.9219e-01],\n",
      "        [-5.5049e-01],\n",
      "        [-1.5778e-01],\n",
      "        [-1.6559e-02],\n",
      "        [-2.3510e-01],\n",
      "        [-9.3485e-01],\n",
      "        [-6.0023e-01],\n",
      "        [ 5.2926e-02],\n",
      "        [-1.0144e+00],\n",
      "        [-6.1727e-01],\n",
      "        [ 2.8342e-01],\n",
      "        [-4.6692e-01],\n",
      "        [ 4.5544e-01],\n",
      "        [ 2.0094e-02],\n",
      "        [-6.0076e-01],\n",
      "        [-4.8611e-01],\n",
      "        [-2.2961e-01],\n",
      "        [-1.3753e-01],\n",
      "        [ 3.0199e-01],\n",
      "        [-4.9543e-01],\n",
      "        [ 2.5702e-02],\n",
      "        [ 1.8570e-01],\n",
      "        [-6.0884e-02],\n",
      "        [-7.9904e-02],\n",
      "        [-1.6729e-01],\n",
      "        [ 4.1252e-01],\n",
      "        [ 1.2444e-01],\n",
      "        [-9.2944e-01],\n",
      "        [-4.2219e-01],\n",
      "        [-5.6752e-01],\n",
      "        [-7.5076e-03],\n",
      "        [-2.8285e-03],\n",
      "        [ 1.7692e-01],\n",
      "        [-7.6891e-02],\n",
      "        [-2.9697e-01],\n",
      "        [-3.2525e-01],\n",
      "        [-4.9394e-01],\n",
      "        [-4.0868e-01],\n",
      "        [ 6.7742e-01],\n",
      "        [-9.9130e-01],\n",
      "        [-6.3066e-01],\n",
      "        [-9.4846e-04],\n",
      "        [-4.7519e-01],\n",
      "        [-3.1959e-01],\n",
      "        [ 2.7917e-02],\n",
      "        [-6.0914e-01],\n",
      "        [-8.3405e-01],\n",
      "        [-3.8719e-01],\n",
      "        [-2.0077e-01],\n",
      "        [-7.2300e-02],\n",
      "        [-8.9555e-01],\n",
      "        [ 5.1436e-01],\n",
      "        [ 4.9155e-02],\n",
      "        [-3.8190e-01],\n",
      "        [ 3.0584e-01],\n",
      "        [-3.6078e-02],\n",
      "        [ 1.6735e-01],\n",
      "        [-9.6762e-02],\n",
      "        [-4.6737e-01],\n",
      "        [-1.6064e-01],\n",
      "        [ 5.2606e-01],\n",
      "        [ 4.3912e-01],\n",
      "        [-4.0349e-01],\n",
      "        [-2.6453e-01],\n",
      "        [-1.0768e-01],\n",
      "        [ 4.5466e-01],\n",
      "        [ 5.4986e-02],\n",
      "        [-1.7596e-01],\n",
      "        [ 2.1883e-01],\n",
      "        [-5.9110e-01],\n",
      "        [-1.3518e-01],\n",
      "        [ 1.1817e-01],\n",
      "        [ 9.9566e-02],\n",
      "        [-4.8485e-01],\n",
      "        [-2.0461e-02],\n",
      "        [-3.2946e-02],\n",
      "        [ 4.0638e-01],\n",
      "        [-1.4860e-01],\n",
      "        [ 4.9261e-02],\n",
      "        [-2.9819e-01],\n",
      "        [ 1.3227e-01],\n",
      "        [-4.2056e-01],\n",
      "        [-3.2627e-01],\n",
      "        [-3.1008e-01],\n",
      "        [-4.8657e-01],\n",
      "        [ 4.8452e-02],\n",
      "        [ 4.4519e-01],\n",
      "        [ 4.8601e-02],\n",
      "        [-8.0522e-01],\n",
      "        [-1.1278e-01],\n",
      "        [-1.2389e-01],\n",
      "        [-1.9107e-01],\n",
      "        [ 1.5834e-01],\n",
      "        [-2.4654e-01],\n",
      "        [-3.0980e-01],\n",
      "        [-3.0403e-01],\n",
      "        [-7.1570e-02],\n",
      "        [-2.9021e-01],\n",
      "        [ 3.0472e-01],\n",
      "        [-2.4051e-01],\n",
      "        [-1.0026e+00],\n",
      "        [-4.8205e-01],\n",
      "        [-6.3569e-01],\n",
      "        [-1.9412e-02],\n",
      "        [-9.5232e-01],\n",
      "        [-7.4493e-01],\n",
      "        [-4.4036e-01],\n",
      "        [-6.0407e-01],\n",
      "        [-2.9199e-01],\n",
      "        [-4.9090e-01],\n",
      "        [-3.3321e-01],\n",
      "        [-1.1448e-01],\n",
      "        [ 4.0511e-01],\n",
      "        [ 2.4327e-01],\n",
      "        [-1.5005e-01],\n",
      "        [-3.9485e-01],\n",
      "        [ 5.0506e-01],\n",
      "        [-3.8580e-01],\n",
      "        [-1.2067e-01],\n",
      "        [-2.2430e-01],\n",
      "        [-8.2743e-01],\n",
      "        [ 3.1393e-01],\n",
      "        [ 7.9790e-02],\n",
      "        [ 6.8257e-01],\n",
      "        [-5.9184e-01]], device='cuda:0', grad_fn=<MmBackward>), 'norm': tensor([0.0022, 0.0022, 0.0021,  ..., 0.0021, 0.0022, 0.0023], device='cuda:0'), 'edge_index': tensor([[  0,   1,   0,  ..., 997, 998, 999],\n",
      "        [  1,   0,   2,  ..., 997, 998, 999]], device='cuda:0')}\n",
      "[tensor([[-0.1977],\n",
      "        [-0.8811],\n",
      "        [-0.4304],\n",
      "        ...,\n",
      "        [ 0.0798],\n",
      "        [ 0.6826],\n",
      "        [-0.5918]], device='cuda:0', grad_fn=<IndexBackward>), tensor([0.0022, 0.0022, 0.0021,  ..., 0.0021, 0.0022, 0.0023], device='cuda:0')]\n",
      "epoch-loss:  0 tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "['x_j', 'norm']\n",
      "{'x': tensor([[ 0.5269, -0.1071,  0.4654,  ...,  0.4200, -0.4151, -0.4665],\n",
      "        [ 0.5269, -0.1071,  0.4654,  ...,  0.4200, -0.4151, -0.4665],\n",
      "        [ 0.5269, -0.1071,  0.4654,  ...,  0.4200, -0.4151, -0.4665],\n",
      "        ...,\n",
      "        [ 0.5269, -0.1071,  0.4654,  ...,  0.4200, -0.4151, -0.4665],\n",
      "        [ 0.5269, -0.1071,  0.4654,  ...,  0.4200, -0.4151, -0.4665],\n",
      "        [ 0.5269, -0.1071,  0.4654,  ...,  0.4200, -0.4151, -0.4665]],\n",
      "       device='cuda:0', grad_fn=<MmBackward>), 'norm': tensor([0.0022, 0.0022, 0.0021,  ..., 0.0021, 0.0022, 0.0023], device='cuda:0'), 'edge_index': tensor([[  0,   1,   0,  ..., 997, 998, 999],\n",
      "        [  1,   0,   2,  ..., 997, 998, 999]], device='cuda:0')}\n",
      "[tensor([[ 0.5269, -0.1071,  0.4654,  ...,  0.4200, -0.4151, -0.4665],\n",
      "        [ 0.5269, -0.1071,  0.4654,  ...,  0.4200, -0.4151, -0.4665],\n",
      "        [ 0.5269, -0.1071,  0.4654,  ...,  0.4200, -0.4151, -0.4665],\n",
      "        ...,\n",
      "        [ 0.5269, -0.1071,  0.4654,  ...,  0.4200, -0.4151, -0.4665],\n",
      "        [ 0.5269, -0.1071,  0.4654,  ...,  0.4200, -0.4151, -0.4665],\n",
      "        [ 0.5269, -0.1071,  0.4654,  ...,  0.4200, -0.4151, -0.4665]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward>), tensor([0.0022, 0.0022, 0.0021,  ..., 0.0021, 0.0022, 0.0023], device='cuda:0')]\n",
      "['x_j', 'norm']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[-0.0587],\n",
      "        [-0.0546],\n",
      "        [-0.0559],\n",
      "        [-0.0537],\n",
      "        [-0.0569],\n",
      "        [-0.0569],\n",
      "        [-0.0544],\n",
      "        [-0.0555],\n",
      "        [-0.0551],\n",
      "        [-0.0566],\n",
      "        [-0.0566],\n",
      "        [-0.0562],\n",
      "        [-0.0572],\n",
      "        [-0.0548],\n",
      "        [-0.0547],\n",
      "        [-0.0578],\n",
      "        [-0.0541],\n",
      "        [-0.0573],\n",
      "        [-0.0551],\n",
      "        [-0.0589],\n",
      "        [-0.0539],\n",
      "        [-0.0534],\n",
      "        [-0.0561],\n",
      "        [-0.0544],\n",
      "        [-0.0530],\n",
      "        [-0.0557],\n",
      "        [-0.0528],\n",
      "        [-0.0556],\n",
      "        [-0.0556],\n",
      "        [-0.0566],\n",
      "        [-0.0569],\n",
      "        [-0.0546],\n",
      "        [-0.0543],\n",
      "        [-0.0558],\n",
      "        [-0.0563],\n",
      "        [-0.0548],\n",
      "        [-0.0550],\n",
      "        [-0.0571],\n",
      "        [-0.0545],\n",
      "        [-0.0554],\n",
      "        [-0.0543],\n",
      "        [-0.0552],\n",
      "        [-0.0541],\n",
      "        [-0.0568],\n",
      "        [-0.0536],\n",
      "        [-0.0571],\n",
      "        [-0.0549],\n",
      "        [-0.0569],\n",
      "        [-0.0535],\n",
      "        [-0.0568],\n",
      "        [-0.0562],\n",
      "        [-0.0540],\n",
      "        [-0.0537],\n",
      "        [-0.0568],\n",
      "        [-0.0558],\n",
      "        [-0.0561],\n",
      "        [-0.0544],\n",
      "        [-0.0582],\n",
      "        [-0.0573],\n",
      "        [-0.0565],\n",
      "        [-0.0541],\n",
      "        [-0.0537],\n",
      "        [-0.0551],\n",
      "        [-0.0566],\n",
      "        [-0.0549],\n",
      "        [-0.0554],\n",
      "        [-0.0553],\n",
      "        [-0.0565],\n",
      "        [-0.0559],\n",
      "        [-0.0545],\n",
      "        [-0.0578],\n",
      "        [-0.0546],\n",
      "        [-0.0566],\n",
      "        [-0.0543],\n",
      "        [-0.0547],\n",
      "        [-0.0569],\n",
      "        [-0.0579],\n",
      "        [-0.0540],\n",
      "        [-0.0563],\n",
      "        [-0.0554],\n",
      "        [-0.0549],\n",
      "        [-0.0542],\n",
      "        [-0.0566],\n",
      "        [-0.0569],\n",
      "        [-0.0532],\n",
      "        [-0.0565],\n",
      "        [-0.0537],\n",
      "        [-0.0549],\n",
      "        [-0.0592],\n",
      "        [-0.0549],\n",
      "        [-0.0540],\n",
      "        [-0.0551],\n",
      "        [-0.0568],\n",
      "        [-0.0558],\n",
      "        [-0.0559],\n",
      "        [-0.0570],\n",
      "        [-0.0561],\n",
      "        [-0.0537],\n",
      "        [-0.0550],\n",
      "        [-0.0581],\n",
      "        [-0.0537],\n",
      "        [-0.0557],\n",
      "        [-0.0536],\n",
      "        [-0.0530],\n",
      "        [-0.0543],\n",
      "        [-0.0567],\n",
      "        [-0.0561],\n",
      "        [-0.0551],\n",
      "        [-0.0583],\n",
      "        [-0.0595],\n",
      "        [-0.0560],\n",
      "        [-0.0529],\n",
      "        [-0.0548],\n",
      "        [-0.0567],\n",
      "        [-0.0554],\n",
      "        [-0.0562],\n",
      "        [-0.0549],\n",
      "        [-0.0567],\n",
      "        [-0.0567],\n",
      "        [-0.0571],\n",
      "        [-0.0548],\n",
      "        [-0.0546],\n",
      "        [-0.0548],\n",
      "        [-0.0558],\n",
      "        [-0.0541],\n",
      "        [-0.0572],\n",
      "        [-0.0564],\n",
      "        [-0.0536],\n",
      "        [-0.0572],\n",
      "        [-0.0568],\n",
      "        [-0.0543],\n",
      "        [-0.0536],\n",
      "        [-0.0572],\n",
      "        [-0.0568],\n",
      "        [-0.0534],\n",
      "        [-0.0550],\n",
      "        [-0.0566],\n",
      "        [-0.0530],\n",
      "        [-0.0561],\n",
      "        [-0.0559],\n",
      "        [-0.0566],\n",
      "        [-0.0544],\n",
      "        [-0.0533],\n",
      "        [-0.0550],\n",
      "        [-0.0557],\n",
      "        [-0.0555],\n",
      "        [-0.0537],\n",
      "        [-0.0540],\n",
      "        [-0.0537],\n",
      "        [-0.0554],\n",
      "        [-0.0560],\n",
      "        [-0.0549],\n",
      "        [-0.0572],\n",
      "        [-0.0566],\n",
      "        [-0.0551],\n",
      "        [-0.0536],\n",
      "        [-0.0568],\n",
      "        [-0.0545],\n",
      "        [-0.0555],\n",
      "        [-0.0559],\n",
      "        [-0.0565],\n",
      "        [-0.0561],\n",
      "        [-0.0539],\n",
      "        [-0.0576],\n",
      "        [-0.0573],\n",
      "        [-0.0536],\n",
      "        [-0.0497],\n",
      "        [-0.0561],\n",
      "        [-0.0561],\n",
      "        [-0.0561],\n",
      "        [-0.0546],\n",
      "        [-0.0522],\n",
      "        [-0.0548],\n",
      "        [-0.0562],\n",
      "        [-0.0553],\n",
      "        [-0.0553],\n",
      "        [-0.0571],\n",
      "        [-0.0569],\n",
      "        [-0.0571],\n",
      "        [-0.0561],\n",
      "        [-0.0536],\n",
      "        [-0.0562],\n",
      "        [-0.0552],\n",
      "        [-0.0584],\n",
      "        [-0.0575],\n",
      "        [-0.0554],\n",
      "        [-0.0536],\n",
      "        [-0.0540],\n",
      "        [-0.0579],\n",
      "        [-0.0549],\n",
      "        [-0.0581],\n",
      "        [-0.0572],\n",
      "        [-0.0565],\n",
      "        [-0.0557],\n",
      "        [-0.0558],\n",
      "        [-0.0570],\n",
      "        [-0.0559],\n",
      "        [-0.0588],\n",
      "        [-0.0555],\n",
      "        [-0.0569],\n",
      "        [-0.0572],\n",
      "        [-0.0558],\n",
      "        [-0.0554],\n",
      "        [-0.0541],\n",
      "        [-0.0551],\n",
      "        [-0.0558],\n",
      "        [-0.0573],\n",
      "        [-0.0566],\n",
      "        [-0.0546],\n",
      "        [-0.0553],\n",
      "        [-0.0578],\n",
      "        [-0.0550],\n",
      "        [-0.0557],\n",
      "        [-0.0577],\n",
      "        [-0.0532],\n",
      "        [-0.0572],\n",
      "        [-0.0566],\n",
      "        [-0.0553],\n",
      "        [-0.0534],\n",
      "        [-0.0540],\n",
      "        [-0.0545],\n",
      "        [-0.0557],\n",
      "        [-0.0549],\n",
      "        [-0.0556],\n",
      "        [-0.0547],\n",
      "        [-0.0554],\n",
      "        [-0.0559],\n",
      "        [-0.0555],\n",
      "        [-0.0564],\n",
      "        [-0.0556],\n",
      "        [-0.0581],\n",
      "        [-0.0557],\n",
      "        [-0.0548],\n",
      "        [-0.0551],\n",
      "        [-0.0572],\n",
      "        [-0.0561],\n",
      "        [-0.0585],\n",
      "        [-0.0551],\n",
      "        [-0.0569],\n",
      "        [-0.0558],\n",
      "        [-0.0535],\n",
      "        [-0.0549],\n",
      "        [-0.0564],\n",
      "        [-0.0537],\n",
      "        [-0.0543],\n",
      "        [-0.0564],\n",
      "        [-0.0582],\n",
      "        [-0.0555],\n",
      "        [-0.0537],\n",
      "        [-0.0562],\n",
      "        [-0.0545],\n",
      "        [-0.0542],\n",
      "        [-0.0552],\n",
      "        [-0.0552],\n",
      "        [-0.0559],\n",
      "        [-0.0543],\n",
      "        [-0.0555],\n",
      "        [-0.0544],\n",
      "        [-0.0550],\n",
      "        [-0.0551],\n",
      "        [-0.0547],\n",
      "        [-0.0557],\n",
      "        [-0.0574],\n",
      "        [-0.0599],\n",
      "        [-0.0560],\n",
      "        [-0.0572],\n",
      "        [-0.0570],\n",
      "        [-0.0552],\n",
      "        [-0.0571],\n",
      "        [-0.0575],\n",
      "        [-0.0548],\n",
      "        [-0.0564],\n",
      "        [-0.0537],\n",
      "        [-0.0557],\n",
      "        [-0.0544],\n",
      "        [-0.0538],\n",
      "        [-0.0559],\n",
      "        [-0.0550],\n",
      "        [-0.0537],\n",
      "        [-0.0586],\n",
      "        [-0.0559],\n",
      "        [-0.0546],\n",
      "        [-0.0555],\n",
      "        [-0.0551],\n",
      "        [-0.0535],\n",
      "        [-0.0555],\n",
      "        [-0.0558],\n",
      "        [-0.0546],\n",
      "        [-0.0543],\n",
      "        [-0.0531],\n",
      "        [-0.0575],\n",
      "        [-0.0531],\n",
      "        [-0.0560],\n",
      "        [-0.0570],\n",
      "        [-0.0536],\n",
      "        [-0.0586],\n",
      "        [-0.0572],\n",
      "        [-0.0554],\n",
      "        [-0.0555],\n",
      "        [-0.0537],\n",
      "        [-0.0539],\n",
      "        [-0.0566],\n",
      "        [-0.0541],\n",
      "        [-0.0559],\n",
      "        [-0.0537],\n",
      "        [-0.0536],\n",
      "        [-0.0586],\n",
      "        [-0.0540],\n",
      "        [-0.0534],\n",
      "        [-0.0547],\n",
      "        [-0.0550],\n",
      "        [-0.0563],\n",
      "        [-0.0558],\n",
      "        [-0.0536],\n",
      "        [-0.0552],\n",
      "        [-0.0560],\n",
      "        [-0.0563],\n",
      "        [-0.0569],\n",
      "        [-0.0555],\n",
      "        [-0.0544],\n",
      "        [-0.0550],\n",
      "        [-0.0525],\n",
      "        [-0.0551],\n",
      "        [-0.0576],\n",
      "        [-0.0583],\n",
      "        [-0.0565],\n",
      "        [-0.0528],\n",
      "        [-0.0529],\n",
      "        [-0.0528],\n",
      "        [-0.0581],\n",
      "        [-0.0573],\n",
      "        [-0.0566],\n",
      "        [-0.0540],\n",
      "        [-0.0584],\n",
      "        [-0.0566],\n",
      "        [-0.0530],\n",
      "        [-0.0583],\n",
      "        [-0.0547],\n",
      "        [-0.0571],\n",
      "        [-0.0559],\n",
      "        [-0.0580],\n",
      "        [-0.0572],\n",
      "        [-0.0537],\n",
      "        [-0.0542],\n",
      "        [-0.0570],\n",
      "        [-0.0553],\n",
      "        [-0.0555],\n",
      "        [-0.0580],\n",
      "        [-0.0555],\n",
      "        [-0.0542],\n",
      "        [-0.0575],\n",
      "        [-0.0555],\n",
      "        [-0.0560],\n",
      "        [-0.0537],\n",
      "        [-0.0551],\n",
      "        [-0.0548],\n",
      "        [-0.0549],\n",
      "        [-0.0543],\n",
      "        [-0.0568],\n",
      "        [-0.0578],\n",
      "        [-0.0573],\n",
      "        [-0.0520],\n",
      "        [-0.0554],\n",
      "        [-0.0575],\n",
      "        [-0.0531],\n",
      "        [-0.0566],\n",
      "        [-0.0530],\n",
      "        [-0.0538],\n",
      "        [-0.0582],\n",
      "        [-0.0567],\n",
      "        [-0.0547],\n",
      "        [-0.0543],\n",
      "        [-0.0544],\n",
      "        [-0.0556],\n",
      "        [-0.0509],\n",
      "        [-0.0548],\n",
      "        [-0.0558],\n",
      "        [-0.0560],\n",
      "        [-0.0538],\n",
      "        [-0.0548],\n",
      "        [-0.0576],\n",
      "        [-0.0572],\n",
      "        [-0.0571],\n",
      "        [-0.0588],\n",
      "        [-0.0567],\n",
      "        [-0.0554],\n",
      "        [-0.0580],\n",
      "        [-0.0552],\n",
      "        [-0.0566],\n",
      "        [-0.0551],\n",
      "        [-0.0533],\n",
      "        [-0.0558],\n",
      "        [-0.0564],\n",
      "        [-0.0571],\n",
      "        [-0.0546],\n",
      "        [-0.0541],\n",
      "        [-0.0554],\n",
      "        [-0.0569],\n",
      "        [-0.0579],\n",
      "        [-0.0554],\n",
      "        [-0.0552],\n",
      "        [-0.0545],\n",
      "        [-0.0548],\n",
      "        [-0.0547],\n",
      "        [-0.0540],\n",
      "        [-0.0552],\n",
      "        [-0.0544],\n",
      "        [-0.0545],\n",
      "        [-0.0537],\n",
      "        [-0.0533],\n",
      "        [-0.0530],\n",
      "        [-0.0576],\n",
      "        [-0.0541],\n",
      "        [-0.0558],\n",
      "        [-0.0551],\n",
      "        [-0.0547],\n",
      "        [-0.0540],\n",
      "        [-0.0535],\n",
      "        [-0.0567],\n",
      "        [-0.0542],\n",
      "        [-0.0535],\n",
      "        [-0.0550],\n",
      "        [-0.0555],\n",
      "        [-0.0551],\n",
      "        [-0.0567],\n",
      "        [-0.0563],\n",
      "        [-0.0566],\n",
      "        [-0.0579],\n",
      "        [-0.0581],\n",
      "        [-0.0569],\n",
      "        [-0.0558],\n",
      "        [-0.0551],\n",
      "        [-0.0551],\n",
      "        [-0.0553],\n",
      "        [-0.0557],\n",
      "        [-0.0574],\n",
      "        [-0.0541],\n",
      "        [-0.0579],\n",
      "        [-0.0539],\n",
      "        [-0.0564],\n",
      "        [-0.0589],\n",
      "        [-0.0540],\n",
      "        [-0.0556],\n",
      "        [-0.0556],\n",
      "        [-0.0548],\n",
      "        [-0.0545],\n",
      "        [-0.0574],\n",
      "        [-0.0525],\n",
      "        [-0.0577],\n",
      "        [-0.0565],\n",
      "        [-0.0554],\n",
      "        [-0.0574],\n",
      "        [-0.0580],\n",
      "        [-0.0567],\n",
      "        [-0.0554],\n",
      "        [-0.0560],\n",
      "        [-0.0557],\n",
      "        [-0.0546],\n",
      "        [-0.0552],\n",
      "        [-0.0571],\n",
      "        [-0.0558],\n",
      "        [-0.0558],\n",
      "        [-0.0577],\n",
      "        [-0.0560],\n",
      "        [-0.0555],\n",
      "        [-0.0555],\n",
      "        [-0.0564],\n",
      "        [-0.0566],\n",
      "        [-0.0553],\n",
      "        [-0.0567],\n",
      "        [-0.0558],\n",
      "        [-0.0566],\n",
      "        [-0.0541],\n",
      "        [-0.0578],\n",
      "        [-0.0582],\n",
      "        [-0.0553],\n",
      "        [-0.0537],\n",
      "        [-0.0548],\n",
      "        [-0.0539],\n",
      "        [-0.0559],\n",
      "        [-0.0553],\n",
      "        [-0.0535],\n",
      "        [-0.0565],\n",
      "        [-0.0566],\n",
      "        [-0.0536],\n",
      "        [-0.0549],\n",
      "        [-0.0560],\n",
      "        [-0.0563],\n",
      "        [-0.0547],\n",
      "        [-0.0537],\n",
      "        [-0.0550],\n",
      "        [-0.0571],\n",
      "        [-0.0579],\n",
      "        [-0.0571],\n",
      "        [-0.0554],\n",
      "        [-0.0537],\n",
      "        [-0.0544],\n",
      "        [-0.0558],\n",
      "        [-0.0576],\n",
      "        [-0.0549],\n",
      "        [-0.0569],\n",
      "        [-0.0593],\n",
      "        [-0.0564],\n",
      "        [-0.0569],\n",
      "        [-0.0544],\n",
      "        [-0.0544],\n",
      "        [-0.0544],\n",
      "        [-0.0574],\n",
      "        [-0.0542],\n",
      "        [-0.0551],\n",
      "        [-0.0569],\n",
      "        [-0.0565],\n",
      "        [-0.0526],\n",
      "        [-0.0551],\n",
      "        [-0.0560],\n",
      "        [-0.0579],\n",
      "        [-0.0569],\n",
      "        [-0.0568],\n",
      "        [-0.0539],\n",
      "        [-0.0551],\n",
      "        [-0.0545],\n",
      "        [-0.0591],\n",
      "        [-0.0558],\n",
      "        [-0.0567],\n",
      "        [-0.0558],\n",
      "        [-0.0553],\n",
      "        [-0.0564],\n",
      "        [-0.0527],\n",
      "        [-0.0545],\n",
      "        [-0.0540],\n",
      "        [-0.0539],\n",
      "        [-0.0558],\n",
      "        [-0.0547],\n",
      "        [-0.0582],\n",
      "        [-0.0565],\n",
      "        [-0.0549],\n",
      "        [-0.0539],\n",
      "        [-0.0543],\n",
      "        [-0.0560],\n",
      "        [-0.0543],\n",
      "        [-0.0550],\n",
      "        [-0.0535],\n",
      "        [-0.0578],\n",
      "        [-0.0563],\n",
      "        [-0.0571],\n",
      "        [-0.0556],\n",
      "        [-0.0576],\n",
      "        [-0.0544],\n",
      "        [-0.0550],\n",
      "        [-0.0529],\n",
      "        [-0.0571],\n",
      "        [-0.0565],\n",
      "        [-0.0556],\n",
      "        [-0.0534],\n",
      "        [-0.0554],\n",
      "        [-0.0573],\n",
      "        [-0.0583],\n",
      "        [-0.0543],\n",
      "        [-0.0558],\n",
      "        [-0.0547],\n",
      "        [-0.0537],\n",
      "        [-0.0536],\n",
      "        [-0.0596],\n",
      "        [-0.0537],\n",
      "        [-0.0556],\n",
      "        [-0.0552],\n",
      "        [-0.0546],\n",
      "        [-0.0570],\n",
      "        [-0.0529],\n",
      "        [-0.0572],\n",
      "        [-0.0566],\n",
      "        [-0.0571],\n",
      "        [-0.0561],\n",
      "        [-0.0567],\n",
      "        [-0.0557],\n",
      "        [-0.0528],\n",
      "        [-0.0568],\n",
      "        [-0.0563],\n",
      "        [-0.0544],\n",
      "        [-0.0552],\n",
      "        [-0.0527],\n",
      "        [-0.0557],\n",
      "        [-0.0558],\n",
      "        [-0.0548],\n",
      "        [-0.0537],\n",
      "        [-0.0571],\n",
      "        [-0.0580],\n",
      "        [-0.0558],\n",
      "        [-0.0563],\n",
      "        [-0.0565],\n",
      "        [-0.0536],\n",
      "        [-0.0570],\n",
      "        [-0.0549],\n",
      "        [-0.0537],\n",
      "        [-0.0540],\n",
      "        [-0.0555],\n",
      "        [-0.0573],\n",
      "        [-0.0537],\n",
      "        [-0.0567],\n",
      "        [-0.0554],\n",
      "        [-0.0550],\n",
      "        [-0.0556],\n",
      "        [-0.0567],\n",
      "        [-0.0547],\n",
      "        [-0.0573],\n",
      "        [-0.0524],\n",
      "        [-0.0595],\n",
      "        [-0.0555],\n",
      "        [-0.0553],\n",
      "        [-0.0562],\n",
      "        [-0.0586],\n",
      "        [-0.0562],\n",
      "        [-0.0582],\n",
      "        [-0.0555],\n",
      "        [-0.0540],\n",
      "        [-0.0539],\n",
      "        [-0.0565],\n",
      "        [-0.0548],\n",
      "        [-0.0560],\n",
      "        [-0.0572],\n",
      "        [-0.0538],\n",
      "        [-0.0560],\n",
      "        [-0.0565],\n",
      "        [-0.0544],\n",
      "        [-0.0585],\n",
      "        [-0.0549],\n",
      "        [-0.0564],\n",
      "        [-0.0551],\n",
      "        [-0.0568],\n",
      "        [-0.0563],\n",
      "        [-0.0549],\n",
      "        [-0.0576],\n",
      "        [-0.0533],\n",
      "        [-0.0558],\n",
      "        [-0.0557],\n",
      "        [-0.0554],\n",
      "        [-0.0550],\n",
      "        [-0.0543],\n",
      "        [-0.0570],\n",
      "        [-0.0562],\n",
      "        [-0.0565],\n",
      "        [-0.0556],\n",
      "        [-0.0530],\n",
      "        [-0.0553],\n",
      "        [-0.0563],\n",
      "        [-0.0554],\n",
      "        [-0.0554],\n",
      "        [-0.0571],\n",
      "        [-0.0549],\n",
      "        [-0.0548],\n",
      "        [-0.0556],\n",
      "        [-0.0578],\n",
      "        [-0.0587],\n",
      "        [-0.0588],\n",
      "        [-0.0572],\n",
      "        [-0.0571],\n",
      "        [-0.0529],\n",
      "        [-0.0540],\n",
      "        [-0.0561],\n",
      "        [-0.0542],\n",
      "        [-0.0560],\n",
      "        [-0.0565],\n",
      "        [-0.0552],\n",
      "        [-0.0549],\n",
      "        [-0.0537],\n",
      "        [-0.0550],\n",
      "        [-0.0565],\n",
      "        [-0.0544],\n",
      "        [-0.0545],\n",
      "        [-0.0543],\n",
      "        [-0.0563],\n",
      "        [-0.0581],\n",
      "        [-0.0550],\n",
      "        [-0.0578],\n",
      "        [-0.0542],\n",
      "        [-0.0555],\n",
      "        [-0.0521],\n",
      "        [-0.0546],\n",
      "        [-0.0564],\n",
      "        [-0.0522],\n",
      "        [-0.0547],\n",
      "        [-0.0526],\n",
      "        [-0.0559],\n",
      "        [-0.0554],\n",
      "        [-0.0571],\n",
      "        [-0.0576],\n",
      "        [-0.0539],\n",
      "        [-0.0572],\n",
      "        [-0.0547],\n",
      "        [-0.0559],\n",
      "        [-0.0561],\n",
      "        [-0.0567],\n",
      "        [-0.0540],\n",
      "        [-0.0561],\n",
      "        [-0.0543],\n",
      "        [-0.0542],\n",
      "        [-0.0559],\n",
      "        [-0.0548],\n",
      "        [-0.0568],\n",
      "        [-0.0554],\n",
      "        [-0.0577],\n",
      "        [-0.0583],\n",
      "        [-0.0566],\n",
      "        [-0.0541],\n",
      "        [-0.0561],\n",
      "        [-0.0565],\n",
      "        [-0.0555],\n",
      "        [-0.0545],\n",
      "        [-0.0567],\n",
      "        [-0.0554],\n",
      "        [-0.0550],\n",
      "        [-0.0551],\n",
      "        [-0.0559],\n",
      "        [-0.0537],\n",
      "        [-0.0566],\n",
      "        [-0.0555],\n",
      "        [-0.0575],\n",
      "        [-0.0543],\n",
      "        [-0.0527],\n",
      "        [-0.0559],\n",
      "        [-0.0549],\n",
      "        [-0.0542],\n",
      "        [-0.0585],\n",
      "        [-0.0557],\n",
      "        [-0.0539],\n",
      "        [-0.0593],\n",
      "        [-0.0554],\n",
      "        [-0.0585],\n",
      "        [-0.0551],\n",
      "        [-0.0544],\n",
      "        [-0.0567],\n",
      "        [-0.0571],\n",
      "        [-0.0536],\n",
      "        [-0.0550],\n",
      "        [-0.0575],\n",
      "        [-0.0571],\n",
      "        [-0.0536],\n",
      "        [-0.0566],\n",
      "        [-0.0563],\n",
      "        [-0.0570],\n",
      "        [-0.0537],\n",
      "        [-0.0564],\n",
      "        [-0.0553],\n",
      "        [-0.0555],\n",
      "        [-0.0553],\n",
      "        [-0.0558],\n",
      "        [-0.0557],\n",
      "        [-0.0546],\n",
      "        [-0.0552],\n",
      "        [-0.0567],\n",
      "        [-0.0569],\n",
      "        [-0.0540],\n",
      "        [-0.0561],\n",
      "        [-0.0538],\n",
      "        [-0.0555],\n",
      "        [-0.0534],\n",
      "        [-0.0549],\n",
      "        [-0.0553],\n",
      "        [-0.0517],\n",
      "        [-0.0549],\n",
      "        [-0.0553],\n",
      "        [-0.0584],\n",
      "        [-0.0550],\n",
      "        [-0.0557],\n",
      "        [-0.0563],\n",
      "        [-0.0588],\n",
      "        [-0.0560],\n",
      "        [-0.0569],\n",
      "        [-0.0567],\n",
      "        [-0.0548],\n",
      "        [-0.0513],\n",
      "        [-0.0551],\n",
      "        [-0.0576],\n",
      "        [-0.0573],\n",
      "        [-0.0542],\n",
      "        [-0.0578],\n",
      "        [-0.0534],\n",
      "        [-0.0569],\n",
      "        [-0.0558],\n",
      "        [-0.0562],\n",
      "        [-0.0546],\n",
      "        [-0.0568],\n",
      "        [-0.0565],\n",
      "        [-0.0556],\n",
      "        [-0.0557],\n",
      "        [-0.0530],\n",
      "        [-0.0574],\n",
      "        [-0.0539],\n",
      "        [-0.0552],\n",
      "        [-0.0542],\n",
      "        [-0.0570],\n",
      "        [-0.0560],\n",
      "        [-0.0533],\n",
      "        [-0.0588],\n",
      "        [-0.0577],\n",
      "        [-0.0565],\n",
      "        [-0.0544],\n",
      "        [-0.0551],\n",
      "        [-0.0554],\n",
      "        [-0.0545],\n",
      "        [-0.0556],\n",
      "        [-0.0556],\n",
      "        [-0.0571],\n",
      "        [-0.0521],\n",
      "        [-0.0541],\n",
      "        [-0.0543],\n",
      "        [-0.0552],\n",
      "        [-0.0554],\n",
      "        [-0.0584],\n",
      "        [-0.0534],\n",
      "        [-0.0536],\n",
      "        [-0.0566],\n",
      "        [-0.0553],\n",
      "        [-0.0547],\n",
      "        [-0.0548],\n",
      "        [-0.0554],\n",
      "        [-0.0547],\n",
      "        [-0.0568],\n",
      "        [-0.0533],\n",
      "        [-0.0546],\n",
      "        [-0.0565],\n",
      "        [-0.0526],\n",
      "        [-0.0552],\n",
      "        [-0.0555],\n",
      "        [-0.0540],\n",
      "        [-0.0554],\n",
      "        [-0.0528],\n",
      "        [-0.0567],\n",
      "        [-0.0547],\n",
      "        [-0.0550],\n",
      "        [-0.0542],\n",
      "        [-0.0536],\n",
      "        [-0.0553],\n",
      "        [-0.0549],\n",
      "        [-0.0559],\n",
      "        [-0.0539],\n",
      "        [-0.0550],\n",
      "        [-0.0589],\n",
      "        [-0.0554],\n",
      "        [-0.0569],\n",
      "        [-0.0550],\n",
      "        [-0.0540],\n",
      "        [-0.0526],\n",
      "        [-0.0554],\n",
      "        [-0.0542],\n",
      "        [-0.0545],\n",
      "        [-0.0565],\n",
      "        [-0.0539],\n",
      "        [-0.0561],\n",
      "        [-0.0546],\n",
      "        [-0.0530],\n",
      "        [-0.0565],\n",
      "        [-0.0547],\n",
      "        [-0.0570],\n",
      "        [-0.0553],\n",
      "        [-0.0540],\n",
      "        [-0.0569],\n",
      "        [-0.0570],\n",
      "        [-0.0561],\n",
      "        [-0.0564],\n",
      "        [-0.0551],\n",
      "        [-0.0572],\n",
      "        [-0.0536],\n",
      "        [-0.0548],\n",
      "        [-0.0556],\n",
      "        [-0.0550],\n",
      "        [-0.0573],\n",
      "        [-0.0553],\n",
      "        [-0.0543],\n",
      "        [-0.0577],\n",
      "        [-0.0576],\n",
      "        [-0.0565],\n",
      "        [-0.0569],\n",
      "        [-0.0558],\n",
      "        [-0.0536],\n",
      "        [-0.0536],\n",
      "        [-0.0568],\n",
      "        [-0.0546],\n",
      "        [-0.0551],\n",
      "        [-0.0572],\n",
      "        [-0.0548],\n",
      "        [-0.0575],\n",
      "        [-0.0562],\n",
      "        [-0.0570],\n",
      "        [-0.0567],\n",
      "        [-0.0546],\n",
      "        [-0.0521],\n",
      "        [-0.0553],\n",
      "        [-0.0541],\n",
      "        [-0.0575],\n",
      "        [-0.0556],\n",
      "        [-0.0539],\n",
      "        [-0.0558],\n",
      "        [-0.0548],\n",
      "        [-0.0572],\n",
      "        [-0.0554],\n",
      "        [-0.0560],\n",
      "        [-0.0551],\n",
      "        [-0.0539],\n",
      "        [-0.0571],\n",
      "        [-0.0545],\n",
      "        [-0.0570],\n",
      "        [-0.0551],\n",
      "        [-0.0537],\n",
      "        [-0.0555],\n",
      "        [-0.0568],\n",
      "        [-0.0574],\n",
      "        [-0.0568],\n",
      "        [-0.0539],\n",
      "        [-0.0531],\n",
      "        [-0.0544],\n",
      "        [-0.0567],\n",
      "        [-0.0556],\n",
      "        [-0.0557],\n",
      "        [-0.0569],\n",
      "        [-0.0563],\n",
      "        [-0.0566],\n",
      "        [-0.0524],\n",
      "        [-0.0545],\n",
      "        [-0.0566],\n",
      "        [-0.0585],\n",
      "        [-0.0542],\n",
      "        [-0.0533],\n",
      "        [-0.0560],\n",
      "        [-0.0550],\n",
      "        [-0.0526],\n",
      "        [-0.0543],\n",
      "        [-0.0569],\n",
      "        [-0.0560],\n",
      "        [-0.0577],\n",
      "        [-0.0571],\n",
      "        [-0.0560],\n",
      "        [-0.0555],\n",
      "        [-0.0527],\n",
      "        [-0.0573],\n",
      "        [-0.0579],\n",
      "        [-0.0565],\n",
      "        [-0.0560],\n",
      "        [-0.0573],\n",
      "        [-0.0536],\n",
      "        [-0.0562],\n",
      "        [-0.0560],\n",
      "        [-0.0550],\n",
      "        [-0.0542],\n",
      "        [-0.0562],\n",
      "        [-0.0552],\n",
      "        [-0.0548],\n",
      "        [-0.0584],\n",
      "        [-0.0562],\n",
      "        [-0.0582],\n",
      "        [-0.0545],\n",
      "        [-0.0543],\n",
      "        [-0.0535],\n",
      "        [-0.0559],\n",
      "        [-0.0534],\n",
      "        [-0.0569],\n",
      "        [-0.0560],\n",
      "        [-0.0566],\n",
      "        [-0.0569],\n",
      "        [-0.0566],\n",
      "        [-0.0544],\n",
      "        [-0.0536],\n",
      "        [-0.0547],\n",
      "        [-0.0551],\n",
      "        [-0.0550],\n",
      "        [-0.0550],\n",
      "        [-0.0550],\n",
      "        [-0.0573],\n",
      "        [-0.0566],\n",
      "        [-0.0580],\n",
      "        [-0.0551],\n",
      "        [-0.0584],\n",
      "        [-0.0572],\n",
      "        [-0.0556],\n",
      "        [-0.0524],\n",
      "        [-0.0559],\n",
      "        [-0.0548],\n",
      "        [-0.0531],\n",
      "        [-0.0578],\n",
      "        [-0.0573],\n",
      "        [-0.0547],\n",
      "        [-0.0549],\n",
      "        [-0.0532],\n",
      "        [-0.0585],\n",
      "        [-0.0524],\n",
      "        [-0.0573],\n",
      "        [-0.0539],\n",
      "        [-0.0586],\n",
      "        [-0.0563],\n",
      "        [-0.0537],\n",
      "        [-0.0548],\n",
      "        [-0.0542],\n",
      "        [-0.0577],\n",
      "        [-0.0573],\n",
      "        [-0.0588],\n",
      "        [-0.0554],\n",
      "        [-0.0551],\n",
      "        [-0.0571],\n",
      "        [-0.0564],\n",
      "        [-0.0544]], device='cuda:0', grad_fn=<MmBackward>), 'norm': tensor([0.0022, 0.0022, 0.0021,  ..., 0.0021, 0.0022, 0.0023], device='cuda:0'), 'edge_index': tensor([[  0,   1,   0,  ..., 997, 998, 999],\n",
      "        [  1,   0,   2,  ..., 997, 998, 999]], device='cuda:0')}\n",
      "[tensor([[-0.0546],\n",
      "        [-0.0587],\n",
      "        [-0.0559],\n",
      "        ...,\n",
      "        [-0.0571],\n",
      "        [-0.0564],\n",
      "        [-0.0544]], device='cuda:0', grad_fn=<IndexBackward>), tensor([0.0022, 0.0022, 0.0021,  ..., 0.0021, 0.0022, 0.0023], device='cuda:0')]\n",
      "RMSE:  tensor(1.2219, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Total train-test time: 0.21542096138000488\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data', 'filename', 'num_classes', 'num_features']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = loadDataset(collection='MyOwnDataset2', name='precomputed/er_1000_0_45_nb.pickle')\n",
    "global Net\n",
    "Net=Net1(d1=20)\n",
    "trainTestEval(dataset,  epochs=1)\n",
    "del Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch_geometric.data.dataloader.DataLoader object at 0x7f0c3d2a70f0>\n",
      "['_DataLoader__initialized', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'batch_sampler', 'batch_size', 'collate_fn', 'dataset', 'drop_last', 'num_workers', 'pin_memory', 'sampler', 'timeout', 'worker_init_fn']\n",
      "Data(edge_index=[2, 449110], x=[1000, 1], y=[1000])\n",
      "epoch-loss:  0 tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  25 tensor(5.6608e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  50 tensor(3.4854e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  75 tensor(1.4919e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  100 tensor(9.4465e-07, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  125 tensor(5.5526e-07, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  150 tensor(4.2140e-07, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  175 tensor(2.2137e-07, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "RMSE:  tensor(0.0027, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Total train-test time: 22.22233486175537\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data', 'filename', 'num_classes', 'num_features']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = loadDataset(collection='MyOwnDataset2', name='precomputed/er_1000_0_45_nb.pickle')\n",
    "global Net\n",
    "Net=Net2(d1=30,d2=10)\n",
    "trainTestEval(dataset,  epochs=1)\n",
    "del Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch_geometric.data.dataloader.DataLoader object at 0x7f0c3d2a7630>\n",
      "['_DataLoader__initialized', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'batch_sampler', 'batch_size', 'collate_fn', 'dataset', 'drop_last', 'num_workers', 'pin_memory', 'sampler', 'timeout', 'worker_init_fn']\n",
      "Data(edge_index=[2, 149596], x=[1000, 1], y=[1000])\n",
      "epoch-loss:  0 tensor(0.0105, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  25 tensor(3.9370e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  50 tensor(7.9181e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  75 tensor(5.0373e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  100 tensor(2.3855e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  125 tensor(1.3804e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  150 tensor(7.8238e-07, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  175 tensor(5.2753e-07, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "RMSE:  tensor(0.0051, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Total train-test time: 7.01012921333313\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data', 'filename', 'num_classes', 'num_features']\n"
     ]
    }
   ],
   "source": [
    "dataset = loadDataset(collection='MyOwnDataset2', name='precomputed/er_1000_0_15_nb.pickle')\n",
    "global Net\n",
    "Net=Net2(d1=30,d2=50)\n",
    "trainTestEval(dataset, epochs=200)\n",
    "del Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch_geometric.data.dataloader.DataLoader object at 0x7fa445005518>\n",
      "['_DataLoader__initialized', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'batch_sampler', 'batch_size', 'collate_fn', 'dataset', 'drop_last', 'num_workers', 'pin_memory', 'sampler', 'timeout', 'worker_init_fn']\n",
      "Data(edge_index=[2, 149596], x=[1000, 1], y=[1000])\n",
      "epoch-loss:  0 tensor(0.0089, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  25 tensor(3.8539e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  50 tensor(2.3776e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  75 tensor(1.3707e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  100 tensor(6.1590e-07, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  125 tensor(2.4946e-07, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  150 tensor(1.3637e-07, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  175 tensor(7.1854e-08, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "RMSE:  tensor(0.0037, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Total train-test time: 7.273108720779419\n"
     ]
    }
   ],
   "source": [
    "dataset = loadDataset(collection='MyOwnDataset2', name='precomputed/er_1000_0_15_nb.pickle')\n",
    "global Net\n",
    "Net=Net2(d1=30,d2=50)\n",
    "trainTestEval(dataset,  epochs=200)\n",
    "del Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch_geometric.data.dataloader.DataLoader object at 0x7f0c3d324e10>\n",
      "['_DataLoader__initialized', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'batch_sampler', 'batch_size', 'collate_fn', 'dataset', 'drop_last', 'num_workers', 'pin_memory', 'sampler', 'timeout', 'worker_init_fn']\n",
      "Data(edge_index=[2, 1542], x=[100, 1], y=[100])\n",
      "epoch-loss:  0 tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  25 tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  50 tensor(5.2695e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  75 tensor(2.9153e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  100 tensor(2.1987e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  125 tensor(1.8023e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  150 tensor(1.6061e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch-loss:  175 tensor(1.5628e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "RMSE:  tensor(0.0388, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Total train-test time: 0.5616779327392578\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data', 'filename', 'num_classes', 'num_features']\n"
     ]
    }
   ],
   "source": [
    "dataset = loadDataset(collection='MyOwnDataset2', name='precomputed/er_100_0_15_nb.pickle')\n",
    "global Net\n",
    "Net=Net3(d1=30,d2=50)\n",
    "trainTestEval(dataset,  epochs=200)\n",
    "del Net"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-pytorch",
   "language": "python",
   "name": "gnn-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
