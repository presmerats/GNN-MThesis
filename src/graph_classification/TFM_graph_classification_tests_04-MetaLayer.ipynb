{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "This notebook will experiment with:\n",
    "- train & compare differnt GNN models for graph classificaiton in common benchmarks (PPI, Proteins, ENZYMES,..)\n",
    "- compare results to publication results\n",
    "\n",
    "Most of the experiments will be done in PyTorch/PyTorch Geometric, but some models are implemented in Tensor Flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import MessagePassing\n",
    "#from torch_geometric.nn.conv.gated_graph_conv import GatedGraphConv\n",
    "from torch_geometric.nn.glob.glob import global_mean_pool, global_add_pool\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.nn import MetaLayer\n",
    "\n",
    "from TFM_graph_classification import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net1(torch.nn.Module):\n",
    "    def __init__(self, d1=50,d2=20,num_classes=6, num_layers=2, aggr_type='mean'):\n",
    "        super(Net1, self).__init__()\n",
    "        self.ggnn = GatedGraphConv(out_channels=d1, num_layers=num_layers,aggr=aggr_type, bias=True)\n",
    "        self.fc1 = nn.Linear(d1, d2)\n",
    "        self.fc2 = nn.Linear(d2, num_classes)\n",
    "        self.global_pool = global_mean_pool\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch_vector = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.ggnn(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training) # until here the output is for each node\n",
    "        \n",
    "        x = self.global_pool(x, batch_vector) # this makes the output to be graph level?\n",
    "        #x = self.fc1(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        #x = self.pool1(x, batch )\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        #x = torch.argmax(x, dim=1)  # we output softmax to use the nll_loss\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Net2(torch.nn.Module):\n",
    "    def __init__(self, d1=50,d2=20,num_classes=6, num_layers=2, aggr_type='mean'):\n",
    "        super(Net2, self).__init__()\n",
    "        self.ggnn = GatedGraphConv(out_channels=d1, num_layers=num_layers,aggr=aggr_type, bias=True)\n",
    "        self.fc1 = nn.Linear(d1, num_classes)\n",
    "        self.global_pool = global_mean_pool\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch_vector = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.ggnn(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training) # until here the output is for each node\n",
    "        \n",
    "        x = self.global_pool(x, batch_vector) # this makes the output to be graph level?\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Net3(torch.nn.Module):\n",
    "    def __init__(self, d1=50,d2=20, d3=10,num_classes=6, num_layers=2, aggr_type='mean'):\n",
    "        super(Net3, self).__init__()\n",
    "        self.ggnn = GatedGraphConv(out_channels=d1, num_layers=num_layers,aggr=aggr_type, bias=True)\n",
    "        self.fc1 = nn.Linear(d1, d2)\n",
    "        self.dense1_bn = nn.BatchNorm1d(d2)\n",
    "        self.fc2 = nn.Linear(d2, d3)\n",
    "        self.dense2_bn = nn.BatchNorm1d(d3)\n",
    "        self.fc3 = nn.Linear(d3, num_classes)\n",
    "        self.global_pool = global_mean_pool\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch_vector = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.ggnn(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training) # until here the output is for each node\n",
    "        \n",
    "        x = self.global_pool(x, batch_vector) # this makes the output to be graph level?\n",
    "        x = F.relu(self.dense1_bn(self.fc1(x)))\n",
    "        x = F.relu(self.dense2_bn(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "class Net4(torch.nn.Module):\n",
    "    def __init__(self, d1=50,d2=20,num_classes=6, num_layers=2, aggr_type='mean'):\n",
    "        super(Net4, self).__init__()\n",
    "        self.ggnn = GatedGraphConv(out_channels=d1, num_layers=num_layers,aggr=aggr_type, bias=True)\n",
    "        self.fc1 = nn.Linear(d1, d2)\n",
    "        self.dense1_bn = nn.BatchNorm1d(d2)\n",
    "        self.fc2 = nn.Linear(d2, num_classes)\n",
    "        self.global_pool = global_mean_pool\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch_vector = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.ggnn(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training) # until here the output is for each node\n",
    "        \n",
    "        x = self.global_pool(x, batch_vector) # this makes the output to be graph level?\n",
    "        #x = self.fc1(x)\n",
    "        x = F.relu(self.dense1_bn(self.fc1(x)))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        #x = self.pool1(x, batch )\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        #x = torch.argmax(x, dim=1)  # we output softmax to use the nll_loss\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class META1(torch.nn.Module):\n",
    "    def __init__(self, d1=3, d2=50, d3=15, d4 =15,d5=10,num_classes=6):\n",
    "        super(META1, self).__init__()\n",
    "\n",
    "        self.edge_mlp = Seq(Lin(d1*3, d2), ReLU(), Lin(d2, d3))\n",
    "        self.node_mlp = Seq(Lin(d1*6, d2), ReLU(), Lin(d2, d3))\n",
    "        self.global_mlp = Seq(Lin(d3+1, d2), ReLU(), Lin(d2, d3))\n",
    "        \n",
    "        self.fc1 = nn.Linear(d4, d5)\n",
    "        self.dense1_bn = nn.BatchNorm1d(d5)\n",
    "        self.fc2 = nn.Linear(d5, num_classes)\n",
    "        self.dense2_bn = nn.BatchNorm1d(num_classes)\n",
    "        self.global_pool = global_mean_pool\n",
    "\n",
    "        def edge_model(source, target, edge_attr, u):\n",
    "            # source, target: [E, F_x], where E is the number of edges.\n",
    "            # edge_attr: [E, F_e]\n",
    "            # u: [B, F_u], where B is the number of graphs.\n",
    "            #print(\"edge_model\")\n",
    "            #print(source.size())\n",
    "            #print(target.size())\n",
    "            #print(edge_attr.size())\n",
    "            out = torch.cat([source, target, edge_attr], dim=1)\n",
    "            return self.edge_mlp(out)\n",
    "\n",
    "        def node_model(x, edge_index, edge_attr, u):\n",
    "            # x: [N, F_x], where N is the number of nodes.\n",
    "            # edge_index: [2, E] with max entry N - 1.\n",
    "            # edge_attr: [E, F_e]\n",
    "            # u: [B, F_u]\n",
    "            row, col = edge_index\n",
    "            \n",
    "            #print(\"node_model\")\n",
    "            #print(row.size())\n",
    "            #print(col.size())\n",
    "            #print(x[col].size())\n",
    "            #print(edge_attr.size())\n",
    "            \n",
    "            out = torch.cat([x[col], edge_attr], dim=1)\n",
    "            out = self.node_mlp(out)\n",
    "            return scatter_mean(out, row, dim=0, dim_size=x.size(0))\n",
    "\n",
    "        def global_model(x, edge_index, edge_attr, u, batch):\n",
    "            # x: [N, F_x], where N is the number of nodes.\n",
    "            # edge_index: [2, E] with max entry N - 1.\n",
    "            # edge_attr: [E, F_e]\n",
    "            # u: [B, F_u]\n",
    "            # batch: [N] with max entry B - 1.\n",
    "            \n",
    "            #print(\"global_Model\")\n",
    "            #print(\"u.size():\")\n",
    "            #print(u.size())\n",
    "            #print(\"scatter_mean(x,batch,..):\")\n",
    "            #smean = scatter_mean(x, batch, dim=0)\n",
    "            #print(smean.size())\n",
    "            \n",
    "            out = torch.cat([u, scatter_mean(x, batch, dim=0)], dim=1)\n",
    "            \n",
    "            #print(\"out.size():\")\n",
    "            #print(out.size())\n",
    "            return self.global_mlp(out)\n",
    "\n",
    "        self.op = MetaLayer(edge_model, node_model, global_model)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index, edge_attr, u, batch = data.x, data.edge_index, data.edge_attr, data.u, data.batch        \n",
    "        \n",
    "        # output of meta is x,edge_attr, u\n",
    "        x2, edge_attr2, u2 =  self.op(x, edge_index, edge_attr, u, batch)\n",
    "        \n",
    "        # idea1 is to cat x2, edge_attr2 and u2?\n",
    "        # idea2 is to update edge_attr and u...\n",
    "        data.x = x2\n",
    "        data.edge_attr = edge_attr2\n",
    "        data.u = u2\n",
    "\n",
    "        # version using only u\n",
    "        x = F.relu(self.dense1_bn(self.fc1(u2)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "        \n",
    "    \n",
    "    \n",
    "class META2(torch.nn.Module):\n",
    "    def __init__(self, d1=3, d2=50, d3=15, d4 =15,d5=10,num_classes=6):\n",
    "        super(META2, self).__init__()\n",
    "\n",
    "        self.edge_mlp = Seq(Lin(d1*3, d2), ReLU(), Lin(d2, d3))\n",
    "        self.node_mlp = Seq(Lin(d1*6, d2), ReLU(), Lin(d2, d3))\n",
    "        self.global_mlp = Seq(Lin(d3+1, d2), ReLU(), Lin(d2, d3))\n",
    "        \n",
    "        self.fc1 = nn.Linear(d4, d5)\n",
    "        self.dense1_bn = nn.BatchNorm1d(d5)\n",
    "        self.fc2 = nn.Linear(d5, num_classes)\n",
    "        self.dense2_bn = nn.BatchNorm1d(num_classes)\n",
    "        self.global_pool = global_mean_pool\n",
    "\n",
    "        def edge_model(source, target, edge_attr, u):\n",
    "            # source, target: [E, F_x], where E is the number of edges.\n",
    "            # edge_attr: [E, F_e]\n",
    "            # u: [B, F_u], where B is the number of graphs.\n",
    "            #print(\"edge_model\")\n",
    "            #print(source.size())\n",
    "            #print(target.size())\n",
    "            #print(edge_attr.size())\n",
    "            out = torch.cat([source, target, edge_attr], dim=1)\n",
    "            return self.edge_mlp(out)\n",
    "\n",
    "        def node_model(x, edge_index, edge_attr, u):\n",
    "            # x: [N, F_x], where N is the number of nodes.\n",
    "            # edge_index: [2, E] with max entry N - 1.\n",
    "            # edge_attr: [E, F_e]\n",
    "            # u: [B, F_u]\n",
    "\n",
    "            \n",
    "            row, col = edge_index\n",
    "            \n",
    "            #print(\"node_model\")\n",
    "            #print(row.size())\n",
    "            #print(col.size())\n",
    "            #print(x[col].size())\n",
    "            #print(edge_attr.size())\n",
    "            \n",
    "            out = torch.cat([x[col], edge_attr], dim=1)\n",
    "            out = self.node_mlp(out)\n",
    "            return scatter_mean(out, row, dim=0, dim_size=x.size(0))\n",
    "\n",
    "        def global_model(x, edge_index, edge_attr, u, batch):\n",
    "            # x: [N, F_x], where N is the number of nodes.\n",
    "            # edge_index: [2, E] with max entry N - 1.\n",
    "            # edge_attr: [E, F_e]\n",
    "            # u: [B, F_u]\n",
    "            # batch: [N] with max entry B - 1.\n",
    "            \n",
    "            #print(\"global_Model\")\n",
    "            #print(\"u.size():\")\n",
    "            #print(u.size())\n",
    "            #print(\"scatter_mean(x,batch,..):\")\n",
    "            #smean = scatter_mean(x, batch, dim=0)\n",
    "            #print(smean.size())\n",
    "            \n",
    "            out = torch.cat([u, scatter_mean(x, batch, dim=0)], dim=1)\n",
    "            \n",
    "            #print(\"out.size():\")\n",
    "            #print(out.size())\n",
    "            return self.global_mlp(out)\n",
    "\n",
    "        self.op = MetaLayer(edge_model, node_model, global_model)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index, edge_attr, u, batch = data.x, data.edge_index, data.edge_attr, data.u, data.batch        \n",
    "        \n",
    "        # output of meta is x,edge_attr, u\n",
    "        x2, edge_attr2, u2 =  self.op(x, edge_index, edge_attr, u, batch)\n",
    "        \n",
    "        # idea1 is to cat x2, edge_attr2 and u2?\n",
    "        # idea2 is to update edge_attr and u...\n",
    "        data.x = x2\n",
    "        data.edge_attr = edge_attr2\n",
    "        data.u = u2\n",
    "        \n",
    "        # version using only x \n",
    "        x = self.global_pool(x2,batch) # separate by graph level\n",
    "        x = F.relu(self.dense1_bn(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "class META3(torch.nn.Module):\n",
    "    def __init__(self, d1=3, d2=50, d3=15, d4 =15,d5=10,num_classes=6):\n",
    "        super(META3, self).__init__()\n",
    "\n",
    "        self.edge_mlp = Seq(Lin(d1*3, d2), ReLU(), Lin(d2, d3))\n",
    "        self.node_mlp = Seq(Lin(d1*6, d2), ReLU(), Lin(d2, d3))\n",
    "        self.global_mlp = Seq(Lin(d3+1, d2), ReLU(), Lin(d2, d3))\n",
    "        \n",
    "        self.fc1 = nn.Linear(d4, d5)\n",
    "        self.dense1_bn = nn.BatchNorm1d(d5)\n",
    "        self.fc2 = nn.Linear(d5, num_classes)\n",
    "        self.dense2_bn = nn.BatchNorm1d(num_classes)\n",
    "        self.global_pool = global_mean_pool\n",
    "\n",
    "        def edge_model(source, target, edge_attr, u):\n",
    "            # source, target: [E, F_x], where E is the number of edges.\n",
    "            # edge_attr: [E, F_e]\n",
    "            # u: [B, F_u], where B is the number of graphs.\n",
    "            #print(\"edge_model\")\n",
    "            #print(source.size())\n",
    "            #print(target.size())\n",
    "            #print(edge_attr.size())\n",
    "            out = torch.cat([source, target, edge_attr], dim=1)\n",
    "            return self.edge_mlp(out)\n",
    "\n",
    "        def node_model(x, edge_index, edge_attr, u):\n",
    "            # x: [N, F_x], where N is the number of nodes.\n",
    "            # edge_index: [2, E] with max entry N - 1.\n",
    "            # edge_attr: [E, F_e]\n",
    "            # u: [B, F_u]\n",
    "\n",
    "            \n",
    "            row, col = edge_index\n",
    "            \n",
    "            #print(\"node_model\")\n",
    "            #print(row.size())\n",
    "            #print(col.size())\n",
    "            #print(x[col].size())\n",
    "            #print(edge_attr.size())\n",
    "            \n",
    "            out = torch.cat([x[col], edge_attr], dim=1)\n",
    "            out = self.node_mlp(out)\n",
    "            return scatter_mean(out, row, dim=0, dim_size=x.size(0))\n",
    "\n",
    "        def global_model(x, edge_index, edge_attr, u, batch):\n",
    "            # x: [N, F_x], where N is the number of nodes.\n",
    "            # edge_index: [2, E] with max entry N - 1.\n",
    "            # edge_attr: [E, F_e]\n",
    "            # u: [B, F_u]\n",
    "            # batch: [N] with max entry B - 1.\n",
    "            \n",
    "            #print(\"global_Model\")\n",
    "            #print(\"u.size():\")\n",
    "            #print(u.size())\n",
    "            #print(\"scatter_mean(x,batch,..):\")\n",
    "            #smean = scatter_mean(x, batch, dim=0)\n",
    "            #print(smean.size())\n",
    "            \n",
    "            out = torch.cat([u, scatter_mean(x, batch, dim=0)], dim=1)\n",
    "            \n",
    "            #print(\"out.size():\")\n",
    "            #print(out.size())\n",
    "            return self.global_mlp(out)\n",
    "\n",
    "        self.op = MetaLayer(edge_model, node_model, global_model)\n",
    "\n",
    "    def forward(self, data):\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        x, edge_index, edge_attr, u, batch = data.x, data.edge_index, data.edge_attr, data.u, data.batch        \n",
    "        \n",
    "        # output of meta is x,edge_attr, u\n",
    "        x2, edge_attr2, u2 =  self.op(x, edge_index, edge_attr, u, batch)\n",
    "        \n",
    "        # idea1 is to cat x2, edge_attr2 and u2?\n",
    "        # idea2 is to update edge_attr and u...\n",
    "        data.x = x2\n",
    "        data.edge_attr = edge_attr2\n",
    "        data.u = u2\n",
    "\n",
    "\n",
    "        # version using x and  u\n",
    "        x = F.relu(torch.cat([x2,u2], dim=0))\n",
    "        x = F.dropout(x, training=self.training) # until here the output is for each node\n",
    "        ubatch = list(set([ elem.item() for elem in batch]))\n",
    "        #print(ubatch)\n",
    "        x = self.global_pool(x, torch.cat([batch,torch.LongTensor( ubatch).to(device) ],dim=0)) # this makes the output to be graph level?\n",
    "        x = F.relu(self.dense1_bn(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "class META4(torch.nn.Module):\n",
    "    def __init__(self, d1=3, d2=50, d3=15, d4 =15,d5=10,num_classes=6):\n",
    "        super(META4, self).__init__()\n",
    "\n",
    "        self.edge_mlp = Seq(Lin(d1*3, d2), ReLU(), Lin(d2, d3))\n",
    "        self.node_mlp = Seq(Lin(d1*6, d2), ReLU(), Lin(d2, d3))\n",
    "        self.global_mlp = Seq(Lin(16, d2), ReLU(), Lin(d2, d3))\n",
    "        \n",
    "        self.fc1 = nn.Linear(d4, d5)\n",
    "        self.dense1_bn = nn.BatchNorm1d(d5)\n",
    "        self.fc2 = nn.Linear(d5, num_classes)\n",
    "        self.dense2_bn = nn.BatchNorm1d(num_classes)\n",
    "        self.global_pool = global_mean_pool\n",
    "\n",
    "        def edge_model(source, target, edge_attr, u):\n",
    "            # source, target: [E, F_x], where E is the number of edges.\n",
    "            # edge_attr: [E, F_e]\n",
    "            # u: [B, F_u], where B is the number of graphs.\n",
    "            #print(\"edge_model\")\n",
    "            #print(source.size())\n",
    "            #print(target.size())\n",
    "            #print(edge_attr.size())\n",
    "            out = torch.cat([source, target, edge_attr], dim=1)\n",
    "            return self.edge_mlp(out)\n",
    "\n",
    "        def node_model(x, edge_index, edge_attr, u):\n",
    "            # x: [N, F_x], where N is the number of nodes.\n",
    "            # edge_index: [2, E] with max entry N - 1.\n",
    "            # edge_attr: [E, F_e]\n",
    "            # u: [B, F_u]\n",
    "\n",
    "            \n",
    "            row, col = edge_index\n",
    "            \n",
    "            #print(\"node_model\")\n",
    "            #print(row.size())\n",
    "            #print(col.size())\n",
    "            #print(x[col].size())\n",
    "            #print(edge_attr.size())\n",
    "            \n",
    "            out = torch.cat([x[col], edge_attr], dim=1)\n",
    "            out = self.node_mlp(out)\n",
    "            return scatter_mean(out, row, dim=0, dim_size=x.size(0))\n",
    "\n",
    "        def global_model(x, edge_index, edge_attr, u, batch):\n",
    "            # x: [N, F_x], where N is the number of nodes.\n",
    "            # edge_index: [2, E] with max entry N - 1.\n",
    "            # edge_attr: [E, F_e]\n",
    "            # u: [B, F_u]\n",
    "            # batch: [N] with max entry B - 1.\n",
    "            \n",
    "            #print(\"global_Model\")\n",
    "            #print(\"u.size():\")\n",
    "            #print(u.size())\n",
    "            #print(\"scatter_mean(x,batch,..):\")\n",
    "            #smean = scatter_mean(x, batch, dim=0)\n",
    "            #print(smean.size())\n",
    "            \n",
    "            out = torch.cat([u, scatter_mean(x, batch, dim=0)], dim=1)\n",
    "            \n",
    "            #print(\"out.size():\")\n",
    "            #print(out.size())\n",
    "            return self.global_mlp(out)\n",
    "\n",
    "        self.op = MetaLayer(edge_model, node_model, global_model)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index, edge_attr, u, batch = data.x, data.edge_index, data.edge_attr, data.u, data.batch        \n",
    "        \n",
    "        # output of meta is x,edge_attr, u\n",
    "        x2, edge_attr2, u2 =  self.op(x, edge_index, edge_attr, u, batch)\n",
    "        \n",
    "        # idea1 is to cat x2, edge_attr2 and u2?\n",
    "        # idea2 is to update edge_attr and u...\n",
    "        data.x = x2\n",
    "        data.edge_attr = edge_attr2\n",
    "        data.u = u2\n",
    "\n",
    "    \n",
    "        # version using x and  u and edge_attr\n",
    "        x = F.relu(torch.cat([x2,u2], dim=0))\n",
    "        #x = x2\n",
    "        x = F.dropout(x, training=self.training) # until here the output is for each node\n",
    "        \n",
    "        x = self.global_pool(x, torch.cat([batch, ],dim=0)) # this makes the output to be graph level?\n",
    "        x = F.relu(self.dense1_bn(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class META5(torch.nn.Module):\n",
    "    \"\"\"\n",
    "        Not using edge attribute\n",
    "    \"\"\"\n",
    "    def __init__(self, d1=3, d2=50, d3=15):\n",
    "        super(META5, self).__init__()\n",
    "\n",
    "        self.edge_mlp = Seq(Lin(d1*2, d2), ReLU(), Lin(d2, d3))\n",
    "        self.node_mlp = Seq(Lin(d1, d2), ReLU(), Lin(d2, d3))\n",
    "        self.global_mlp = Seq(Lin(2, d2), ReLU(), Lin(d2, d3))\n",
    "\n",
    "        def edge_model(source, target, edge_attr, u):\n",
    "            # source, target: [E, F_x], where E is the number of edges.\n",
    "            # edge_attr: [E, F_e]\n",
    "            # u: [B, F_u], where B is the number of graphs.\n",
    "            out = torch.cat([source, target], dim=1)\n",
    "            #print(\"edge_model\")\n",
    "            #print(out.size())\n",
    "            return self.edge_mlp(out)\n",
    "\n",
    "        def node_model(x, edge_index, edge_attr, u):\n",
    "            # x: [N, F_x], where N is the number of nodes.\n",
    "            # edge_index: [2, E] with max entry N - 1.\n",
    "            # edge_attr: [E, F_e]\n",
    "            # u: [B, F_u]\n",
    "            row, col = edge_index\n",
    "            out = torch.cat([x[col]], dim=1)\n",
    "            out = self.node_mlp(out)\n",
    "            return scatter_mean(out, row, dim=0, dim_size=x.size(0))\n",
    "\n",
    "        def global_model(x, edge_index, edge_attr, u, batch):\n",
    "            # x: [N, F_x], where N is the number of nodes.\n",
    "            # edge_index: [2, E] with max entry N - 1.\n",
    "            # edge_attr: [E, F_e]\n",
    "            # u: [B, F_u]\n",
    "            # batch: [N] with max entry B - 1.\n",
    "            out = torch.cat([u, scatter_mean(x, batch, dim=0)], dim=1)\n",
    "            \n",
    "            return self.global_mlp(out)\n",
    "\n",
    "        self.op = MetaLayer(edge_model, node_model, global_model)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        #print(\"Forward: \")\n",
    "        #print(x.size())\n",
    "        return self.op(x, edge_index, edge_attr, u, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models for hyperparameter search\n",
    "model_list =[\n",
    "    {'epochs': 200,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 50,'d2': 20,'num_layers':2, 'aggr_type':'mean'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    {'epochs': 100,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 50,'d2': 20,'num_layers':2, 'aggr_type':'mean'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    {'epochs': 200,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 50,'d2': 20,'num_layers':2, 'aggr_type':'add'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    {'epochs': 100,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 50,'d2': 20,'num_layers':2, 'aggr_type':'add'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    \n",
    "    {'epochs': 200,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 100,'d2': 20,'num_layers':2, 'aggr_type':'mean'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    {'epochs': 100,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 100,'d2': 20,'num_layers':2, 'aggr_type':'mean'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    {'epochs': 200,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 100,'d2': 50,'num_layers':2, 'aggr_type':'mean'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    {'epochs': 100,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 100,'d2': 50,'num_layers':2, 'aggr_type':'mean'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "]\n",
    "\n",
    "model_list2 = []\n",
    "for modelclass in [Net1, Net2, Net3,Net4]:\n",
    "    for d1 in [25,50,100,200]:\n",
    "        for d2 in [20,50]:\n",
    "            for aggr_type in ['mean','add']:\n",
    "                for epochs in [10,20,300]:\n",
    "                    model_list2.append(\n",
    "                        {\n",
    "                        'model': modelclass,\n",
    "                        'epochs': epochs,\n",
    "                        'kwargs':{'d1': d1,'d2': d2,'num_layers':2, \n",
    "                                  'aggr_type':aggr_type}, \n",
    "                        'learning_rate': 0.01, 'weight_decay':5e-4, \n",
    "                        'batch_size': 32},\n",
    "                    )\n",
    "                    \n",
    "                    \n",
    "model_list3 =[\n",
    "    {'epochs': 200,\n",
    "    'model': META1,\n",
    "    'kwargs':{'d1': 3,'d2': 20, 'd3': 15, 'd4': 15, 'd5':10}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    {'epochs': 200,\n",
    "    'model': META2,\n",
    "    'kwargs':{'d1': 3,'d2': 20, 'd3': 15, 'd4': 15, 'd5':10}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    {'epochs': 200,\n",
    "    'model': META3,\n",
    "    'kwargs':{'d1': 3,'d2': 20, 'd3': 15, 'd4': 15, 'd5':10}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    #{'epochs': 200,\n",
    "    #'model': META4,\n",
    "    #'kwargs':{'d1': 3,'d2': 20, 'd3': 15}, \n",
    "    #'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "]\n",
    "   \n",
    "\n",
    "model_list4 = []\n",
    "for modelclass in [META3, META2, META1]:\n",
    "    for d1 in [3]:\n",
    "        for d2 in [10,20,50,100]:\n",
    "            for d3 in [15]:\n",
    "                for d4 in [15,30,60]:\n",
    "                    for d5 in [10,20]:\n",
    "                        for epochs in [100,200,400,800]:\n",
    "                            model_list4.append(\n",
    "                                {'epochs': epochs,\n",
    "                                'model': modelclass,\n",
    "                                'kwargs':{'d1': d1,'d2': d2, 'd3': d3, 'd4': d4, 'd5':d5}, \n",
    "                                'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "                            )\n",
    "\n",
    "model_list = model_list2\n",
    "model_list = model_list[:2]\n",
    "model_list = model_list3[2:3]\n",
    "model_list = model_list4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n: 600  k folds= 3\n",
      "Datasets balancing: \n",
      "{0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100}\n",
      "{0: 80, 1: 80, 2: 80, 3: 80, 4: 80, 5: 80}\n",
      "{0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "dataset = dataset.shuffle()\n",
    "k = 3\n",
    "n = len(dataset)\n",
    "print(\" n:\",n,\" k folds=\",k)\n",
    "train_dataset, test_dataset = balancedDatasetSplit_slice(dataset, prop=0.8)\n",
    "print(\"Datasets balancing: \")\n",
    "printDatasetBalance(dataset )\n",
    "printDatasetBalance(train_dataset )\n",
    "printDatasetBalance(test_dataset )\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__call__', '__class__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'apply', 'cat_dim', 'clone', 'contains_isolated_nodes', 'contains_self_loops', 'contiguous', 'edge_attr', 'edge_index', 'from_dict', 'is_coalesced', 'is_directed', 'is_undirected', 'keys', 'num_edges', 'num_features', 'num_nodes', 'pos', 'to', 'x', 'y']\n",
      "3\n",
      "208\n",
      "\n",
      "['__call__', '__class__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'apply', 'batch', 'cat_dim', 'clone', 'contains_isolated_nodes', 'contains_self_loops', 'contiguous', 'cumsum', 'edge_attr', 'edge_index', 'from_data_list', 'from_dict', 'is_coalesced', 'is_directed', 'is_undirected', 'keys', 'num_edges', 'num_features', 'num_graphs', 'num_nodes', 'pos', 'to', 'x', 'y']\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n",
      "None\n",
      "tensor([[   1,    1,    2,  ..., 1041, 1041, 1041],\n",
      "        [  24,   26,   25,  ..., 1021, 1033, 1034]])\n",
      "tensor([ 0,  0,  0,  ..., 31, 31, 31])\n",
      "tensor([3, 4, 4, 0, 5, 1, 3, 1, 2, 3, 5, 0, 4, 2, 2, 0, 0, 2, 4, 2, 3, 4, 3, 2,\n",
      "        5, 2, 4, 1, 3, 5, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# get  edge_index, edge_attr and global attributes..\n",
    "print(dir(dataset[1]))\n",
    "print(dataset[1].num_features)\n",
    "print(dataset[1].num_edges)\n",
    "print()\n",
    "\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "for data in loader:\n",
    "    print(dir(data))\n",
    "    \n",
    "    print(data.x)\n",
    "    print(data.edge_attr)\n",
    "    print(data.edge_index)\n",
    "    print(data.batch)\n",
    "    print(data.y)\n",
    "    \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 15, 'd5': 10}  epochs: 100  val loss= 0.05306003739436468  val accuracy= 0.32142857142857145  val microF1= 0.3162393162393162  val macroF1= 0.30535526618296427\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 15, 'd5': 10}  epochs: 200  val loss= 0.05067132040858269  val accuracy= 0.42857142857142855  val microF1= 0.3696581196581197  val macroF1= 0.36753955061359095\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 15, 'd5': 10}  epochs: 400  val loss= 0.05175297955671946  val accuracy= 0.36904761904761907  val microF1= 0.37393162393162394  val macroF1= 0.3664226123924525\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 15, 'd5': 10}  epochs: 800  val loss= 0.05074156199892362  val accuracy= 0.369047619047619  val microF1= 0.3974358974358974  val macroF1= 0.4019578914589401\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 15, 'd5': 20}  epochs: 100  val loss= 0.05050691465536753  val accuracy= 0.35714285714285715  val microF1= 0.3846153846153846  val macroF1= 0.38404152170510164\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 15, 'd5': 20}  epochs: 200  val loss= 0.04974100242058436  val accuracy= 0.36904761904761907  val microF1= 0.4038461538461538  val macroF1= 0.40725227514027096\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 15, 'd5': 20}  epochs: 400  val loss= 0.05143154039978981  val accuracy= 0.48809523809523814  val microF1= 0.40170940170940167  val macroF1= 0.4033596919324339\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 15, 'd5': 20}  epochs: 800  val loss= 0.0543019101023674  val accuracy= 0.32142857142857145  val microF1= 0.37820512820512825  val macroF1= 0.3664329983842769\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 30, 'd5': 10}  epochs: 100  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 30, 'd5': 10}  epochs: 200  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 30, 'd5': 10}  epochs: 400  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 363, in forward\n",
      "    ubatch = list(set([ elem.item() for elem in batch]))\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 363, in <listcomp>\n",
      "    ubatch = list(set([ elem.item() for elem in batch]))\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [30 x 10] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [30 x 10] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [30 x 10] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 30, 'd5': 10}  epochs: 800  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 30, 'd5': 20}  epochs: 100  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 30, 'd5': 20}  epochs: 200  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 30, 'd5': 20}  epochs: 400  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [30 x 10] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [30 x 20] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [30 x 20] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [30 x 20] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 30, 'd5': 20}  epochs: 800  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 60, 'd5': 10}  epochs: 100  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 60, 'd5': 10}  epochs: 200  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 60, 'd5': 10}  epochs: 400  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [30 x 20] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [60 x 10] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [60 x 10] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [60 x 10] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 60, 'd5': 10}  epochs: 800  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 60, 'd5': 20}  epochs: 100  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 60, 'd5': 20}  epochs: 200  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 60, 'd5': 20}  epochs: 400  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [60 x 10] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [60 x 20] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [60 x 20] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [60 x 20] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 10, 'd3': 15, 'd4': 60, 'd5': 20}  epochs: 800  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 366, in forward\n",
      "    x = F.relu(self.dense1_bn(self.fc1(x)))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 67, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 1352, in linear\n",
      "    ret = torch.addmm(torch.jit._unwrap_optional(bias), input, weight.t())\n",
      "RuntimeError: size mismatch, m1: [32 x 15], m2: [60 x 20] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trained model:  META3 {'d1': 3, 'd2': 20, 'd3': 15, 'd4': 15, 'd5': 10}  epochs: 100  val loss= 0.052314007033904396  val accuracy= 0.2976190476190476  val microF1= 0.3482905982905982  val macroF1= 0.34780534951141506\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 20, 'd3': 15, 'd4': 15, 'd5': 10}  epochs: 200  val loss= 0.10477696359157562  val accuracy= 0.75  val microF1= 0.7371794871794872  val macroF1= 0.7552799025917887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 784, in modelSelection\n",
      "    val_loss_model(model, loader_val, optimizer, val_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 573, in val_loss_model\n",
      "    return val_loss_model_META(model, loader, optimizer, val_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 566, in val_loss_model_META\n",
      "    measures = F1Score(total_acc, total_gt)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 193, in F1Score\n",
      "    if pred[j] not in preddict[i] and pred[j] not in targetdict[i]:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 20, 'd3': 15, 'd4': 15, 'd5': 10}  epochs: 400  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 363, in forward\n",
      "    ubatch = list(set([ elem.item() for elem in batch]))\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 363, in <listcomp>\n",
      "    ubatch = list(set([ elem.item() for elem in batch]))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/tensor.py\", line 428, in <lambda>\n",
      "    return iter(imap(lambda i: self[i], range(self.size(0))))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 20, 'd3': 15, 'd4': 15, 'd5': 10}  epochs: 800  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 20, 'd3': 15, 'd4': 15, 'd5': 20}  epochs: 100  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 453, in train_model_META\n",
      "    loss.backward()\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/tensor.py\", line 102, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 90, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 363, in forward\n",
      "    ubatch = list(set([ elem.item() for elem in batch]))\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 363, in <listcomp>\n",
      "    ubatch = list(set([ elem.item() for elem in batch]))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 20, 'd3': 15, 'd4': 15, 'd5': 20}  epochs: 200  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n",
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 20, 'd3': 15, 'd4': 15, 'd5': 20}  epochs: 400  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 351, in forward\n",
      "    x2, edge_attr2, u2 =  self.op(x, edge_index, edge_attr, u, batch)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch_geometric/nn/meta.py\", line 101, in forward\n",
      "    x = self.node_model(x, edge_index, edge_attr, u)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 321, in node_model\n",
      "    return scatter_mean(out, row, dim=0, dim_size=x.size(0))\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch_scatter/mean.py\", line 68, in scatter_mean\n",
      "    out = scatter_add(src, index, dim, out, dim_size, fill_value)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch_scatter/add.py\", line 72, in scatter_add\n",
      "    src, out, index, dim = gen(src, index, dim, out, dim_size, fill_value)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch_scatter/utils/gen.py\", line 18, in gen\n",
      "    out = src.new_full(out_size, fill_value)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 448, in train_model_META\n",
      "    out = model(data)\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 363, in forward\n",
      "    ubatch = list(set([ elem.item() for elem in batch]))\n",
      "  File \"<ipython-input-2-3b200bb6aac2>\", line 363, in <listcomp>\n",
      "    ubatch = list(set([ elem.item() for elem in batch]))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem training model META3\n",
      " trained model:  META3 {'d1': 3, 'd2': 20, 'd3': 15, 'd4': 15, 'd5': 20}  epochs: 800  val loss= 0.0  val accuracy= 0.0  val microF1= 0.0  val macroF1= 0.0\n",
      "Problem training model META3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 783, in modelSelection\n",
      "    train_model(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 464, in train_model\n",
      "    return train_model_META(model, loader, optimizer, train_loss_history)\n",
      "  File \"/media/disk/home/pau/Projectes/GNN-MThesis/src/graph_classification/TFM_graph_classification.py\", line 454, in train_model_META\n",
      "    optimizer.step()\n",
      "  File \"/home/pau/.pyenv/versions/3.6.7/envs/gnn-pytorch/lib/python3.6/site-packages/torch/optim/adam.py\", line 103, in step\n",
      "    bias_correction1 = 1 - beta1 ** state['step']\n",
      "KeyboardInterrupt\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "modelsdict = modelSelection(model_list,k, train_dataset)\n",
    "reportModelSelectionResult(modelsdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmodel = final_model_train(modelsdict['best_models']['loss'], train_dataset)\n",
    "testresult = testModel(bmodel, test_dataset)\n",
    "modelsdict['testing'][bmodel.__class__.__name__+'loss']=testresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmodel = final_model_train(modelsdict['best_models']['accuracy'], train_dataset)\n",
    "testresult = testModel(bmodel, test_dataset)\n",
    "modelsdict['testing'][bmodel.__class__.__name__+'accuracy']=testresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmodel = final_model_train(modelsdict['best_models']['microF1'], train_dataset)\n",
    "testresult = testModel(bmodel, test_dataset)\n",
    "modelsdict['testing'][bmodel.__class__.__name__+'microF1']=testresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmodel = final_model_train(modelsdict['best_models']['macroF1'], train_dataset)\n",
    "testresult = testModel(bmodel, test_dataset)\n",
    "modelsdict['testing'][bmodel.__class__.__name__+'macroF1']=testresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reportAllTest(modelsdict)\n",
    "saveResults(modelsdict)\n",
    "# review microF1 & macroF1\n",
    "# review Random Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "1. encapsulate all training, model selection,.. everything\n",
    "2. present results with Pandas tables, and histograms\n",
    "3. save models and results to disk, and load them later for testing\n",
    "4. transform into a python module or package\n",
    "\n",
    "### Pending:\n",
    "\n",
    "- prepare another notebook using the python module (prepare local and on collab)\n",
    "- test other GNN layers: GAT, GCN, GraphSAGE, Metalayer\n",
    "- do a good HP search\n",
    "- look for published architectures?\n",
    "- compare with published benchmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-pytorch",
   "language": "python",
   "name": "gnn-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
