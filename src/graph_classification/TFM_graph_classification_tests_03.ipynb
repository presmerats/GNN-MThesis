{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "This notebook will experiment with:\n",
    "- train & compare differnt GNN models for graph classificaiton in common benchmarks (PPI, Proteins, ENZYMES,..)\n",
    "- compare results to publication results\n",
    "\n",
    "Most of the experiments will be done in PyTorch/PyTorch Geometric, but some models are implemented in Tensor Flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import MessagePassing\n",
    "#from torch_geometric.nn.conv.gated_graph_conv import GatedGraphConv\n",
    "from torch_geometric.nn.glob.glob import global_mean_pool, global_add_pool\n",
    "import torch.nn as nn\n",
    "\n",
    "from TFM_graph_classification import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net1(torch.nn.Module):\n",
    "    def __init__(self, d1=50,d2=20,num_classes=6, num_layers=2, aggr_type='mean'):\n",
    "        super(Net1, self).__init__()\n",
    "        self.ggnn = GatedGraphConv(out_channels=d1, num_layers=num_layers,aggr=aggr_type, bias=True)\n",
    "        self.fc1 = nn.Linear(d1, d2)\n",
    "        self.fc2 = nn.Linear(d2, num_classes)\n",
    "        self.global_pool = global_mean_pool\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch_vector = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.ggnn(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training) # until here the output is for each node\n",
    "        \n",
    "        x = self.global_pool(x, batch_vector) # this makes the output to be graph level?\n",
    "        #x = self.fc1(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        #x = self.pool1(x, batch )\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        #x = torch.argmax(x, dim=1)  # we output softmax to use the nll_loss\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Net2(torch.nn.Module):\n",
    "    def __init__(self, d1=50,d2=20,num_classes=6, num_layers=2, aggr_type='mean'):\n",
    "        super(Net2, self).__init__()\n",
    "        self.ggnn = GatedGraphConv(out_channels=d1, num_layers=num_layers,aggr=aggr_type, bias=True)\n",
    "        self.fc1 = nn.Linear(d1, num_classes)\n",
    "        self.global_pool = global_mean_pool\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch_vector = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.ggnn(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training) # until here the output is for each node\n",
    "        \n",
    "        x = self.global_pool(x, batch_vector) # this makes the output to be graph level?\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Net3(torch.nn.Module):\n",
    "    def __init__(self, d1=50,d2=20, d3=10,num_classes=6, num_layers=2, aggr_type='mean'):\n",
    "        super(Net3, self).__init__()\n",
    "        self.ggnn = GatedGraphConv(out_channels=d1, num_layers=num_layers,aggr=aggr_type, bias=True)\n",
    "        self.fc1 = nn.Linear(d1, d2)\n",
    "        self.dense1_bn = nn.BatchNorm1d(d2)\n",
    "        self.fc2 = nn.Linear(d2, d3)\n",
    "        self.dense2_bn = nn.BatchNorm1d(d3)\n",
    "        self.fc3 = nn.Linear(d3, num_classes)\n",
    "        self.global_pool = global_mean_pool\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch_vector = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.ggnn(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training) # until here the output is for each node\n",
    "        \n",
    "        x = self.global_pool(x, batch_vector) # this makes the output to be graph level?\n",
    "        x = F.relu(self.dense1_bn(self.fc1(x)))\n",
    "        x = F.relu(self.dense2_bn(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "class Net4(torch.nn.Module):\n",
    "    def __init__(self, d1=50,d2=20,num_classes=6, num_layers=2, aggr_type='mean'):\n",
    "        super(Net4, self).__init__()\n",
    "        self.ggnn = GatedGraphConv(out_channels=d1, num_layers=num_layers,aggr=aggr_type, bias=True)\n",
    "        self.fc1 = nn.Linear(d1, d2)\n",
    "        self.dense1_bn = nn.BatchNorm1d(d2)\n",
    "        self.fc2 = nn.Linear(d2, num_classes)\n",
    "        self.global_pool = global_mean_pool\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch_vector = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.ggnn(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training) # until here the output is for each node\n",
    "        \n",
    "        x = self.global_pool(x, batch_vector) # this makes the output to be graph level?\n",
    "        #x = self.fc1(x)\n",
    "        x = F.relu(self.dense1_bn(self.fc1(x)))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        #x = self.pool1(x, batch )\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        #x = torch.argmax(x, dim=1)  # we output softmax to use the nll_loss\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models for hyperparameter search\n",
    "model_list =[\n",
    "    {'epochs': 200,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 50,'d2': 20,'num_layers':2, 'aggr_type':'mean'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    {'epochs': 100,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 50,'d2': 20,'num_layers':2, 'aggr_type':'mean'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    {'epochs': 200,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 50,'d2': 20,'num_layers':2, 'aggr_type':'add'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    {'epochs': 100,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 50,'d2': 20,'num_layers':2, 'aggr_type':'add'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    \n",
    "    {'epochs': 200,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 100,'d2': 20,'num_layers':2, 'aggr_type':'mean'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    {'epochs': 100,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 100,'d2': 20,'num_layers':2, 'aggr_type':'mean'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    {'epochs': 200,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 100,'d2': 50,'num_layers':2, 'aggr_type':'mean'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "    {'epochs': 100,\n",
    "    'model': Net1,\n",
    "    'kwargs':{'d1': 100,'d2': 50,'num_layers':2, 'aggr_type':'mean'}, \n",
    "    'learning_rate': 0.01, 'weight_decay':5e-4, 'batch_size': 32},\n",
    "]\n",
    "\n",
    "model_list2 = []\n",
    "for modelclass in [Net1, Net2, Net3,Net4]:\n",
    "    for d1 in [25,50,100,200]:\n",
    "        for d2 in [20,50]:\n",
    "            for aggr_type in ['mean','add']:\n",
    "                for epochs in [100,200,300]:\n",
    "                    model_list2.append(\n",
    "                        {\n",
    "                        'model': modelclass,\n",
    "                        'epochs': epochs,\n",
    "                        'kwargs':{'d1': d1,'d2': d2,'num_layers':2, \n",
    "                                  'aggr_type':aggr_type}, \n",
    "                        'learning_rate': 0.01, 'weight_decay':5e-4, \n",
    "                        'batch_size': 32},\n",
    "                    )\n",
    "                    \n",
    "model_list = model_list2\n",
    "model_list = model_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n: 600  k folds= 3\n",
      "Datasets balancing: \n",
      "{0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100}\n",
      "{0: 80, 1: 80, 2: 80, 3: 80, 4: 80, 5: 80}\n",
      "{0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20}\n",
      "\n",
      " trained model:  Net1 {'d1': 25, 'd2': 20, 'num_layers': 2, 'aggr_type': 'mean'}  epochs: 100  val loss= 0.04978044951955477  val accuracy= 0.5238095238095238  val microF1= 0.4188034188034188  val macroF1= 0.4078394644917617\n",
      " trained model:  Net1 {'d1': 25, 'd2': 20, 'num_layers': 2, 'aggr_type': 'mean'}  epochs: 200  val loss= 0.04971835513909658  val accuracy= 0.4166666666666667  val microF1= 0.4487179487179487  val macroF1= 0.4502073884220046\n",
      "ERROR SAVING MODELtype\n",
      "ERROR SAVING MODELtype\n",
      "ERROR SAVING MODELtype\n",
      "ERROR SAVING MODELtype\n",
      "\n",
      " selected model from loss:  Net1 {'d1': 25, 'd2': 20, 'num_layers': 2, 'aggr_type': 'mean'}  epochs: 200 0.04971835513909658 0.4166666666666667 0.4487179487179487 0.4502073884220046\n",
      " selected model from accuracy:  Net1 {'d1': 25, 'd2': 20, 'num_layers': 2, 'aggr_type': 'mean'}  epochs: 100 0.04978044951955477 0.5238095238095238 0.4487179487179487 0.4502073884220046\n",
      " selected model from microF1:  Net1 {'d1': 25, 'd2': 20, 'num_layers': 2, 'aggr_type': 'mean'}  epochs: 200 0.04971835513909658 0.4166666666666667 0.4487179487179487 0.4502073884220046\n",
      " selected model from macroF1:  Net1 {'d1': 25, 'd2': 20, 'num_layers': 2, 'aggr_type': 'mean'}  epochs: 200 0.04971835513909658 0.4166666666666667 0.4487179487179487 0.4502073884220046\n"
     ]
    }
   ],
   "source": [
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "dataset = dataset.shuffle()\n",
    "k = 3\n",
    "n = len(dataset)\n",
    "print(\" n:\",n,\" k folds=\",k)\n",
    "train_dataset, test_dataset = balancedDatasetSplit_slice(dataset, prop=0.8)\n",
    "print(\"Datasets balancing: \")\n",
    "printDatasetBalance(dataset )\n",
    "printDatasetBalance(train_dataset )\n",
    "printDatasetBalance(test_dataset )\n",
    "print()\n",
    "\n",
    "modelsdict = modelSelection(model_list,k, train_dataset)\n",
    "reportModelSelectionResult(modelsdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(test_dataset):  120\n",
      "num graphs:  120\n",
      "tensor([3, 2, 2, 0, 1, 2, 2, 3, 3, 4, 5, 1, 4, 3, 4, 5, 1, 4, 2, 0, 2, 2, 1, 3,\n",
      "        4, 3, 2, 3, 0, 3, 1, 4, 3, 2, 3, 2, 4, 1, 5, 3, 1, 5, 0, 5, 2, 5, 1, 3,\n",
      "        1, 2, 5, 3, 0, 5, 3, 3, 2, 1, 2, 4, 5, 4, 0, 5, 3, 2, 1, 2, 1, 2, 0, 1,\n",
      "        5, 5, 5, 4, 0, 3, 3, 3, 4, 4, 3, 4, 5, 2, 5, 4, 0, 5, 4, 1, 2, 5, 3, 4,\n",
      "        4, 5, 0, 4, 2, 4, 2, 4, 5, 4, 3, 1, 1, 4, 5, 1, 5, 1, 5, 4, 1, 4, 4, 1],\n",
      "       device='cuda:0')\n",
      "tensor([3, 2, 5, 4, 1, 1, 3, 4, 3, 5, 2, 1, 0, 3, 1, 5, 2, 4, 0, 0, 2, 2, 3, 1,\n",
      "        2, 0, 1, 3, 5, 5, 4, 4, 4, 4, 3, 5, 4, 1, 2, 3, 5, 2, 4, 2, 2, 3, 1, 3,\n",
      "        0, 3, 3, 1, 3, 0, 0, 4, 2, 1, 5, 0, 5, 4, 3, 2, 3, 0, 5, 3, 1, 3, 4, 0,\n",
      "        1, 5, 4, 1, 2, 0, 0, 2, 0, 1, 5, 5, 5, 1, 4, 0, 3, 3, 4, 1, 2, 5, 0, 4,\n",
      "        4, 5, 0, 2, 1, 5, 2, 0, 5, 2, 0, 0, 2, 3, 4, 1, 5, 2, 5, 4, 1, 4, 1, 0],\n",
      "       device='cuda:0')\n",
      "Accuracy: 0.3667  macroF1: 0.35953567834491795  microF1: 0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "bmodel = final_model_train(modelsdict['best_models']['loss'], train_dataset)\n",
    "testresult = testModel(bmodel, test_dataset)\n",
    "modelsdict['testing'][bmodel.__class__.__name__+'loss']=testresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(test_dataset):  120\n",
      "num graphs:  120\n",
      "tensor([4, 5, 4, 4, 5, 5, 5, 0, 2, 2, 1, 5, 2, 5, 4, 4, 5, 1, 3, 3, 4, 1, 5, 4,\n",
      "        0, 4, 5, 3, 4, 3, 1, 5, 1, 0, 2, 3, 2, 5, 1, 4, 3, 0, 3, 1, 3, 5, 4, 1,\n",
      "        2, 1, 5, 1, 0, 2, 4, 0, 1, 3, 5, 4, 0, 5, 2, 5, 5, 1, 4, 5, 2, 0, 4, 1,\n",
      "        4, 1, 1, 3, 4, 0, 2, 1, 1, 1, 1, 5, 5, 4, 2, 5, 1, 2, 2, 4, 1, 1, 5, 4,\n",
      "        1, 5, 2, 1, 1, 4, 5, 3, 2, 3, 3, 1, 4, 4, 1, 4, 5, 5, 5, 0, 2, 5, 1, 5],\n",
      "       device='cuda:0')\n",
      "tensor([4, 5, 0, 3, 0, 1, 4, 4, 2, 1, 0, 2, 1, 5, 4, 3, 5, 0, 3, 2, 3, 1, 1, 4,\n",
      "        0, 3, 5, 4, 5, 3, 4, 2, 5, 3, 2, 3, 2, 4, 4, 0, 1, 5, 4, 0, 4, 5, 4, 1,\n",
      "        3, 5, 1, 1, 2, 0, 1, 2, 2, 0, 0, 0, 2, 5, 5, 5, 5, 1, 3, 5, 2, 3, 5, 5,\n",
      "        4, 0, 0, 3, 3, 0, 4, 3, 3, 1, 1, 1, 3, 1, 2, 0, 1, 4, 2, 3, 0, 0, 2, 2,\n",
      "        1, 2, 3, 2, 5, 2, 5, 0, 4, 4, 4, 1, 5, 3, 2, 1, 0, 0, 4, 4, 5, 1, 3, 2],\n",
      "       device='cuda:0')\n",
      "Accuracy: 0.3000  macroF1: 0.2963974008450804  microF1: 0.3\n"
     ]
    }
   ],
   "source": [
    "bmodel = final_model_train(modelsdict['best_models']['accuracy'], train_dataset)\n",
    "testresult = testModel(bmodel, test_dataset)\n",
    "modelsdict['testing'][bmodel.__class__.__name__+'accuracy']=testresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(test_dataset):  120\n",
      "num graphs:  120\n",
      "tensor([2, 3, 4, 5, 2, 3, 5, 2, 4, 1, 2, 3, 4, 4, 3, 3, 2, 5, 5, 2, 4, 5, 3, 3,\n",
      "        3, 2, 0, 2, 4, 4, 3, 2, 0, 0, 4, 3, 2, 1, 3, 2, 5, 1, 3, 1, 0, 4, 2, 1,\n",
      "        4, 0, 4, 1, 5, 2, 4, 3, 3, 2, 1, 4, 5, 2, 5, 0, 2, 4, 5, 4, 4, 1, 0, 5,\n",
      "        2, 4, 2, 2, 1, 5, 0, 4, 4, 2, 4, 2, 2, 1, 3, 2, 0, 5, 0, 5, 2, 5, 3, 4,\n",
      "        2, 3, 4, 2, 3, 4, 3, 3, 1, 1, 4, 4, 0, 0, 3, 4, 5, 1, 2, 2, 1, 2, 4, 0],\n",
      "       device='cuda:0')\n",
      "tensor([3, 5, 2, 2, 1, 5, 1, 5, 4, 1, 1, 3, 4, 3, 0, 3, 2, 1, 4, 5, 0, 4, 0, 2,\n",
      "        2, 5, 0, 2, 4, 1, 3, 2, 0, 3, 1, 1, 4, 0, 3, 0, 5, 1, 4, 1, 0, 1, 1, 0,\n",
      "        4, 2, 1, 0, 5, 0, 4, 3, 2, 1, 5, 4, 5, 2, 2, 4, 3, 4, 5, 0, 4, 1, 5, 5,\n",
      "        2, 4, 1, 2, 1, 5, 2, 2, 4, 2, 3, 2, 5, 0, 0, 0, 4, 5, 4, 5, 4, 0, 3, 4,\n",
      "        2, 3, 5, 3, 0, 4, 3, 3, 1, 5, 0, 3, 5, 2, 0, 3, 5, 3, 3, 1, 1, 2, 0, 3],\n",
      "       device='cuda:0')\n",
      "Accuracy: 0.4167  macroF1: 0.417590670532298  microF1: 0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "bmodel = final_model_train(modelsdict['best_models']['microF1'], train_dataset)\n",
    "testresult = testModel(bmodel, test_dataset)\n",
    "modelsdict['testing'][bmodel.__class__.__name__+'microF1']=testresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(test_dataset):  120\n",
      "num graphs:  120\n",
      "tensor([2, 2, 5, 4, 4, 2, 2, 5, 4, 4, 2, 5, 3, 4, 2, 2, 3, 1, 1, 2, 1, 4, 5, 5,\n",
      "        0, 1, 0, 2, 2, 2, 4, 5, 5, 3, 1, 5, 3, 5, 1, 5, 3, 5, 5, 0, 2, 5, 5, 4,\n",
      "        3, 5, 5, 0, 1, 5, 4, 1, 3, 0, 0, 2, 4, 5, 3, 1, 5, 3, 3, 3, 5, 5, 4, 3,\n",
      "        3, 5, 5, 3, 3, 5, 4, 5, 5, 4, 3, 4, 3, 5, 0, 5, 3, 5, 3, 5, 2, 3, 3, 3,\n",
      "        3, 0, 5, 3, 5, 3, 0, 5, 4, 5, 4, 2, 5, 5, 0, 1, 5, 3, 3, 3, 5, 4, 5, 1],\n",
      "       device='cuda:0')\n",
      "tensor([3, 2, 0, 1, 3, 5, 0, 1, 5, 3, 2, 2, 1, 4, 1, 2, 0, 5, 1, 3, 5, 4, 3, 1,\n",
      "        0, 4, 0, 1, 1, 2, 4, 2, 1, 5, 4, 2, 2, 5, 0, 5, 3, 3, 1, 2, 0, 5, 1, 0,\n",
      "        3, 5, 5, 4, 1, 0, 3, 1, 4, 3, 0, 2, 4, 2, 2, 0, 5, 0, 3, 4, 5, 4, 3, 3,\n",
      "        4, 5, 0, 3, 4, 1, 0, 2, 1, 1, 2, 0, 0, 4, 2, 5, 4, 4, 3, 0, 4, 0, 3, 4,\n",
      "        2, 2, 5, 3, 5, 0, 5, 0, 4, 2, 2, 5, 1, 2, 4, 1, 3, 5, 3, 3, 5, 4, 1, 1],\n",
      "       device='cuda:0')\n",
      "Accuracy: 0.3417  macroF1: 0.3462424800776116  microF1: 0.3416666666666667\n"
     ]
    }
   ],
   "source": [
    "bmodel = final_model_train(modelsdict['best_models']['macroF1'], train_dataset)\n",
    "testresult = testModel(bmodel, test_dataset)\n",
    "modelsdict['testing'][bmodel.__class__.__name__+'macroF1']=testresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macroF1</th>\n",
       "      <th>microF1</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.359536</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>Net1loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.296397</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>Net1accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.417591</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>Net1microF1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.346242</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>Net1macroF1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy   macroF1   microF1          name\n",
       "0  0.366667  0.359536  0.366667      Net1loss\n",
       "1  0.300000  0.296397  0.300000  Net1accuracy\n",
       "2  0.416667  0.417591  0.416667   Net1microF1\n",
       "3  0.341667  0.346242  0.341667   Net1macroF1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reportAllTest(modelsdict)\n",
    "saveResults(modelsdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "1. encapsulate all training, model selection,.. everything\n",
    "2. present results with Pandas tables, and histograms\n",
    "3. save models and results to disk, and load them later for testing\n",
    "4. transform into a python module or package\n",
    "\n",
    "### Pending:\n",
    "\n",
    "- prepare another notebook using the python module (prepare local and on collab)\n",
    "- test other GNN layers: GAT, GCN, GraphSAGE, Metalayer\n",
    "- do a good HP search\n",
    "- look for published architectures?\n",
    "- compare with published benchmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-pytorch",
   "language": "python",
   "name": "gnn-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
