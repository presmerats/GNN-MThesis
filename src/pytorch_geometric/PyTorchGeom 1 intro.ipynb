{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling of graphs\n",
    "A graph is used to model pairwise relations (edges) between objects (nodes). A single graph in PyTorch Geometric is described by an instance of torch_geometric.data.Data, which holds the following attributes by default:\n",
    "\n",
    "- data.x: Node feature matrix with shape [num_nodes, num_node_features]\n",
    "- data.edge_index: Graph connectivity in COO format with shape [2, num_edges] and type torch.long\n",
    "- data.edge_attr: Edge feature matrix with shape [num_edges, num_edge_features]\n",
    "- data.y: Target to train against (may have arbitrary shape)\n",
    "- data.pos: Node position matrix with shape [num_nodes, num_dimensions]\n",
    "\n",
    "None of these attributes is required. In fact, the Data object is not even restricted to these attributes. We can, e.g., extend it by data.face to save the connectivity of triangles from a 3D mesh in a tensor with shape [3, num_faces] and type torch.long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 4], x=[3, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 4], x=[3, 1])\n"
     ]
    }
   ],
   "source": [
    "# when edge_index defined as a list of tuples (closer to math notation)\n",
    "# then use .contiguous()\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1],\n",
    "                           [1, 0],\n",
    "                           [1, 2],\n",
    "                           [2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index.t().contiguous())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'edge_index']\n",
      "tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "edge_index found in data\n",
      "x found in data\n",
      "3\n",
      "4\n",
      "1\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# utility functions\n",
    "print(data.keys)\n",
    "print(data['x'])\n",
    "for key,item in data:\n",
    "    print('{} found in data'.format(key))\n",
    "print(data.num_nodes)\n",
    "print(data.num_edges)\n",
    "print(data.num_features)\n",
    "print(data.contains_isolated_nodes())\n",
    "print(data.contains_self_loops())\n",
    "print(data.is_directed())\n",
    "device = torch.device('cuda')\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Common benchmark datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ls11-www.cs.uni-dortmund.de/people/morris/graphkerneldatasets/ENZYMES.zip\n",
      "Extracting /tmp/ENZYMES/ENZYMES.zip\n",
      "Processing...\n",
      "Done!\n",
      "ENZYMES(600)\n",
      "600\n",
      "6\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# initialization of a dataset (download and process)\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "print(dataset)\n",
    "print(len(dataset))\n",
    "print(dataset.num_classes)\n",
    "print(dataset.num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 168], x=[37, 3], y=[1])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])\n",
    "print(data.is_undirected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENZYMES(540)\n",
      "ENZYMES(60)\n",
      "ENZYMES(600)\n",
      "ENZYMES(600)\n",
      "ENZYMES(540)\n",
      "ENZYMES(60)\n"
     ]
    }
   ],
   "source": [
    "# using slices\n",
    "train_dataset = dataset[:540]\n",
    "print(train_dataset)\n",
    "test_dataset = dataset[540:]\n",
    "print(test_dataset)\n",
    "\n",
    "# using shuffle\n",
    "dataset = dataset.shuffle()\n",
    "print(dataset)\n",
    "# same as\n",
    "perm = torch.randperm(len(dataset))\n",
    "dataset = dataset[perm]\n",
    "print(dataset)\n",
    "\n",
    "# splitting dataset into train/test\n",
    "train_dataset = dataset[60:]\n",
    "test_dataset = dataset[:60]\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n",
      "Cora()\n",
      "1\n",
      "7\n",
      "1433\n",
      "Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])\n",
      "True\n",
      "tensor(140)\n",
      "tensor(500)\n",
      "tensor(1000)\n"
     ]
    }
   ],
   "source": [
    "# Cora dataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "print(dataset)\n",
    "print(len(dataset))\n",
    "print(dataset.num_classes)\n",
    "print(dataset.num_features)\n",
    "\n",
    "data = dataset[0]\n",
    "print(data)\n",
    "print(data.is_undirected())\n",
    "print(data.train_mask.sum())\n",
    "print(data.val_mask.sum())\n",
    "print(data.test_mask.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[1112], edge_index=[2, 3986], x=[1112, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[940], edge_index=[2, 3662], x=[940, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[1154], edge_index=[2, 4234], x=[1154, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[1141], edge_index=[2, 4374], x=[1141, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[1061], edge_index=[2, 4058], x=[1061, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[927], edge_index=[2, 3730], x=[927, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[1064], edge_index=[2, 4078], x=[1064, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[1041], edge_index=[2, 3992], x=[1041, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[1164], edge_index=[2, 4286], x=[1164, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[848], edge_index=[2, 3280], x=[848, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[1048], edge_index=[2, 4104], x=[1048, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[1109], edge_index=[2, 4228], x=[1109, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[1017], edge_index=[2, 3826], x=[1017, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[1149], edge_index=[2, 3940], x=[1149, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[961], edge_index=[2, 3660], x=[961, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[999], edge_index=[2, 4018], x=[999, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[975], edge_index=[2, 3894], x=[975, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[1059], edge_index=[2, 4110], x=[1059, 3], y=[32])\n",
      "32\n",
      "Batch(batch=[811], edge_index=[2, 3104], x=[811, 3], y=[24])\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for batch in loader:\n",
    "    print(batch)\n",
    "    print(batch.num_graphs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[998], edge_index=[2, 3776], x=[998, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1110], edge_index=[2, 3982], x=[1110, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1060], edge_index=[2, 4032], x=[1060, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1133], edge_index=[2, 4132], x=[1133, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1019], edge_index=[2, 4070], x=[1019, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1010], edge_index=[2, 3964], x=[1010, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1080], edge_index=[2, 3990], x=[1080, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1168], edge_index=[2, 4208], x=[1168, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1053], edge_index=[2, 4112], x=[1053, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[987], edge_index=[2, 3896], x=[987, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1010], edge_index=[2, 3994], x=[1010, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1087], edge_index=[2, 3954], x=[1087, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1082], edge_index=[2, 4120], x=[1082, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[958], edge_index=[2, 3686], x=[958, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[973], edge_index=[2, 3620], x=[973, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[991], edge_index=[2, 4010], x=[991, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1021], edge_index=[2, 3842], x=[1021, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[1027], edge_index=[2, 3986], x=[1027, 3], y=[32])\n",
      "32\n",
      "torch.Size([32, 3])\n",
      "Batch(batch=[813], edge_index=[2, 3190], x=[813, 3], y=[24])\n",
      "24\n",
      "torch.Size([24, 3])\n"
     ]
    }
   ],
   "source": [
    "# usign batch : a column vector of graph identifiers \n",
    "# for al nodes of all graphs in the batch\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for data in loader:\n",
    "    print(data)\n",
    "    print(data.num_graphs)\n",
    "    x = scatter_mean(data.x, data.batch, dim=0)\n",
    "    print(x.size())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(pos=[2518, 3], y=[2518])\n"
     ]
    }
   ],
   "source": [
    "# transform get a graph as Data and return a graph\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "\n",
    "dataset = ShapeNet(root='/tmp/ShapeNet', category='Airplane')\n",
    "\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AddSelfLoops', 'Cartesian', 'Center', 'Compose', 'Constant', 'Distance', 'FaceToEdge', 'KNNGraph', 'LinearTransformation', 'LocalCartesian', 'NormalizeFeatures', 'NormalizeScale', 'OneHotDegree', 'Polar', 'RadiusGraph', 'RandomFlip', 'RandomRotate', 'RandomScale', 'RandomShear', 'RandomTranslate', 'SamplePoints', 'Spherical', 'TargetIndegree', 'ToDense', 'TwoHop', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'add_self_loops', 'cartesian', 'center', 'compose', 'constant', 'distance', 'face_to_edge', 'knn_graph', 'linear_transformation', 'local_cartesian', 'normalize_features', 'normalize_scale', 'one_hot_degree', 'polar', 'radius_graph', 'random_flip', 'random_rotate', 'random_scale', 'random_shear', 'random_translate', 'sample_points', 'spherical', 'target_indegree', 'to_dense', 'two_hop']\n",
      "Data(pos=[2518, 3], y=[2518])\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "\n",
    "print(dir(T))\n",
    "\n",
    "data = ShapeNet(root='/tmp/ShapeNet', category='Airplane',\n",
    "                    pre_transform=T.KNNGraph(k=6))\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning methods on graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of GCN on Cora datasest\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.9391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "1 tensor(1.8491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "2 tensor(1.7233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "3 tensor(1.5967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "4 tensor(1.4528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "5 tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "6 tensor(1.2246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "7 tensor(1.0772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "8 tensor(0.9786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "9 tensor(0.8883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "10 tensor(0.7864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "11 tensor(0.6765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "12 tensor(0.6059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "13 tensor(0.5335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "14 tensor(0.4865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "15 tensor(0.4145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "16 tensor(0.3495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "17 tensor(0.3169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "18 tensor(0.2779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "19 tensor(0.2628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "20 tensor(0.2331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "21 tensor(0.2003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "22 tensor(0.1756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "23 tensor(0.1796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "24 tensor(0.1615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "25 tensor(0.1336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "26 tensor(0.1246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "27 tensor(0.1570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "28 tensor(0.1241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "29 tensor(0.0929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "30 tensor(0.0956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "31 tensor(0.0968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "32 tensor(0.0855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "33 tensor(0.0861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "34 tensor(0.0743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "35 tensor(0.0789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "36 tensor(0.0706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "37 tensor(0.0761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "38 tensor(0.0608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "39 tensor(0.0838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "40 tensor(0.0419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "41 tensor(0.0456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "42 tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "43 tensor(0.0673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "44 tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "45 tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "46 tensor(0.0710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "47 tensor(0.0551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "48 tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "49 tensor(0.0527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "50 tensor(0.0381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "51 tensor(0.0513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "52 tensor(0.0436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "53 tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "54 tensor(0.0433, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "55 tensor(0.0539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "56 tensor(0.0400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "57 tensor(0.0627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "58 tensor(0.0292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "59 tensor(0.0475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "60 tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "61 tensor(0.0605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "62 tensor(0.0487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "63 tensor(0.0280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "64 tensor(0.0391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "65 tensor(0.0426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "66 tensor(0.0364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "67 tensor(0.0400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "68 tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "69 tensor(0.0393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "70 tensor(0.0524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "71 tensor(0.0374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "72 tensor(0.0325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "73 tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "74 tensor(0.0465, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "75 tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "76 tensor(0.0302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "77 tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "78 tensor(0.0364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "79 tensor(0.0361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "80 tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "81 tensor(0.0447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "82 tensor(0.0375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "83 tensor(0.0322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "84 tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "85 tensor(0.0359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "86 tensor(0.0352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "87 tensor(0.0309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "88 tensor(0.0553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "89 tensor(0.0401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "90 tensor(0.0368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "91 tensor(0.0353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "92 tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "93 tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "94 tensor(0.0392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "95 tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "96 tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "97 tensor(0.0334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "98 tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "99 tensor(0.0375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "100 tensor(0.0388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "101 tensor(0.0479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "102 tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "103 tensor(0.0528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "104 tensor(0.0372, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "105 tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "106 tensor(0.0472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "107 tensor(0.0329, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "108 tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "109 tensor(0.0329, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "110 tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "111 tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "112 tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "113 tensor(0.0417, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "114 tensor(0.0522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "115 tensor(0.0229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "116 tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "117 tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "118 tensor(0.0406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "119 tensor(0.0459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "120 tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "121 tensor(0.0401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "122 tensor(0.0398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "123 tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "124 tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "125 tensor(0.0280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "126 tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "127 tensor(0.0499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "128 tensor(0.0266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "129 tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "130 tensor(0.0313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "131 tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "132 tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "133 tensor(0.0349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "134 tensor(0.0319, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "135 tensor(0.0278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "136 tensor(0.0289, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "137 tensor(0.0267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "138 tensor(0.0242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "139 tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "140 tensor(0.0271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "141 tensor(0.0357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "142 tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "143 tensor(0.0330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "144 tensor(0.0264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "145 tensor(0.0331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "146 tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "147 tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "148 tensor(0.0359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "149 tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "150 tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "151 tensor(0.0397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "152 tensor(0.0259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "153 tensor(0.0447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "154 tensor(0.0306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "155 tensor(0.0365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "156 tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "157 tensor(0.0276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "158 tensor(0.0340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "159 tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "160 tensor(0.0267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "161 tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "162 tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 tensor(0.0273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "164 tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "165 tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "166 tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "167 tensor(0.0256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "168 tensor(0.0375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "169 tensor(0.0299, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "170 tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "171 tensor(0.0337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "172 tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "173 tensor(0.0271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "174 tensor(0.0277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "175 tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "176 tensor(0.0304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "177 tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "178 tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "179 tensor(0.0356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "180 tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "181 tensor(0.0314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "182 tensor(0.0244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "183 tensor(0.0340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "184 tensor(0.0311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "185 tensor(0.0208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "186 tensor(0.0321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "187 tensor(0.0392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "188 tensor(0.0313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "189 tensor(0.0320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "190 tensor(0.0283, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "191 tensor(0.0442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "192 tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "193 tensor(0.0326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "194 tensor(0.0309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "195 tensor(0.0204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "196 tensor(0.0218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "197 tensor(0.0317, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "198 tensor(0.0242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "199 tensor(0.0312, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "   \n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(epoch, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8060\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = pred[data.test_mask].eq(data.y[data.test_mask]).sum().item()\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-pytorch",
   "language": "python",
   "name": "gnn-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
