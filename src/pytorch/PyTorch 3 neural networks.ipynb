{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the network, processing inputs, calling backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# First network (MNIST CNN )\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# learnable parameters\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight\n",
    "print(params[1].size())\n",
    "print(params[2].size())\n",
    "print(params[3].size())\n",
    "print(params[4].size())\n",
    "print(params[5].size())\n",
    "print(params[6].size())\n",
    "print(params[7].size())\n",
    "print(params[8].size())\n",
    "print(params[9].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0521, -0.0487, -0.0587, -0.0992,  0.1464,  0.0598, -0.0326, -0.0367,\n",
      "         -0.0256,  0.2233]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "print(out.backward(torch.randn(1, 10)))\n",
    "print(input.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn only accepts mini-batches, If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3851, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "# there are other losses\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x7f78d426f518>\n",
      "<ThAddmmBackward object at 0x7f78d426f588>\n",
      "<ExpandBackward object at 0x7f78d426f518>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  BackProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0086,  0.0007,  0.0023,  0.0021, -0.0078,  0.0030])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters (before starting sgd)\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Weight updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually updating weights\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[-0.1862, -0.1496,  0.0201, -0.0144, -0.0385],\n",
      "          [-0.0734, -0.1475, -0.1783,  0.0469, -0.1246],\n",
      "          [-0.1170, -0.0707, -0.0914,  0.1348,  0.1972],\n",
      "          [-0.1182, -0.0188,  0.0521, -0.0176, -0.1451],\n",
      "          [-0.1851, -0.1346,  0.1965, -0.1993,  0.1852]]],\n",
      "\n",
      "\n",
      "        [[[-0.1402, -0.0542,  0.0397,  0.0189, -0.0440],\n",
      "          [ 0.0155,  0.0717,  0.1549,  0.0371, -0.1972],\n",
      "          [ 0.1675,  0.1704,  0.0326,  0.1616, -0.0726],\n",
      "          [-0.1405,  0.1913,  0.1534, -0.0872, -0.0068],\n",
      "          [ 0.0080, -0.0805, -0.1816, -0.1202,  0.1645]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0261,  0.0236,  0.0641, -0.0029, -0.1618],\n",
      "          [ 0.1385,  0.0227,  0.0386, -0.1392, -0.0843],\n",
      "          [ 0.0571, -0.0162, -0.1808,  0.1128, -0.0065],\n",
      "          [ 0.1614, -0.0830, -0.0743,  0.0074, -0.0097],\n",
      "          [-0.0345, -0.1926, -0.0815,  0.0059,  0.1234]]],\n",
      "\n",
      "\n",
      "        [[[-0.0305,  0.0817,  0.0022, -0.0534, -0.1564],\n",
      "          [ 0.0065, -0.0198, -0.1114,  0.1549, -0.1864],\n",
      "          [ 0.0500, -0.0402, -0.1681,  0.0352,  0.1215],\n",
      "          [ 0.0200,  0.0715, -0.0461,  0.0595,  0.0674],\n",
      "          [ 0.1060,  0.1213, -0.0617, -0.1832, -0.0270]]],\n",
      "\n",
      "\n",
      "        [[[-0.0527,  0.0034, -0.0171, -0.1472, -0.1929],\n",
      "          [ 0.0336,  0.0263,  0.0518,  0.1726, -0.0617],\n",
      "          [-0.1292, -0.1759, -0.1096,  0.1268, -0.0606],\n",
      "          [-0.0584,  0.1484, -0.0436, -0.0854,  0.1835],\n",
      "          [-0.1086, -0.1892,  0.0208, -0.0206,  0.1161]]],\n",
      "\n",
      "\n",
      "        [[[-0.1013,  0.1111,  0.0452,  0.1088,  0.1149],\n",
      "          [-0.0868, -0.0666,  0.0250, -0.0186, -0.0670],\n",
      "          [-0.0938,  0.1555,  0.1186,  0.1955,  0.1430],\n",
      "          [ 0.1846, -0.1587,  0.0778,  0.1600, -0.0155],\n",
      "          [-0.1399, -0.1656,  0.1193,  0.0377,  0.0451]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1188, -0.0867,  0.0872,  0.0361, -0.0371, -0.1152], requires_grad=True), Parameter containing:\n",
      "tensor([[[[-0.0427, -0.0207, -0.0583, -0.0374,  0.0000],\n",
      "          [-0.0606,  0.0033, -0.0615,  0.0118,  0.0739],\n",
      "          [ 0.0063,  0.0351,  0.0302,  0.0544,  0.0053],\n",
      "          [-0.0676, -0.0285,  0.0529, -0.0468, -0.0251],\n",
      "          [-0.0558, -0.0788, -0.0279, -0.0453,  0.0214]],\n",
      "\n",
      "         [[ 0.0737,  0.0030, -0.0181,  0.0534,  0.0513],\n",
      "          [-0.0145, -0.0308, -0.0420, -0.0640,  0.0585],\n",
      "          [-0.0469,  0.0036,  0.0628, -0.0076,  0.0452],\n",
      "          [-0.0390, -0.0144, -0.0070, -0.0354, -0.0433],\n",
      "          [ 0.0369,  0.0453, -0.0251, -0.0661,  0.0585]],\n",
      "\n",
      "         [[ 0.0102, -0.0490, -0.0164, -0.0093,  0.0805],\n",
      "          [-0.0464,  0.0426, -0.0332, -0.0424, -0.0323],\n",
      "          [ 0.0315, -0.0645,  0.0299, -0.0548,  0.0376],\n",
      "          [ 0.0185, -0.0410, -0.0452, -0.0796,  0.0011],\n",
      "          [ 0.0006, -0.0715, -0.0723,  0.0026,  0.0033]],\n",
      "\n",
      "         [[ 0.0729,  0.0104, -0.0490, -0.0545,  0.0807],\n",
      "          [ 0.0634, -0.0446, -0.0608,  0.0656,  0.0256],\n",
      "          [-0.0553, -0.0745, -0.0094,  0.0539, -0.0671],\n",
      "          [-0.0646,  0.0742,  0.0603,  0.0573,  0.0117],\n",
      "          [-0.0251,  0.0748, -0.0347,  0.0680, -0.0689]],\n",
      "\n",
      "         [[ 0.0696, -0.0815,  0.0213, -0.0633, -0.0659],\n",
      "          [ 0.0565,  0.0615, -0.0720, -0.0530, -0.0181],\n",
      "          [-0.0704,  0.0266, -0.0191,  0.0186, -0.0642],\n",
      "          [ 0.0212,  0.0632,  0.0424,  0.0687, -0.0711],\n",
      "          [-0.0447, -0.0581,  0.0055,  0.0109, -0.0484]],\n",
      "\n",
      "         [[ 0.0205, -0.0445, -0.0322,  0.0604,  0.0076],\n",
      "          [ 0.0314, -0.0396,  0.0076,  0.0448,  0.0416],\n",
      "          [-0.0626,  0.0219, -0.0237,  0.0013,  0.0542],\n",
      "          [ 0.0354,  0.0011,  0.0604, -0.0563, -0.0709],\n",
      "          [ 0.0469,  0.0284, -0.0380,  0.0376, -0.0160]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0235,  0.0700, -0.0107, -0.0637, -0.0405],\n",
      "          [ 0.0236, -0.0695, -0.0261, -0.0506,  0.0711],\n",
      "          [-0.0360,  0.0468,  0.0737, -0.0678,  0.0543],\n",
      "          [-0.0262, -0.0273, -0.0728,  0.0753,  0.0337],\n",
      "          [ 0.0363,  0.0541,  0.0718,  0.0216, -0.0608]],\n",
      "\n",
      "         [[-0.0589, -0.0434,  0.0818,  0.0179, -0.0640],\n",
      "          [-0.0459,  0.0695, -0.0525, -0.0241,  0.0102],\n",
      "          [-0.0103,  0.0292, -0.0339, -0.0686,  0.0313],\n",
      "          [-0.0207, -0.0440,  0.0182,  0.0009, -0.0193],\n",
      "          [-0.0025, -0.0495,  0.0512, -0.0739,  0.0120]],\n",
      "\n",
      "         [[ 0.0396,  0.0213,  0.0636, -0.0424,  0.0161],\n",
      "          [-0.0273,  0.0419, -0.0794,  0.0490,  0.0671],\n",
      "          [-0.0337,  0.0492,  0.0386,  0.0813,  0.0152],\n",
      "          [-0.0685, -0.0191,  0.0710, -0.0749, -0.0525],\n",
      "          [-0.0289, -0.0666,  0.0194,  0.0803, -0.0748]],\n",
      "\n",
      "         [[ 0.0502, -0.0190,  0.0519,  0.0196, -0.0801],\n",
      "          [-0.0209, -0.0157, -0.0789, -0.0120, -0.0628],\n",
      "          [-0.0474,  0.0665,  0.0212, -0.0456, -0.0148],\n",
      "          [ 0.0064, -0.0017, -0.0379, -0.0477, -0.0593],\n",
      "          [ 0.0369, -0.0405, -0.0414,  0.0354, -0.0758]],\n",
      "\n",
      "         [[ 0.0351, -0.0563,  0.0802,  0.0162, -0.0643],\n",
      "          [-0.0478,  0.0788,  0.0590,  0.0560, -0.0669],\n",
      "          [-0.0215, -0.0032, -0.0032, -0.0716, -0.0161],\n",
      "          [ 0.0798,  0.0504, -0.0361, -0.0437, -0.0086],\n",
      "          [-0.0630, -0.0493, -0.0070,  0.0709,  0.0718]],\n",
      "\n",
      "         [[ 0.0188,  0.0180,  0.0563,  0.0660,  0.0019],\n",
      "          [-0.0115, -0.0628,  0.0724,  0.0548, -0.0254],\n",
      "          [ 0.0579, -0.0613, -0.0325,  0.0053,  0.0782],\n",
      "          [-0.0244,  0.0408,  0.0756, -0.0132,  0.0645],\n",
      "          [-0.0251,  0.0763,  0.0728, -0.0318, -0.0226]]],\n",
      "\n",
      "\n",
      "        [[[-0.0017, -0.0303,  0.0046, -0.0225,  0.0582],\n",
      "          [-0.0107, -0.0356,  0.0202, -0.0176, -0.0629],\n",
      "          [ 0.0549,  0.0632, -0.0605,  0.0001, -0.0104],\n",
      "          [ 0.0109, -0.0747,  0.0590,  0.0597,  0.0431],\n",
      "          [ 0.0108,  0.0447, -0.0174, -0.0038, -0.0164]],\n",
      "\n",
      "         [[ 0.0016, -0.0565, -0.0274,  0.0153,  0.0156],\n",
      "          [-0.0301,  0.0423, -0.0526,  0.0496,  0.0510],\n",
      "          [-0.0416,  0.0625,  0.0774, -0.0642, -0.0639],\n",
      "          [-0.0540, -0.0475, -0.0030,  0.0196,  0.0586],\n",
      "          [-0.0699, -0.0811, -0.0177, -0.0229,  0.0406]],\n",
      "\n",
      "         [[ 0.0790, -0.0695,  0.0156,  0.0577,  0.0324],\n",
      "          [-0.0106,  0.0267, -0.0009,  0.0756,  0.0292],\n",
      "          [-0.0417, -0.0198,  0.0471,  0.0265, -0.0109],\n",
      "          [ 0.0453, -0.0073,  0.0702,  0.0375, -0.0679],\n",
      "          [ 0.0276,  0.0420, -0.0446,  0.0332, -0.0714]],\n",
      "\n",
      "         [[ 0.0218,  0.0103,  0.0515, -0.0787, -0.0256],\n",
      "          [ 0.0047,  0.0803,  0.0138,  0.0337, -0.0146],\n",
      "          [ 0.0747, -0.0796,  0.0649, -0.0161, -0.0386],\n",
      "          [ 0.0424, -0.0062, -0.0803, -0.0691,  0.0534],\n",
      "          [-0.0661, -0.0531,  0.0649, -0.0492,  0.0401]],\n",
      "\n",
      "         [[-0.0514,  0.0244,  0.0710, -0.0168, -0.0277],\n",
      "          [ 0.0196, -0.0014, -0.0261,  0.0466, -0.0814],\n",
      "          [-0.0254, -0.0430, -0.0051, -0.0074,  0.0165],\n",
      "          [-0.0053,  0.0069, -0.0510,  0.0404,  0.0798],\n",
      "          [-0.0771,  0.0682, -0.0345, -0.0154,  0.0085]],\n",
      "\n",
      "         [[ 0.0182,  0.0666,  0.0407,  0.0500,  0.0701],\n",
      "          [-0.0539, -0.0236, -0.0764, -0.0329,  0.0611],\n",
      "          [-0.0311, -0.0046,  0.0736,  0.0620,  0.0646],\n",
      "          [ 0.0723,  0.0229,  0.0518,  0.0038, -0.0139],\n",
      "          [-0.0479,  0.0562, -0.0254, -0.0527, -0.0082]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0661, -0.0722,  0.0757, -0.0773,  0.0062],\n",
      "          [-0.0606,  0.0390, -0.0274, -0.0094,  0.0305],\n",
      "          [ 0.0623,  0.0007,  0.0604,  0.0410,  0.0653],\n",
      "          [-0.0717, -0.0770, -0.0619,  0.0168,  0.0189],\n",
      "          [-0.0552,  0.0410, -0.0144,  0.0668, -0.0357]],\n",
      "\n",
      "         [[-0.0241, -0.0332,  0.0108,  0.0493, -0.0132],\n",
      "          [ 0.0733,  0.0701,  0.0086,  0.0280,  0.0799],\n",
      "          [ 0.0142,  0.0322,  0.0663, -0.0563, -0.0813],\n",
      "          [-0.0606,  0.0788, -0.0261, -0.0726,  0.0376],\n",
      "          [ 0.0748,  0.0789,  0.0738,  0.0786, -0.0478]],\n",
      "\n",
      "         [[ 0.0640,  0.0426,  0.0314,  0.0468, -0.0511],\n",
      "          [ 0.0817,  0.0642, -0.0363, -0.0306, -0.0315],\n",
      "          [ 0.0356, -0.0348, -0.0562, -0.0373, -0.0397],\n",
      "          [ 0.0031, -0.0581, -0.0549,  0.0381, -0.0537],\n",
      "          [ 0.0322,  0.0166, -0.0342, -0.0689,  0.0380]],\n",
      "\n",
      "         [[-0.0516, -0.0633, -0.0210, -0.0129, -0.0108],\n",
      "          [ 0.0012,  0.0310, -0.0239, -0.0354, -0.0766],\n",
      "          [-0.0352,  0.0762, -0.0306, -0.0641,  0.0729],\n",
      "          [-0.0387,  0.0302, -0.0805,  0.0720, -0.0594],\n",
      "          [-0.0812,  0.0495,  0.0418, -0.0665,  0.0168]],\n",
      "\n",
      "         [[-0.0305,  0.0632,  0.0108,  0.0271, -0.0547],\n",
      "          [ 0.0302, -0.0601, -0.0176,  0.0315,  0.0459],\n",
      "          [ 0.0138,  0.0167,  0.0384, -0.0758, -0.0037],\n",
      "          [-0.0024,  0.0776,  0.0288, -0.0238, -0.0807],\n",
      "          [-0.0430, -0.0387,  0.0338, -0.0756,  0.0405]],\n",
      "\n",
      "         [[-0.0728, -0.0155, -0.0566, -0.0567,  0.0507],\n",
      "          [ 0.0320,  0.0223, -0.0509, -0.0074,  0.0537],\n",
      "          [-0.0192, -0.0501,  0.0767, -0.0485, -0.0623],\n",
      "          [ 0.0289,  0.0286, -0.0743, -0.0312,  0.0175],\n",
      "          [ 0.0228, -0.0053,  0.0535,  0.0145,  0.0458]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0163,  0.0294,  0.0351,  0.0569,  0.0345],\n",
      "          [-0.0265, -0.0606,  0.0625, -0.0383,  0.0115],\n",
      "          [-0.0210, -0.0529,  0.0434, -0.0038,  0.0304],\n",
      "          [ 0.0162,  0.0107,  0.0764, -0.0575,  0.0561],\n",
      "          [-0.0043, -0.0094,  0.0262,  0.0657,  0.0640]],\n",
      "\n",
      "         [[ 0.0543,  0.0231, -0.0202, -0.0670, -0.0289],\n",
      "          [-0.0085,  0.0325, -0.0668, -0.0383,  0.0798],\n",
      "          [ 0.0166,  0.0146, -0.0085,  0.0481, -0.0782],\n",
      "          [ 0.0650,  0.0290,  0.0429, -0.0109, -0.0113],\n",
      "          [ 0.0188, -0.0239, -0.0228,  0.0273, -0.0431]],\n",
      "\n",
      "         [[-0.0762, -0.0524, -0.0250,  0.0482, -0.0767],\n",
      "          [-0.0696,  0.0190, -0.0446, -0.0451,  0.0794],\n",
      "          [ 0.0590, -0.0510,  0.0614,  0.0699,  0.0233],\n",
      "          [-0.0281, -0.0276,  0.0552,  0.0731,  0.0564],\n",
      "          [-0.0802, -0.0198, -0.0562,  0.0622,  0.0355]],\n",
      "\n",
      "         [[-0.0394, -0.0362, -0.0554,  0.0531,  0.0328],\n",
      "          [ 0.0700, -0.0030,  0.0082, -0.0084,  0.0082],\n",
      "          [ 0.0478, -0.0800,  0.0635, -0.0323,  0.0554],\n",
      "          [ 0.0780, -0.0226, -0.0091, -0.0457, -0.0325],\n",
      "          [ 0.0762, -0.0133, -0.0500, -0.0592,  0.0464]],\n",
      "\n",
      "         [[ 0.0249,  0.0701,  0.0668,  0.0780,  0.0275],\n",
      "          [ 0.0030, -0.0098,  0.0286,  0.0077, -0.0218],\n",
      "          [ 0.0132, -0.0430,  0.0114, -0.0725, -0.0652],\n",
      "          [-0.0766,  0.0154, -0.0443, -0.0119,  0.0788],\n",
      "          [-0.0769, -0.0367, -0.0787, -0.0650,  0.0634]],\n",
      "\n",
      "         [[-0.0413,  0.0429,  0.0057, -0.0187,  0.0678],\n",
      "          [-0.0380, -0.0729,  0.0482, -0.0489, -0.0011],\n",
      "          [ 0.0306,  0.0425, -0.0671, -0.0262, -0.0297],\n",
      "          [-0.0737, -0.0091, -0.0048,  0.0209, -0.0477],\n",
      "          [-0.0281,  0.0470, -0.0289, -0.0699, -0.0459]]],\n",
      "\n",
      "\n",
      "        [[[-0.0559, -0.0585, -0.0119, -0.0017,  0.0303],\n",
      "          [ 0.0464, -0.0146, -0.0268,  0.0682,  0.0360],\n",
      "          [-0.0193,  0.0573, -0.0573, -0.0615,  0.0552],\n",
      "          [-0.0313, -0.0657, -0.0352, -0.0423, -0.0665],\n",
      "          [-0.0684, -0.0599, -0.0291,  0.0175, -0.0119]],\n",
      "\n",
      "         [[-0.0694, -0.0296,  0.0062, -0.0456, -0.0160],\n",
      "          [-0.0199, -0.0199, -0.0563, -0.0773, -0.0087],\n",
      "          [ 0.0398,  0.0784,  0.0780, -0.0252,  0.0531],\n",
      "          [-0.0648,  0.0043, -0.0296, -0.0355,  0.0095],\n",
      "          [ 0.0017,  0.0468,  0.0259, -0.0789,  0.0173]],\n",
      "\n",
      "         [[-0.0407, -0.0180, -0.0652,  0.0365,  0.0171],\n",
      "          [-0.0749,  0.0458,  0.0734, -0.0376,  0.0122],\n",
      "          [-0.0487,  0.0249, -0.0094, -0.0107, -0.0579],\n",
      "          [-0.0650,  0.0417, -0.0096,  0.0691, -0.0523],\n",
      "          [-0.0336, -0.0278, -0.0640, -0.0263,  0.0232]],\n",
      "\n",
      "         [[ 0.0158,  0.0245,  0.0170,  0.0770, -0.0163],\n",
      "          [-0.0339, -0.0165,  0.0590, -0.0536,  0.0667],\n",
      "          [ 0.0778, -0.0489, -0.0501, -0.0561,  0.0703],\n",
      "          [-0.0741, -0.0726,  0.0540, -0.0468, -0.0133],\n",
      "          [ 0.0512, -0.0440, -0.0403,  0.0002,  0.0388]],\n",
      "\n",
      "         [[ 0.0748, -0.0372,  0.0510, -0.0689,  0.0042],\n",
      "          [-0.0048, -0.0628, -0.0681,  0.0219, -0.0115],\n",
      "          [-0.0180,  0.0732, -0.0510,  0.0682,  0.0422],\n",
      "          [ 0.0815, -0.0382,  0.0417,  0.0752,  0.0696],\n",
      "          [-0.0559, -0.0182, -0.0791, -0.0798,  0.0171]],\n",
      "\n",
      "         [[ 0.0715, -0.0396,  0.0483,  0.0277,  0.0590],\n",
      "          [-0.0426,  0.0367,  0.0385,  0.0786, -0.0607],\n",
      "          [ 0.0279, -0.0679, -0.0374,  0.0713,  0.0330],\n",
      "          [-0.0743,  0.0662, -0.0406, -0.0345,  0.0302],\n",
      "          [-0.0749,  0.0275, -0.0814, -0.0735,  0.0368]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0305,  0.0241, -0.0758,  0.0650, -0.0766,  0.0239,  0.0285,  0.0160,\n",
      "         0.0740, -0.0693,  0.0713,  0.0256, -0.0352, -0.0233,  0.0354,  0.0292],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0126,  0.0177,  0.0340,  ..., -0.0240,  0.0405,  0.0381],\n",
      "        [ 0.0009,  0.0421,  0.0464,  ..., -0.0092,  0.0123, -0.0191],\n",
      "        [ 0.0349,  0.0443, -0.0222,  ...,  0.0303,  0.0496, -0.0016],\n",
      "        ...,\n",
      "        [ 0.0349, -0.0061,  0.0446,  ..., -0.0149,  0.0407,  0.0252],\n",
      "        [ 0.0268,  0.0041,  0.0251,  ..., -0.0069,  0.0443, -0.0489],\n",
      "        [ 0.0347,  0.0306,  0.0194,  ..., -0.0057,  0.0190,  0.0473]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0436, -0.0319,  0.0414,  0.0208,  0.0377, -0.0322, -0.0094,  0.0360,\n",
      "         0.0132,  0.0167,  0.0349, -0.0005, -0.0310,  0.0043,  0.0101,  0.0343,\n",
      "         0.0199, -0.0498,  0.0186,  0.0158,  0.0465, -0.0111,  0.0230, -0.0100,\n",
      "         0.0190,  0.0261, -0.0013,  0.0266, -0.0168,  0.0437,  0.0160,  0.0164,\n",
      "        -0.0473, -0.0275, -0.0342,  0.0440,  0.0303, -0.0260,  0.0044,  0.0047,\n",
      "         0.0152, -0.0200, -0.0438, -0.0196, -0.0268, -0.0050,  0.0471,  0.0372,\n",
      "        -0.0211, -0.0288,  0.0202, -0.0141,  0.0005,  0.0471, -0.0175, -0.0148,\n",
      "        -0.0150,  0.0160, -0.0348,  0.0234, -0.0373, -0.0245,  0.0146, -0.0469,\n",
      "         0.0033, -0.0346,  0.0305,  0.0427, -0.0017, -0.0406,  0.0194,  0.0024,\n",
      "        -0.0162,  0.0434,  0.0211,  0.0071, -0.0075,  0.0146, -0.0198,  0.0284,\n",
      "        -0.0406, -0.0217,  0.0183,  0.0332,  0.0110,  0.0277, -0.0067,  0.0443,\n",
      "        -0.0235, -0.0340,  0.0272,  0.0231,  0.0404, -0.0086, -0.0208, -0.0048,\n",
      "        -0.0465, -0.0248, -0.0071,  0.0406,  0.0459,  0.0139,  0.0421, -0.0257,\n",
      "        -0.0434,  0.0022,  0.0004,  0.0272, -0.0240,  0.0206,  0.0223,  0.0141,\n",
      "        -0.0490,  0.0058, -0.0037, -0.0244,  0.0152, -0.0147, -0.0345,  0.0217],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0696,  0.0690, -0.0339,  ...,  0.0865, -0.0032,  0.0338],\n",
      "        [-0.0422, -0.0112, -0.0878,  ..., -0.0483,  0.0453, -0.0698],\n",
      "        [-0.0078, -0.0439, -0.0194,  ...,  0.0275, -0.0669,  0.0629],\n",
      "        ...,\n",
      "        [-0.0280,  0.0406, -0.0388,  ...,  0.0559, -0.0038,  0.0781],\n",
      "        [ 0.0292,  0.0186,  0.0460,  ..., -0.0349, -0.0498,  0.0330],\n",
      "        [ 0.0026, -0.0882, -0.0425,  ...,  0.0879, -0.0660, -0.0300]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0286, -0.0647, -0.0424, -0.0669, -0.0764,  0.0299, -0.0677, -0.0360,\n",
      "         0.0297, -0.0164, -0.0686,  0.0522,  0.0659, -0.0273,  0.0869, -0.0409,\n",
      "        -0.0422,  0.0163,  0.0507, -0.0726,  0.0840,  0.0636,  0.0540, -0.0502,\n",
      "         0.0795,  0.0416,  0.0471,  0.0051,  0.0412, -0.0690,  0.0452,  0.0614,\n",
      "         0.0153,  0.0388, -0.0262,  0.0360,  0.0487, -0.0789,  0.0748, -0.0760,\n",
      "         0.0325, -0.0474, -0.0274, -0.0750, -0.0376, -0.0721, -0.0361,  0.0171,\n",
      "         0.0804,  0.0906, -0.0604, -0.0035,  0.0909, -0.0514,  0.0198,  0.0012,\n",
      "         0.0038,  0.0640,  0.0585, -0.0023, -0.0262, -0.0570, -0.0331,  0.0727,\n",
      "         0.0745,  0.0024, -0.0496, -0.0454, -0.0558, -0.0572,  0.0838, -0.0831,\n",
      "         0.0638,  0.0751, -0.0078, -0.0671,  0.0671, -0.0417, -0.0806, -0.0733,\n",
      "        -0.0442, -0.0889,  0.0218, -0.0222], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0489, -0.0673, -0.0464, -0.0576,  0.0794,  0.0226,  0.0938, -0.0562,\n",
      "          0.0756, -0.0975, -0.0442, -0.0560, -0.0611,  0.0978, -0.1074,  0.0541,\n",
      "          0.0437, -0.0760, -0.0322,  0.0123, -0.0189,  0.0157,  0.0735,  0.1017,\n",
      "          0.0012,  0.0084,  0.0642, -0.0899, -0.1017,  0.0314, -0.0913,  0.0793,\n",
      "         -0.0242,  0.0432, -0.0911,  0.0202,  0.0165, -0.0647,  0.0369,  0.0297,\n",
      "          0.0588, -0.0057,  0.0103,  0.0946,  0.0059,  0.0592, -0.0746,  0.0423,\n",
      "          0.0358, -0.0682, -0.0005, -0.0659,  0.0849, -0.1051,  0.0612,  0.0106,\n",
      "          0.0391, -0.0868,  0.0816, -0.0679,  0.0052,  0.0036,  0.0883, -0.0883,\n",
      "         -0.0532,  0.0378, -0.0066,  0.0313,  0.0254, -0.1042, -0.0825,  0.0878,\n",
      "         -0.0829,  0.0085,  0.0618, -0.0079,  0.0167,  0.0983,  0.1025, -0.0199,\n",
      "         -0.0368, -0.0154,  0.0857, -0.0294],\n",
      "        [ 0.0069, -0.0987, -0.0610, -0.0676,  0.0924,  0.0233, -0.0495,  0.0203,\n",
      "         -0.0809,  0.0618, -0.0737, -0.0117, -0.0484,  0.0782,  0.0538, -0.0436,\n",
      "          0.0391, -0.0266,  0.0964, -0.0031, -0.0485,  0.0272,  0.0277, -0.0515,\n",
      "         -0.0328, -0.0803,  0.0923,  0.0087,  0.0454, -0.1028,  0.0986, -0.0471,\n",
      "         -0.0844,  0.0986, -0.0060, -0.1041,  0.0316, -0.0528, -0.0424,  0.0106,\n",
      "         -0.0492,  0.0369,  0.0315,  0.0183, -0.0371,  0.0448, -0.0597, -0.0207,\n",
      "         -0.0366, -0.0207,  0.0124, -0.0218,  0.0181, -0.0842,  0.0331,  0.0809,\n",
      "          0.0237,  0.1042,  0.0414, -0.0015,  0.0683,  0.0043, -0.0067, -0.0565,\n",
      "          0.0189, -0.1041, -0.0711,  0.0578, -0.0247,  0.0710,  0.0636, -0.0366,\n",
      "          0.0887, -0.0242, -0.0451,  0.0418, -0.0955,  0.1056, -0.0875, -0.0031,\n",
      "         -0.0263,  0.0577,  0.0807, -0.1000],\n",
      "        [-0.0772,  0.0566,  0.0967,  0.0498, -0.0115,  0.0813, -0.1064,  0.0868,\n",
      "         -0.0354,  0.0476, -0.0180,  0.0948, -0.0362, -0.0351,  0.0112, -0.1001,\n",
      "         -0.0165,  0.0323, -0.0841, -0.1068, -0.0875,  0.0206, -0.0129,  0.0243,\n",
      "          0.0331, -0.0953, -0.0378, -0.0140, -0.0378, -0.1005,  0.0874,  0.0136,\n",
      "          0.0808, -0.1001, -0.0378, -0.0046,  0.1073,  0.0085, -0.0676, -0.0406,\n",
      "         -0.0511,  0.1022,  0.0822,  0.0190, -0.0637,  0.0551, -0.0038, -0.0271,\n",
      "         -0.0156,  0.0561,  0.0720,  0.0118, -0.0058,  0.0411, -0.0007, -0.0675,\n",
      "          0.0381, -0.0025,  0.0802, -0.0909, -0.0659,  0.0703,  0.0073,  0.0213,\n",
      "         -0.0379,  0.0725,  0.0965,  0.0328, -0.0388,  0.0268, -0.1049,  0.0384,\n",
      "         -0.0410,  0.0621, -0.0266, -0.0963,  0.0591, -0.0091,  0.0601, -0.0704,\n",
      "         -0.0415,  0.0350, -0.0843,  0.0283],\n",
      "        [ 0.0635,  0.0748, -0.0527, -0.0592,  0.0717, -0.0181,  0.0830,  0.0149,\n",
      "          0.0872, -0.0374, -0.0284,  0.0262,  0.0334, -0.0113,  0.0570,  0.0578,\n",
      "         -0.0847,  0.0377,  0.1068, -0.0512, -0.0695, -0.0959,  0.0910,  0.0538,\n",
      "          0.0864, -0.0749, -0.0388,  0.0290, -0.0753, -0.0780,  0.0246,  0.0470,\n",
      "         -0.0909, -0.1010, -0.0881, -0.0065, -0.0233, -0.0138,  0.0448, -0.0689,\n",
      "          0.0915, -0.0795, -0.0894, -0.0623,  0.0849, -0.1082,  0.0522,  0.0738,\n",
      "          0.0300, -0.0039,  0.0231,  0.0623,  0.0013, -0.0810, -0.0694,  0.0956,\n",
      "         -0.1083, -0.0156,  0.1016,  0.0321,  0.0250,  0.0482, -0.0184, -0.0525,\n",
      "         -0.0022,  0.0845,  0.1022,  0.0508, -0.0467,  0.0902,  0.0283,  0.1024,\n",
      "         -0.0763, -0.0881,  0.0501, -0.1058,  0.0865,  0.0290, -0.0585, -0.0919,\n",
      "          0.0970,  0.0846, -0.0730,  0.0501],\n",
      "        [ 0.0833,  0.0601,  0.0798,  0.0389,  0.0965,  0.0217,  0.0983,  0.0242,\n",
      "         -0.0487,  0.0859, -0.0553,  0.0822,  0.0071, -0.0432, -0.0807, -0.0527,\n",
      "          0.0551,  0.0779, -0.0327,  0.0158,  0.0262, -0.0685, -0.0692,  0.0419,\n",
      "          0.0490, -0.1022,  0.0758, -0.0929,  0.0898,  0.1052,  0.0762,  0.0707,\n",
      "         -0.0047,  0.0360,  0.0744,  0.1047, -0.0003, -0.0412, -0.0353,  0.0898,\n",
      "         -0.0304,  0.0118,  0.0878, -0.0237,  0.0758,  0.0838,  0.0148,  0.0553,\n",
      "         -0.0121,  0.0726,  0.0449, -0.0047,  0.0836,  0.0862,  0.0687, -0.0021,\n",
      "          0.0184, -0.0637, -0.0164,  0.0368,  0.1086,  0.0986, -0.0442,  0.0316,\n",
      "          0.0398, -0.0321, -0.0532, -0.0594,  0.0565, -0.0519,  0.0710,  0.0499,\n",
      "         -0.0403,  0.0800, -0.0910, -0.0092, -0.0226, -0.0001,  0.1079, -0.0689,\n",
      "          0.0058,  0.1001, -0.0315,  0.0132],\n",
      "        [-0.0468, -0.0067,  0.0807, -0.0493,  0.0281, -0.0807,  0.0022,  0.0695,\n",
      "         -0.0761,  0.0964,  0.0130, -0.0636, -0.1006,  0.1057,  0.0721, -0.0400,\n",
      "          0.0436,  0.0668,  0.1052,  0.0515, -0.0881, -0.0614,  0.0517, -0.0618,\n",
      "         -0.0037, -0.0925, -0.0925,  0.0391,  0.1026,  0.1087,  0.0744, -0.0516,\n",
      "         -0.0657, -0.0818, -0.0716,  0.1082,  0.0425, -0.0237, -0.0182, -0.0952,\n",
      "         -0.0687, -0.0488, -0.0648,  0.0718,  0.1017, -0.0225,  0.0444,  0.0764,\n",
      "          0.0099, -0.0207,  0.0586,  0.1059, -0.0419, -0.0518,  0.0403, -0.0070,\n",
      "          0.0670, -0.0157, -0.0260,  0.0885,  0.0428,  0.0010, -0.0179, -0.0858,\n",
      "          0.0172,  0.0080, -0.0835, -0.0078,  0.0101,  0.0024,  0.0854,  0.0508,\n",
      "         -0.0985,  0.0887, -0.0952,  0.0858, -0.0953, -0.0302,  0.0447,  0.0633,\n",
      "          0.0025,  0.0539, -0.0214, -0.0715],\n",
      "        [ 0.0828, -0.0737,  0.0971, -0.0850,  0.0221, -0.0684,  0.1080,  0.0809,\n",
      "         -0.0702,  0.1030, -0.1040, -0.0496,  0.0713, -0.0696,  0.0147,  0.0882,\n",
      "         -0.0066, -0.0309, -0.0078,  0.0391,  0.0649,  0.0162, -0.0807, -0.0335,\n",
      "          0.0810,  0.0812, -0.0787,  0.0494, -0.0604,  0.0021, -0.0891,  0.0977,\n",
      "         -0.0888,  0.0061, -0.1070, -0.0298,  0.0108,  0.0551, -0.0858, -0.0164,\n",
      "         -0.0354, -0.0311,  0.0245, -0.0643,  0.0604,  0.0839,  0.0900,  0.0042,\n",
      "         -0.0992, -0.1038, -0.0705,  0.0254, -0.1015, -0.0454, -0.0862, -0.0786,\n",
      "         -0.0471,  0.0426, -0.0933,  0.0133,  0.0630, -0.1075, -0.0063, -0.0556,\n",
      "          0.0186, -0.0654,  0.0372, -0.0537, -0.0089,  0.0799, -0.0980, -0.0881,\n",
      "          0.0446,  0.0114,  0.0142, -0.0103,  0.0503, -0.0216, -0.0527,  0.0580,\n",
      "         -0.0410, -0.0713,  0.0714,  0.0042],\n",
      "        [-0.0347,  0.0611,  0.0999, -0.0784,  0.0592,  0.0497, -0.0480,  0.0438,\n",
      "         -0.0299, -0.0869, -0.0252, -0.0974, -0.1001,  0.0143, -0.0782,  0.0097,\n",
      "          0.0506,  0.0687,  0.0977,  0.0219,  0.0396, -0.0104,  0.0915, -0.0901,\n",
      "         -0.0759,  0.0565, -0.0147, -0.0134, -0.0897,  0.0578,  0.0781,  0.0285,\n",
      "          0.0829, -0.0122, -0.0941, -0.1052,  0.0620, -0.0959,  0.0852,  0.0257,\n",
      "          0.1070, -0.0107, -0.1000,  0.0711,  0.0168, -0.0551,  0.0028,  0.0561,\n",
      "          0.0178, -0.0757,  0.0508,  0.0159,  0.0630,  0.0996, -0.0612,  0.0025,\n",
      "          0.0309,  0.0687, -0.0153,  0.0828,  0.0728,  0.0874,  0.0946, -0.1004,\n",
      "          0.0184,  0.0610,  0.0252,  0.0394,  0.0458, -0.0142, -0.0792,  0.0835,\n",
      "         -0.0809, -0.0263, -0.0722, -0.0658, -0.0828, -0.0789,  0.0522, -0.0974,\n",
      "         -0.0600,  0.0770, -0.0987,  0.0148],\n",
      "        [ 0.0950,  0.0840, -0.1032,  0.0490,  0.0908,  0.0653,  0.0002, -0.0888,\n",
      "          0.0710,  0.0049, -0.0282, -0.1009,  0.0794, -0.0463, -0.0540,  0.0814,\n",
      "          0.1065, -0.0665,  0.0158, -0.0692, -0.0937, -0.0615,  0.0248, -0.0338,\n",
      "         -0.0309,  0.0469, -0.1032,  0.0456, -0.1082,  0.0314, -0.1055, -0.0097,\n",
      "         -0.0576, -0.0136,  0.0134, -0.0409, -0.0557,  0.0896,  0.0976, -0.0523,\n",
      "         -0.0334,  0.0877, -0.0396, -0.0871, -0.0927, -0.0345, -0.0653, -0.0385,\n",
      "         -0.0218, -0.0167,  0.0128, -0.0610,  0.0377, -0.0851,  0.0186, -0.0150,\n",
      "          0.0572,  0.0487, -0.1078,  0.0341,  0.0407, -0.0462, -0.0729,  0.0121,\n",
      "         -0.0426, -0.1085, -0.0604, -0.0060, -0.0962, -0.0006,  0.0221,  0.0216,\n",
      "         -0.0172, -0.0656,  0.0144, -0.0308, -0.1021, -0.0027,  0.0990, -0.0024,\n",
      "         -0.0908,  0.0335, -0.1044, -0.0336],\n",
      "        [-0.0480,  0.0935, -0.0192,  0.0316,  0.0356,  0.0732, -0.0371, -0.0679,\n",
      "          0.0792, -0.0769,  0.0508, -0.0119, -0.0332,  0.0862,  0.0761, -0.0261,\n",
      "         -0.0287, -0.0709,  0.0539, -0.0495,  0.0673,  0.0854,  0.0877,  0.0031,\n",
      "          0.0793, -0.0281, -0.0454, -0.0136,  0.0593,  0.0685,  0.0061,  0.1090,\n",
      "         -0.0896,  0.0302,  0.0639,  0.0058,  0.0476,  0.0356, -0.0920, -0.0409,\n",
      "          0.0633,  0.0725, -0.0727, -0.1071,  0.0571,  0.1030, -0.0014,  0.0862,\n",
      "          0.0896,  0.0832, -0.0614,  0.0565,  0.0584,  0.0096, -0.0426,  0.0247,\n",
      "          0.1028,  0.0831,  0.1069, -0.1029,  0.0448,  0.0099, -0.0256,  0.0105,\n",
      "          0.0072, -0.0490, -0.0929,  0.0333, -0.0005, -0.1007,  0.1074,  0.0296,\n",
      "          0.0569, -0.0273,  0.0833,  0.0988, -0.0729, -0.0984,  0.1045,  0.0970,\n",
      "          0.0764, -0.0041, -0.0301, -0.1068]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0527, -0.0699, -0.0111, -0.0801,  0.0901,  0.1073, -0.0475,  0.0140,\n",
      "         0.0451,  0.1064], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using toch.optim\n",
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-pytorch",
   "language": "python",
   "name": "gnn-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
